{"./":{"url":"./","title":"Introduction","keywords":"","body":"Introduction相关文档Introduction Elasticsearch 是一个分布式、RESTful 风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。 作为 Elastic Stack 的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 相关文档 中文文档: 传送门 官方文档: 传送门 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 16:58:28 "},"sxt/01_简介.html":{"url":"sxt/01_简介.html","title":"01_简介","keywords":"","body":"01_简介一,Elasticsearch 简介01_简介 一,Elasticsearch 简介 Elasticsearch是一个基于Lucene的搜索服务器.他提供了一个分布式的全文搜索引擎,其对外服务是基于RESTful web接口发布的. Elasticsearch是用Java开发的应用,并作为Apache许可条款下的开放源码发布,是当前流行的企业级搜索引擎. 设计用于云计算中,能够达到近实时搜索,稳定,可靠,快速,安装使用方便 JDK环境你依赖的,不要忘记安装 ES中的源码矢量分析算法还是比较NB的 ES要求 你必要要给我提供 1024个线程 和65536字节的虚拟内存 虚拟内存: 就是把硬盘的一部分空间用来存储 做快速读写的时候,这里用至少一个的长期定位的IO流 理论上可以达到近实时搜索 可以做备份,主体宕机,备份可以立刻顶上去 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:19:40 "},"sxt/02_概念.html":{"url":"sxt/02_概念.html","title":"02_概念","keywords":"","body":"02_概念02_概念 功能分类 ES具备下列2个功能: 搜索. 功能和Solr类似 分析, 结合 LogStash 使用(比如 大数据的海量数据的大数据分析) 但是现在更多的用kafka,他是流式计算. 计算后,即有分片结果,也有每个节点的结果 相关概念 cluster 集群.elasticsearch集群由一个或多个节点组成,其中有一个主节点,这个主节点是可以通过选举产生的,主从节点是对于集群内部来说的.Elasticsearch的一个概念就是去中心化,字面上理解就是五中心节点,这是对于集群外部来说的,因为从外部看Elasticsearch集群,在逻辑上是一个整体,你与集群中的任何一个节点通讯和与整个es集群通讯是等价的.in other word,主节点的存在不会产生单点安全隐患(只要节点不是全宕机),并发访问瓶颈等问题. 这个集群是有主,无中心,就是说么有谁是必须的 只要半数以上的节点ok,整个集群就可以 脑裂 Index: 索引 索引.相当于关系型数据库中的表,其中存储若干相似结构的Document的数据.如: 客户索引,订单索引,商品索引等. Elasticsearch中的索引不像数据库表格中的一样强制的数据结构约束,在理论上,可以存储任意数据结构的数据.但是为了更好的为业务提供搜索数据支撑,还是要设计合适的索引体系来存储不同的数据. shards和replicas 统称为分片 shards primary shard: 代表索引的主分片, Elasticsearch可以把一个完整的索引分成多个primary shard,这样的好处是可以把一个大的索引拆分成多个分片,分布存储在不同的es节点上,从而形成分布式存储,并为搜索访问提供分布式服务,提高并发处理能力 primary shard的数量只能在索引创建时指定,并且索引创建后不能在更改primary shard数量. replicas replicas shard: 代表索引主分片的副本(从分片),es可以设置多个replicas shard.replicashard的作用: 一是提高系统的容错性,当某个节点某个primary shard 损坏或丢失时可以从副本中恢复 二是提高es的查询效率,es会自动对搜索请求进行负载 主分片用来读和写,从分片是只读,自动备份 当主分片宕机的时候,从分片可以升级成主分片 当节点恢复之后,他会进行数据同步,重新设定主从的分配的映射关系以及散列关系. 知道了上面这些,下面我们看一个要过期不能用的概念 Type 类型. 每个索引中都必须有唯一的一个Type,Type 是Index中的一个逻辑分类. es中的数据document是存储在索引下的Type中的. type(抽象概念) 注意:es5.x以及更低版本中,一个Index中可以有多个Type. es6.x版本之后,type概念被弱化,一个index中只能有一个唯一的type,且在7.x版本之后,删除type定义 Document 就像你在MongoDB里面的文档是一样的 文档,ES中的最小数据单元,一个Document就是一条数据,一般使用JSON数据结构表示.每个Index下的Type中都可以存储多个Document. 一个Document中可定义多个field,field就是数据字段. 如: 学生数据({\"name\":\"张三\",\"age\":20,\"gender\":\"男\"). 元数据 在es中,所有已_开头的属性都成为元数据,都有着自己特定的含义 例如: _index: 表示索引 倒排索引 对数据进行分析,抽取出数据中的词条,以词条作为key,对应数据的存储位置作为 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 16:14:41 "},"sxt/03_常用场景.html":{"url":"sxt/03_常用场景.html","title":"03_常用场景","keywords":"","body":"03_常用场景Elasticsearch常见使用场景什么适量,油温八成,炸制金黄 而西餐不是,温度210度烤5分钟,盐20g : 公司觉得不错就加大研发进度就NB了,后来 03_常用场景 created by victorfengming Elasticsearch常见使用场景 维基百科: 全文检索,高亮显示,搜索推荐 在wiki百科面前:百度就不能叫做 百科 The Guardian(国外的新闻网站),此平台可以对用户丶的行为(点击,浏览,收藏,评论),社区网络数据(对新闻的评论等)进行数据分析,为新闻的发布者提供相关的公众反馈. Stack Overflow(国外的程序员异常讨论论坛) 大部分技术交流,很少的中文描述 Github(开源代码管理),或者gitee, 西餐料理特别好学,不像中餐 什么适量,油温八成,炸制金黄 而西餐不是,温度210度烤5分钟,盐20g : 待业在家的程序员,他老婆去学菜谱,但是 菜谱不是很好找,他就写了一个搜索菜谱的 东西,这个就是Elasticsearch的前身,然后之后 他在工作中就用到了,他就又优化优化了,后来就 公司觉得不错就加大研发进度就NB了,后来 中国的程序员和外国的程序员的最大不同是: 中国的程序员是面向结果 而外国的程序员而是无聊,所以真的不要惹一个外国的程序员 也不要去挑战他 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 16:46:21 "},"sxt/04_基于Docker安装ElasticSearch和Kibana.html":{"url":"sxt/04_基于Docker安装ElasticSearch和Kibana.html","title":"04_基于Docker安装ElasticSearch和Kibana","keywords":"","body":"04_基于Docker安装ElasticSearch和Kibana.1. 为elasticsearch提供完善的系统配置修改限制信息修改线程数量限制修改系统04_基于Docker安装ElasticSearch和Kibana. created by victorfengming 安装 ES6.x要求linux的内核版本是3.5+版本以上 然后我们校验linux 版本的方式就是 [root@iz8g9301trfnpxz ~]# uname -a Linux iz8g9301trfnpxz 3.10.0-1127.19.1.el7.x86_64 #1 SMP Tue Aug 25 17:23:54 UTC 2020 x86_64 x86_64 x86_64 GNU/Linux [root@iz8g9301trfnpxz ~]# 1. 为elasticsearch提供完善的系统配置 es在linux中安装部署的时候,需要系统为其提供若干系统配置. 如: 应用可启动线程数,应用可以在系统中划分的虚拟内存,应用可以最多创建多少个文件等. 修改限制信息 是修改系统中允许应用最多创建多少个文件等的限制权限 linux默认来说,一般限制应用最多创建的文件是65535个. 但是elasticsearch至少需要65535的文件创建权限. 修改如下: vim /etc/securitylimits.conf [root@iz8g9301trfnpxz ELK]# cat /etc/securitylimits.conf * soft nofile 65536 * hard nofile 65536 [root@iz8g9301trfnpxz ELK]# 修改线程数量限制 [root@iz8g9301trfnpxz ELK]# cat /etc/securitylimits.conf * soft nofile 65536 * hard nofile 65536 * soft nproc 4096 root soft nproc unlimited [root@iz8g9301trfnpxz ELK]# 4096*250k = 1.5G,要求你虚拟机内存至少要1.5GB,推荐提供内存2G+ unlimited 这个只能用在 root用户,不可设置到其他用户!!!**敲黑板 修改系统 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 16:42:27 "},"sxt/05_创建索引及状态查看.html":{"url":"sxt/05_创建索引及状态查看.html","title":"05_创建索引及状态查看","keywords":"","body":"05_创建索引及状态查看.05_创建索引及状态查看. created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:25:24 "},"sxt/06_修改索引及删除索引.html":{"url":"sxt/06_修改索引及删除索引.html","title":"06_修改索引及删除索引","keywords":"","body":"06_修改索引及删除索引.06_修改索引及删除索引. created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:25:26 "},"sxt/07_新增文档.html":{"url":"sxt/07_新增文档.html","title":"07_新增文档","keywords":"","body":"07_新增文档.07_新增文档. created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:25:28 "},"sxt/08_主键查询文档.html":{"url":"sxt/08_主键查询文档.html","title":"08_主键查询文档","keywords":"","body":"08_主键查询文档.08_主键查询文档. created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:25:30 "},"sxt/09_修改文档.html":{"url":"sxt/09_修改文档.html","title":"09_修改文档","keywords":"","body":"09_修改文档.09_修改文档. created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:25:32 "},"sxt/10_删除文档.html":{"url":"sxt/10_删除文档.html","title":"10_删除文档","keywords":"","body":"10_删除文档.10_删除文档. created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:25:34 "},"sxt/11_bulk批量操作.html":{"url":"sxt/11_bulk批量操作.html","title":"11_bulk批量操作","keywords":"","body":"11_bulk批量操作.11_bulk批量操作. created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:25:36 "},"sxt/12_分词器和标准化处理.html":{"url":"sxt/12_分词器和标准化处理.html","title":"12_分词器和标准化处理","keywords":"","body":"12_分词器和标准化处理12_分词器和标准化处理 created by victorfengming new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:25:55 "},"sxt/13_安装中文分词器.html":{"url":"sxt/13_安装中文分词器.html","title":"13_安装中文分词器","keywords":"","body":"13_安装中文分词器13_安装中文分词器 created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:26:01 "},"sxt/14_mapping映射.html":{"url":"sxt/14_mapping映射.html","title":"14_mapping映射","keywords":"","body":"14_mapping映射14_mapping映射 created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:26:04 "},"sxt/15_querystring搜索.html":{"url":"sxt/15_querystring搜索.html","title":"15_querystring搜索","keywords":"","body":"15_querystring搜索.15_querystring搜索.new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:15:59 "},"sxt/16_DSL搜索.html":{"url":"sxt/16_DSL搜索.html","title":"16_DSL搜索","keywords":"","body":"16_DSL搜索.16_DSL搜索.new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:15:59 "},"sxt/17_SpringDataElasticsearch_实体.html":{"url":"sxt/17_SpringDataElasticsearch_实体.html","title":"17_实体","keywords":"","body":"17SpringDataElasticsearch实体17SpringDataElasticsearch实体 created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:26:10 "},"sxt/18_SpringDataElasticsearch_创建索引.html":{"url":"sxt/18_SpringDataElasticsearch_创建索引.html","title":"18_创建索引","keywords":"","body":"18SpringDataElasticsearch创建索引.18SpringDataElasticsearch创建索引.new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:15:59 "},"sxt/19_SpringDataElasticsearch_删除索引.html":{"url":"sxt/19_SpringDataElasticsearch_删除索引.html","title":"19_删除索引","keywords":"","body":"19SpringDataElasticsearch删除索引.19SpringDataElasticsearch删除索引.new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:15:59 "},"sxt/20_SpringDataElasticsearch_新增和修改文档.html":{"url":"sxt/20_SpringDataElasticsearch_新增和修改文档.html","title":"20_新增和修改文档","keywords":"","body":"20SpringDataElasticsearch新增和修改文档.20SpringDataElasticsearch新增和修改文档.new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:15:59 "},"sxt/21_SpringDataElasticsearch_删除文档.html":{"url":"sxt/21_SpringDataElasticsearch_删除文档.html","title":"21_删除文档","keywords":"","body":"21SpringDataElasticsearch删除文档.21SpringDataElasticsearch删除文档.new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:15:59 "},"sxt/22_SpringDataElasticsearch_搜索文档.html":{"url":"sxt/22_SpringDataElasticsearch_搜索文档.html","title":"22_搜索文档","keywords":"","body":"22SpringDataElasticsearch搜索文档.22SpringDataElasticsearch搜索文档.new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:15:59 "},"sxt/23_SpringDataElasticsearch_高亮搜索.html":{"url":"sxt/23_SpringDataElasticsearch_高亮搜索.html","title":"23_高亮搜索","keywords":"","body":"23SpringDataElasticsearch高亮搜索23SpringDataElasticsearch高亮搜索 created by victorfengmingnew Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 14:26:14 "},"hm/1_ElasticSearch介绍与安装/":{"url":"hm/1_ElasticSearch介绍与安装/","title":"1_ElasticSearch介绍与安装","keywords":"","body":"ElasticSearch安装与介绍Elastic Stack简介ElasticsearchLogstashKibanaBeatsElasticSearch快速入门简介前言下载拉取Docker容器单机版安装启动ElasticSearch错误分析错误情况1错误情况2错误情况3错误情况4错误情况5错误情况6ElasticSearchHead可视化工具通过Docker方式安装通过Chrome插件安装ElasticSearch中的基本概念索引文档映射文档类型RESTful API创建非结构化索引创建空索引删除索引插入数据更新数据删除索引搜索数据DSL搜索ElasticSearch核心详解文档查询响应批量操作分页映射结构化查询过滤查询中文分词什么是分词分词api中文分词难点安装分词器测试全文搜索构造数据单词搜索多词搜索组合搜索权重ElasticSearch集群集群节点搭建集群分片和副本故障转移分布式文档搜索文档全文搜索Java客户端REST客户端构造数据REST低级客户端REST高级客户端ElasticSearch安装与介绍 Elastic Stack简介 如果你没有听说过Elastic Stack，那你一定听说过ELK，实际上ELK是三款软件的简称，分别是Elasticsearch、 Logstash、Kibana组成，在发展的过程中，又有新成员Beats的加入，所以就形成了Elastic Stack。所以说，ELK是旧的称呼，Elastic Stack是新的名字。 全系的Elastic Stack技术栈包括： Elasticsearch Elasticsearch 基于java，是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引副本机制，restful风格接口，多数据源，自动搜索负载等。 Logstash Logstash 基于java，是一个开源的用于收集,分析和存储日志的工具。 Kibana Kibana 基于nodejs，也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的Web 界面，可以汇总、分析和搜索重要数据日志。 Beats Beats是elastic公司开源的一款采集系统监控数据的代理agent，是在被监控服务器上以客户端形式运行的数据收集器的统称，可以直接把数据发送给Elasticsearch或者通过Logstash发送给Elasticsearch，然后进行后续的数据分析活动。Beats由如下组成: Packetbeat：是一个网络数据包分析器，用于监控、收集网络流量信息，Packetbeat嗅探服务器之间的流量，解析应用层协议，并关联到消息的处理，其支 持ICMP (v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、Redis、MongoDB、Memcache等协议； Filebeat：用于监控、收集服务器日志文件，其已取代 logstash forwarder； Metricbeat：可定期获取外部系统的监控指标信息，其可以监控、收集 Apache、HAProxy、MongoDB MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务； Beats和Logstash其实都可以进行数据的采集，但是目前主流的是使用Beats进行数据采集，然后使用 Logstash进行数据的分割处理等，早期没有Beats的时候，使用的就是Logstash进行数据的采集。 ElasticSearch快速入门 简介 官网：https://www.elastic.co/ ElasticSearch是一个基于Lucene的搜索服务器。 它提供了一个分布式多用户能力的全文搜索引擎，基于RESTful web接口。 Elasticsearch是用Java开发的，并作为Apache许可条款下的开放源码发布，是当前流行的企业级搜索引擎。设计用于云计算中，能够达到实时搜索，稳定，可靠，快速，安装使用方便。 我们建立一个网站或应用程序，并要添加搜索功能，但是想要完成搜索工作的创建是非常困难的。我们希望搜索解决方案要运行速度快，我们希望能有一个零配置和一个完全免费的搜索模式，我们希望能够简单地使用JSON通过HTTP来索引数据，我们希望我们的搜索服务器始终可用，我们希望能够从一台开始并扩展到数百台，我们要实时搜索，我们要简单的多租户，我们希望建立一个云的解决方案。因此我们利用Elasticsearch来解决所有这些问题及可能出现的更多其它问题。 ElasticSearch是Elastic Stack的核心，同时Elasticsearch 是一个分布式、RESTful风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为Elastic Stack的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况。 前言 Elasticsearch的发展是非常快速的，所以在ES5.0之前，ELK的各个版本都不统一，出现了版本号混乱的状态，所以从5.0开始，所有Elastic Stack中的项目全部统一版本号。目前最新版本是6.5.4，我们将基于这一版本进行学习。 下载 到官网下载：https://www.elastic.co/cn/downloads/ 选择对应版本的数据，这里我使用的是Linux来进行安装，所以就先下载好ElasticSearch的Linux安装包 拉取Docker容器 因为我们需要部署在Linux下，为了以后迁移ElasticStack环境方便，我们就使用Docker来进行部署，首先我们拉取一个带有ssh的centos docker镜像 # 拉取镜像 docker pull moxi/centos_ssh # 制作容器 docker run --privileged -d -it -h ElasticStack --name ElasticStack -p 11122:22 -p 9200:9200 -p 5601:5601 -p 9300:9300 -v /etc/localtime:/etc/localtime:ro moxi/centos_ssh /usr/sbin/init 然后直接远程连接11122端口即可 单机版安装 因为ElasticSearch不支持Root用户直接操作，因此我们需要创建一个elsearch用户 # 添加新用户 useradd elsearch # 创建一个soft目录，存放下载的软件 mkdir /soft # 进入，然后通过xftp工具，将刚刚下载的文件拖动到该目录下 cd /soft # 解压缩 tar -zxvf elasticsearch-7.9.1-linux-x86_64.tar.gz #重命名 mv elasticsearch-7.9.1/ elsearch 因为刚刚我们是使用root用户操作的，所以我们还需要更改一下/soft文件夹的所属，改为elsearch用户 chown elsearch:elsearch /soft/ -R 然后在切换成elsearch用户进行操作 # 切换用户 su - elsearch 然后我们就可以对我们的配置文件进行修改了 # 进入到 elsearch下的config目录 cd /soft/elsearch/config 然后找到下面的配置 #打开配置文件 vim elasticsearch.yml #设置ip地址，任意网络均可访问 network.host: 0.0.0.0 在Elasticsearch中如果，network.host不是localhost或者127.0.0.1的话，就会认为是生产环境，会对环境的要求比较高，我们的测试环境不一定能够满足，一般情况下需要修改2处配置，如下： # 修改jvm启动参数 vim conf/jvm.options #根据自己机器情况修改 -Xms128m -Xmx128m 然后在修改第二处的配置，这个配置要求我们到宿主机器上来进行配置 # 到宿主机上打开文件 vim /etc/sysctl.conf # 增加这样一条配置，一个进程在VMAs(虚拟内存区域)创建内存映射最大数量 vm.max_map_count=655360 # 让配置生效 sysctl -p 启动ElasticSearch 首先我们需要切换到 elsearch用户 su - elsearch 然后在到bin目录下，执行下面 # 进入bin目录 cd /soft/elsearch/bin # 后台启动 ./elasticsearch -d 启动成功后，访问下面的URL http://202.193.56.222:9200/ 如果出现了下面的信息，就表示已经成功启动了 如果你在启动的时候，遇到过问题，那么请参考下面的错误分析~ 错误分析 错误情况1 如果出现下面的错误信息 java.lang.RuntimeException: can not run elasticsearch as root at org.elasticsearch.bootstrap.Bootstrap.initializeNatives(Bootstrap.java:111) at org.elasticsearch.bootstrap.Bootstrap.setup(Bootstrap.java:178) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:393) at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:170) at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:161) at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:127) at org.elasticsearch.cli.Command.main(Command.java:90) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:126) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) For complete error details, refer to the log at /soft/elsearch/logs/elasticsearch.log [root@e588039bc613 bin]# 2020-09-22 02:59:39,537121 UTC [536] ERROR CLogger.cc@310 Cannot log to named pipe /tmp/elasticsearch-5834501324803693929/controller_log_381 as it could not be opened for writing 2020-09-22 02:59:39,537263 UTC [536] INFO Main.cc@103 Parent process died - ML controller exiting 就说明你没有切换成 elsearch用户，因为不能使用root操作es su - elsearch 错误情况2 [1]:max file descriptors [4096] for elasticsearch process is too low, increase to at least[65536] 解决方法：切换到root用户，编辑limits.conf添加如下内容 vi /etc/security/limits.conf # ElasticSearch添加如下内容: * soft nofile 65536 * hard nofile 131072 * soft nproc 2048 * hard nproc 4096 错误情况3 [2]: max number of threads [1024] for user [elsearch] is too low, increase to at least [4096] 也就是最大线程数设置的太低了，需要改成4096 #解决：切换到root用户，进入limits.d目录下修改配置文件。 vi /etc/security/limits.d/90-nproc.conf #修改如下内容： * soft nproc 1024 #修改为 * soft nproc 4096 错误情况4 [3]: system call filters failed to install; check the logs and fix your configuration or disable system call filters at your own risk 解决：Centos6不支持SecComp，而ES5.2.0默认bootstrap.system_call_filter为true vim config/elasticsearch.yml # 添加 bootstrap.system_call_filter: false bootstrap.memory_lock: false 错误情况5 [elsearch@e588039bc613 bin]$ Exception in thread \"main\" org.elasticsearch.bootstrap.BootstrapException: java.nio.file.AccessDeniedException: /soft/elsearch/config/elasticsearch.keystore Likely root cause: java.nio.file.AccessDeniedException: /soft/elsearch/config/elasticsearch.keystore at java.base/sun.nio.fs.UnixException.translateToIOException(UnixException.java:90) at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:111) at java.base/sun.nio.fs.UnixException.rethrowAsIOException(UnixException.java:116) at java.base/sun.nio.fs.UnixFileSystemProvider.newByteChannel(UnixFileSystemProvider.java:219) at java.base/java.nio.file.Files.newByteChannel(Files.java:375) at java.base/java.nio.file.Files.newByteChannel(Files.java:426) at org.apache.lucene.store.SimpleFSDirectory.openInput(SimpleFSDirectory.java:79) at org.elasticsearch.common.settings.KeyStoreWrapper.load(KeyStoreWrapper.java:220) at org.elasticsearch.bootstrap.Bootstrap.loadSecureSettings(Bootstrap.java:240) at org.elasticsearch.bootstrap.Bootstrap.init(Bootstrap.java:349) at org.elasticsearch.bootstrap.Elasticsearch.init(Elasticsearch.java:170) at org.elasticsearch.bootstrap.Elasticsearch.execute(Elasticsearch.java:161) at org.elasticsearch.cli.EnvironmentAwareCommand.execute(EnvironmentAwareCommand.java:86) at org.elasticsearch.cli.Command.mainWithoutErrorHandling(Command.java:127) at org.elasticsearch.cli.Command.main(Command.java:90) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:126) at org.elasticsearch.bootstrap.Elasticsearch.main(Elasticsearch.java:92) 我们通过排查，发现是因为 /soft/elsearch/config/elasticsearch.keystore 存在问题 也就是说该文件还是所属于root用户，而我们使用elsearch用户无法操作，所以需要把它变成elsearch chown elsearch:elsearch elasticsearch.keystore 错误情况6 [1]: the default discovery settings are unsuitable for production use; at least one of [discovery.seed_hosts, discovery.seed_providers, cluster.initial_master_nodes] must be configured ERROR: Elasticsearch did not exit normally - check the logs at /soft/elsearch/logs/elasticsearch.log 继续修改配置 elasticsearch.yaml # 取消注释，并保留一个节点 node.name: node-1 cluster.initial_master_nodes: [\"node-1\"] ElasticSearchHead可视化工具 由于ES官方没有给ES提供可视化管理工具，仅仅是提供了后台的服务，elasticsearch-head是一个为ES开发的一个页面客户端工具，其源码托管于Github，地址为 传送门 head提供了以下安装方式 源码安装，通过npm run start启动（不推荐） 通过docker安装（推荐） 通过chrome插件安装（推荐） 通过ES的plugin方式安装（不推荐） 通过Docker方式安装 #拉取镜像 docker pull mobz/elasticsearch-head:5 #创建容器 docker create --name elasticsearch-head -p 9100:9100 mobz/elasticsearch-head:5 #启动容器 docker start elasticsearch-head 通过浏览器进行访问： 注意： 由于前后端分离开发，所以会存在跨域问题，需要在服务端做CORS的配置，如下： vim elasticsearch.yml http.cors.enabled: true http.cors.allow-origin: \"*\" 通过chrome插件的方式安装不存在该问题 通过Chrome插件安装 打开chrome的应用商店，即可安装 https://chrome.google.com/webstore/detail/elasticsearch-head/ffmkiejjmecolpfloofpjologoblkegm 我们也可以新建索引 建议：推荐使用chrome插件的方式安装，如果网络环境不允许，就采用其它方式安装。 ElasticSearch中的基本概念 索引 索引（index）是Elasticsearch对逻辑数据的逻辑存储，所以它可以分为更小的部分。 可以把索引看成关系型数据库的表，索引的结构是为快速有效的全文索引准备的，特别是它不存储原始值。 Elasticsearch可以把索引存放在一台机器或者分散在多台服务器上，每个索引有一或多个分片（shard），每个分片可以有多个副本（replica）。 文档 存储在Elasticsearch中的主要实体叫文档（document）。用关系型数据库来类比的话，一个文档相当于数据库表中的一行记录。 Elasticsearch和MongoDB中的文档类似，都可以有不同的结构，但Elasticsearch的文档中，相同字段必须有相同类型。 文档由多个字段组成，每个字段可能多次出现在一个文档里，这样的字段叫多值字段（multivalued）。 每个字段的类型，可以是文本、数值、日期等。字段类型也可以是复杂类型，一个字段包含其他子文档或者数 组。 映射 所有文档写进索引之前都会先进行分析，如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做 映射（mapping）。一般由用户自己定义规则。 文档类型 在Elasticsearch中，一个索引对象可以存储很多不同用途的对象。例如，一个博客应用程序可以保存文章和评 论。 每个文档可以有不同的结构。 不同的文档类型不能为相同的属性设置不同的类型。例如，在同一索引中的所有文档类型中，一个叫title的字段必须具有相同的类型。 RESTful API 在Elasticsearch中，提供了功能丰富的RESTful API的操作，包括基本的CRUD、创建索引、删除索引等操作。 创建非结构化索引 在Lucene中，创建索引是需要定义字段名称以及字段的类型的，在Elasticsearch中提供了非结构化的索引，就是不需要创建索引结构，即可写入数据到索引中，实际上在Elasticsearch底层会进行结构化操作，此操作对用户是透明的。 创建空索引 PUT /haoke { \"settings\": { \"index\": { \"number_of_shards\": \"2\", #分片数 \"number_of_replicas\": \"0\" #副本数 } } } 删除索引 #删除索引 DELETE /haoke { \"acknowledged\": true } 插入数据 URL规则： POST /{索引}/{类型}/{id} POST /haoke/user/1001 #数据 { \"id\":1001, \"name\":\"张三\", \"age\":20, \"sex\":\"男\" } 使用postman操作成功后 我们通过ElasticSearchHead进行数据预览就能够看到我们刚刚插入的数据了 说明：非结构化的索引，不需要事先创建，直接插入数据默认创建索引。不指定id插入数据： 更新数据 在Elasticsearch中，文档数据是不为修改的，但是可以通过覆盖的方式进行更新。 PUT /haoke/user/1001 { \"id\":1001, \"name\":\"张三\", \"age\":21, \"sex\":\"女\" } 更新结果如下： 可以看到数据已经被覆盖了。问题来了，可以局部更新吗？ -- 可以的。前面不是说，文档数据不能更新吗？ 其实是这样的：在内部，依然会查询到这个文档数据，然后进行覆盖操作，步骤如下： 从旧文档中检索JSON 修改它 删除旧文档 索引新文档 #注意：这里多了_update标识 POST /haoke/user/1001/_update { \"doc\":{ \"age\":23 } } 可以看到，数据已经是局部更新了 删除索引 在Elasticsearch中，删除文档数据，只需要发起DELETE请求即可，不用额外的参数 DELETE 1 /haoke/user/1001 需要注意的是，result表示已经删除，version也增加了。 如果删除一条不存在的数据，会响应404 删除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch将会在你之后添加更多索引的时候才会在后台进行删除内容的清理。【相当于批量操作】 搜索数据 根据id搜索数据 GET /haoke/user/BbPe_WcB9cFOnF3uebvr #返回的数据如下 { \"_index\": \"haoke\", \"_type\": \"user\", \"_id\": \"BbPe_WcB9cFOnF3uebvr\", \"_version\": 8, \"found\": true, \"_source\": { #原始数据在这里 \"id\": 1002, \"name\": \"李四\", \"age\": 40, \"sex\": \"男\" } } 搜索全部数据 GET 1 /haoke/user/_search 注意，使用查询全部数据的时候，默认只会返回10条 关键字搜索数据 #查询年龄等于20的用户 GET /haoke/user/_search?q=age:20 结果如下： DSL搜索 Elasticsearch提供丰富且灵活的查询语言叫做DSL查询(Query DSL),它允许你构建更加复杂、强大的查询。 DSL(Domain Specific Language特定领域语言)以JSON请求体的形式出现。 POST /haoke/user/_search #请求体 { \"query\" : { \"match\" : { #match只是查询的一种 \"age\" : 20 } } } 实现：查询年龄大于30岁的男性用户。 POST /haoke/user/_search #请求数据 { \"query\": { \"bool\": { \"filter\": { \"range\": { \"age\": { \"gt\": 30 } } }, \"must\": { \"match\": { \"sex\": \"男\" } } } } } 查询出来的结果 全文搜索 POST /haoke/user/_search #请求数据 { \"query\": { \"match\": { \"name\": \"张三 李四\" } } } 高亮显示，只需要在添加一个 highlight即可 POST /haoke/user/_search #请求数据 { \"query\": { \"match\": { \"name\": \"张三 李四\" } } \"highlight\": { \"fields\": { \"name\": {} } } } 聚合 在Elasticsearch中，支持聚合操作，类似SQL中的group by操作。 POST /haoke/user/_search { \"aggs\": { \"all_interests\": { \"terms\": { \"field\": \"age\" } } } } 结果如下，我们通过年龄进行聚合 从结果可以看出，年龄30的有2条数据，20的有一条，40的一条。 ElasticSearch核心详解 文档 在Elasticsearch中，文档以JSON格式进行存储，可以是复杂的结构，如： { \"_index\": \"haoke\", \"_type\": \"user\", \"_id\": \"1005\", \"_version\": 1, \"_score\": 1, \"_source\": { \"id\": 1005, \"name\": \"孙七\", \"age\": 37, \"sex\": \"女\", \"card\": { \"card_number\": \"123456789\" } } } 其中，card是一个复杂对象，嵌套的Card对象 元数据（metadata） 一个文档不只有数据。它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是： index 索引(index)类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方。 提示：事实上，我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空间。然而，这只是一些内部细节——我们的程序完全不用关心分片。对于我们的程序而言，文档存储在索引(index)中。剩下的细节由Elasticsearch关心既可。 _type 在应用中，我们使用对象表示一些“事物”，例如一个用户、一篇博客、一个评论，或者一封邮件。每个对象都属于一个类(class)，这个类定义了属性或与对象关联的数据。user 类的对象可能包含姓名、性别、年龄和Email地址。 在关系型数据库中，我们经常将相同类的对象存储在一个表里，因为它们有着相同的结构。同理，在Elasticsearch 中，我们使用相同类型(type)的文档表示相同的“事物”，因为他们的数据结构也是相同的。 每个类型(type)都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储在同一个索引下，但是类型的映射(mapping)会告诉Elasticsearch不同的文档如何被索引。 _type 的名字可以是大写或小写，不能包含下划线或逗号。我们将使用blog 做为类型名。 _id id仅仅是一个字符串，它与_index 和_type 组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文 档，你可以自定义_id ，也可以让Elasticsearch帮你自动生成（32位长度） 查询响应 pretty 可以在查询url后面添加pretty参数，使得返回的json更易查看。 指定响应字段 在响应的数据中，如果我们不需要全部的字段，可以指定某些需要的字段进行返回。通过添加 _source GET /haoke/user/1005?_source=id,name #响应 { \"_index\": \"haoke\", \"_type\": \"user\", \"_id\": \"1005\", \"_version\": 1, \"found\": true, \"_source\": { \"name\": \"孙七\", \"id\": 1005 } } 如不需要返回元数据，仅仅返回原始数据，可以这样： GET /haoke/1 user/1005/_source 还可以这样： GET /haoke/user/1005/_source?_1 source=id,name 判断文档是否存在 如果我们只需要判断文档是否存在，而不是查询文档内容，那么可以这样： HEAD /haoke/user/1005 通过发送一个head请求，来判断数据是否存在 HEAD 1 /haoke/user/1006 当然，这只表示你在查询的那一刻文档不存在，但并不表示几毫秒后依旧不存在。另一个进程在这期间可能创建新文档。 批量操作 有些情况下可以通过批量操作以减少网络请求。如：批量查询、批量插入数据。 批量查询 POST /haoke/user/_mget { \"ids\" : [ \"1001\", \"1003\" ] } 结果： 如果，某一条数据不存在，不影响整体响应，需要通过found的值进行判断是否查询到数据。 POST /haoke/user/_mget { \"ids\" : [ \"1001\", \"1006\" ] } 结果： 也就是说，一个数据的存在不会影响其它数据的返回 _bulk操作 在Elasticsearch中，支持批量的插入、修改、删除操作，都是通过_bulk的api完成的。 请求格式如下：（请求格式不同寻常） { action: { metadata }} { request body } { action: { metadata }} { request body } ... 批量插入数据： {\"create\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2001}} {\"id\":2001,\"name\":\"name1\",\"age\": 20,\"sex\": \"男\"} {\"create\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2002}} {\"id\":2002,\"name\":\"name2\",\"age\": 20,\"sex\": \"男\"} {\"create\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2003}} {\"id\":2003,\"name\":\"name3\",\"age\": 20,\"sex\": \"男\"} 注意最后一行的回车。 批量删除： {\"delete\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2001}} {\"delete\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2002}} {\"delete\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2003}} 由于delete没有请求体，所以，action的下一行直接就是下一个action。 其他操作就类似了。一次请求多少性能最高？ 整个批量请求需要被加载到接受我们请求节点的内存里，所以请求越大，给其它请求可用的内存就越小。有一 个最佳的bulk请求大小。超过这个大小，性能不再提升而且可能降低。 最佳大小，当然并不是一个固定的数字。它完全取决于你的硬件、你文档的大小和复杂度以及索引和搜索的负 载。 幸运的是，这个最佳点(sweetspot)还是容易找到的：试着批量索引标准的文档，随着大小的增长，当性能开始 降低，说明你每个批次的大小太大了。开始的数量可以在1000~5000个文档之间，如果你的文档非常大，可以使用较小的批次。 通常着眼于你请求批次的物理大小是非常有用的。一千个1kB的文档和一千个1MB的文档大不相同。一个好的 批次最好保持在5-15MB大小间。 分页 和SQL使用LIMIT 关键字返回只有一页的结果一样，Elasticsearch接受from 和size 参数： size: 结果数，默认10 from: 跳过开始的结果数，默认0 如果你想每页显示5个结果，页码从1到3，那请求如下： GET /_search?size=5 GET /_search?size=5&from=5 GET /_search?size=5&from=10 应该当心分页太深或者一次请求太多的结果。结果在返回前会被排序。但是记住一个搜索请求常常涉及多个分 片。每个分片生成自己排好序的结果，它们接着需要集中起来排序以确保整体排序正确。 GET /haoke/user/_1 search?size=1&from=2 在集群系统中深度分页 为了理解为什么深度分页是有问题的，让我们假设在一个有5个主分片的索引中搜索。当我们请求结果的第一 页（结果1到10）时，每个分片产生自己最顶端10个结果然后返回它们给请求节点(requesting node)，它再 排序这所有的50个结果以选出顶端的10个结果。 现在假设我们请求第1000页——结果10001到10010。工作方式都相同，不同的是每个分片都必须产生顶端的 10010个结果。然后请求节点排序这50050个结果并丢弃50040个！ 你可以看到在分布式系统中，排序结果的花费随着分页的深入而成倍增长。这也是为什么网络搜索引擎中任何 语句不能返回多于1000个结果的原因。 映射 前面我们创建的索引以及插入数据，都是由Elasticsearch进行自动判断类型，有些时候我们是需要进行明确字段类型的，否则，自动判断的类型和实际需求是不相符的。 自动判断的规则如下： Elasticsearch中支持的类型如下： string类型在ElasticSearch 旧版本中使用较多，从ElasticSearch 5.x开始不再支持string，由text和 keyword类型替代。 text 类型，当一个字段是要被全文搜索的，比如Email内容、产品描述，应该使用text类型。设置text类型 以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段 不用于排序，很少用于聚合。 keyword类型适用于索引结构化的字段，比如email地址、主机名、状态码和标签。如果字段需要进行过 滤(比如查找已发布博客中status属性为published的文章)、排序、聚合。keyword类型的字段只能通过精 确值搜索到。 创建明确类型的索引： 如果你要像之前旧版版本一样兼容自定义 type ,需要将 *i*nclude_type_name=true 携带 put http://202.193.56.222:9200/itcast?include_type_name=true { \"settings\":{ \"index\":{ \"number_of_shards\":\"2\", \"number_of_replicas\":\"0\" } }, \"mappings\":{ \"person\":{ \"properties\":{ \"name\":{ \"type\":\"text\" }, \"age\":{ \"type\":\"integer\" }, \"mail\":{ \"type\":\"keyword\" }, \"hobby\":{ \"type\":\"text\" } } } } } 查看映射 GET /itcast/_mapping 插入数据 POST /itcast/_bulk {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"张三\",\"age\": 20,\"mail\": \"111@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"李四\",\"age\": 21,\"mail\": \"222@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球、篮球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"王五\",\"age\": 22,\"mail\": \"333@qq.com\",\"hobby\":\"羽毛球、篮球、游泳、听音乐\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"赵六\",\"age\": 23,\"mail\": \"444@qq.com\",\"hobby\":\"跑步、游泳\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影\"} 测试搜索 POST /itcast/person/_search { \"query\":{ \"match\":{ \"hobby\":\"音乐\" } } } 结构化查询 term查询 term 主要用于精确匹配哪些值，比如数字，日期，布尔值或 not_analyzed 的字符串(未经分析的文本数据类型)： { \"term\": { \"age\": 26 }} { \"term\": { \"date\": \"2014-09-01\" }} { \"term\": { \"public\": true }} { \"term\": { \"tag\": \"full_text\" }} 示例 POST /itcast/person/_search { \"query\":{ \"term\":{ \"age\":20 } } } terms查询 terms 跟 term 有点类似，但 terms 允许指定多个匹配条件。 如果某个字段指定了多个值，那么文档需要一起去 做匹配： { \"terms\":{ \"tag\":[ \"search\", \"full_text\", \"nosql\" ] } } 示例： POST /itcast/person/_search { \"query\":{ \"terms\":{ \"age\":[ 20, 21 ] } } } range查询 range 过滤允许我们按照指定范围查找一批数据： { \"range\":{ \"age\":{ \"gte\":20, \"lt\":30 } } } 范围操作符包含： gt : 大于 gte:: 大于等于 lt : 小于 lte: 小于等于 示例： POST /itcast/person/_search { \"query\":{ \"range\":{ \"age\":{ \"gte\":20, \"lte\":22 } } } } exists 查询 exists 查询可以用于查找文档中是否包含指定字段或没有某个字段，类似于SQL语句中的IS_NULL 条件 { \"exists\": { \"field\": \"title\" } } 这两个查询只是针对已经查出一批数据来，但是想区分出某个字段是否存在的时候使用。示例： POST /haoke/user/_search { \"query\": { \"exists\": { #必须包含 \"field\": \"card\" } } } match查询 match 查询是一个标准查询，不管你需要全文本查询还是精确查询基本上都要用到它。 如果你使用 match 查询一个全文本字段，它会在真正查询之前用分析器先分析match 一下查询字符： { \"match\": { \"tweet\": \"About Search\" } } 如果用match 下指定了一个确切值，在遇到数字，日期，布尔值或者not_analyzed 的字符串时，它将为你搜索你 给定的值： { \"match\": { \"age\": 26 }} { \"match\": { \"date\": \"2014-09-01\" }} { \"match\": { \"public\": true }} { \"match\": { \"tag\": \"full_text\" }} bool查询 bool 查询可以用来合并多个条件查询结果的布尔逻辑，它包含一下操作符： must :: 多个查询条件的完全匹配,相当于 and 。 must_not :: 多个查询条件的相反匹配，相当于 not 。 should :: 至少有一个查询条件匹配, 相当于 or 。 这些参数可以分别继承一个查询条件或者一个查询条件的数组： { \"bool\":{ \"must\":{ \"term\":{ \"folder\":\"inbox\" } }, \"must_not\":{ \"term\":{ \"tag\":\"spam\" } }, \"should\":[ { \"term\":{ \"starred\":true } }, { \"term\":{ \"unread\":true } } ] } } 过滤查询 前面讲过结构化查询，Elasticsearch也支持过滤查询，如term、range、match等。 示例：查询年龄为20岁的用户。 POST /itcast/person/_search { \"query\":{ \"bool\":{ \"filter\":{ \"term\":{ \"age\":20 } } } } } 查询和过滤的对比 一条过滤语句会询问每个文档的字段值是否包含着特定值。 查询语句会询问每个文档的字段值与特定值的匹配程度如何。 一条查询语句会计算每个文档与查询语句的相关性，会给出一个相关性评分 _score，并且 按照相关性对匹 配到的文档进行排序。 这种评分方式非常适用于一个没有完全配置结果的全文本搜索。 一个简单的文档列表，快速匹配运算并存入内存是十分方便的， 每个文档仅需要1个字节。这些缓存的过滤结果集与后续请求的结合使用是非常高效的。 查询语句不仅要查找相匹配的文档，还需要计算每个文档的相关性，所以一般来说查询语句要比 过滤语句更耗时，并且查询结果也不可缓存。 建议： 做精确匹配搜索时，最好用过滤语句，因为过滤语句可以缓存数据。 中文分词 什么是分词 分词就是指将一个文本转化成一系列单词的过程，也叫文本分析，在Elasticsearch中称之为Analysis。 举例：我是中国人 --> 我/是/中国人 分词api 指定分词器进行分词 POST /_analyze { \"analyzer\":\"standard\", \"text\":\"hello world\" } 结果如下 在结果中不仅可以看出分词的结果，还返回了该词在文本中的位置。 指定索引分词 POST /itcast/_analyze { \"analyzer\": \"standard\", \"field\": \"hobby\", \"text\": \"听音乐\" } 中文分词难点 中文分词的难点在于，在汉语中没有明显的词汇分界点，如在英语中，空格可以作为分隔符，如果分隔不正确就会造成歧义。如： 我/爱/炒肉丝 我/爱/炒/肉丝 常用中文分词器，IK、jieba、THULAC等，推荐使用IK分词器。 IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算法的中文分词组件。新版本的IK Analyzer 3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提供了对Lucene的默认优化实现。 采用了特有的“正向迭代最细粒度切分算法“，具有80万字/秒的高速处理能力 采用了多子处理器分析模式，支持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇（姓名、地名处理）等分词处理。 优化的词典存储，更小的内存占用。 IK分词器 Elasticsearch插件地址：https://github.com/medcl/elasticsearch-analysis-ik 安装分词器 首先下载到最新的ik分词器：下载地址 下载完成后，使用xftp工具，拷贝到服务器上 #安装方法：将下载到的 es/plugins/ik 目录下 mkdir es/plugins/ik #解压 unzip elasticsearch-analysis-ik-7.9.1.zip #重启 ./bin/elasticsearch 我们通过日志，发现它已经成功加载了ik分词器插件 测试 POST /_analyze { \"analyzer\": \"ik_max_word\", \"text\": \"我是中国人\" } 我们发现ik分词器已经成功分词完成 全文搜索 全文搜索两个最重要的方面是： 相关性（Relevance） 它是评价查询与其结果间的相关程度，并根据这种相关程度对结果排名的一种能力，这 种计算方式可以是 TF/IDF 方法、地理位置邻近、模糊相似，或其他的某些算法。 分词（Analysis） 它是将文本块转换为有区别的、规范化的 token 的一个过程，目的是为了创建倒排索引以及查询倒排索引。 构造数据 ES 7.4 默认不在支持指定索引类型，默认索引类型是_doc http://202.193.56.222:9200/itcast?include_type_name=true { \"settings\":{ \"index\":{ \"number_of_shards\":\"1\", \"number_of_replicas\":\"0\" } }, \"mappings\":{ \"person\":{ \"properties\":{ \"name\":{ \"type\":\"text\" }, \"age\":{ \"type\":\"integer\" }, \"mail\":{ \"type\":\"keyword\" }, \"hobby\":{ \"type\":\"text\", \"analyzer\":\"ik_max_word\" } } } } } 然后插入数据 POST http://202.193.56.222:9200/itcast/_bulk {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"张三\",\"age\": 20,\"mail\": \"111@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"李四\",\"age\": 21,\"mail\": \"222@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球、篮球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"王五\",\"age\": 22,\"mail\": \"333@qq.com\",\"hobby\":\"羽毛球、篮球、游泳、听音乐\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"赵六\",\"age\": 23,\"mail\": \"444@qq.com\",\"hobby\":\"跑步、游泳、篮球\"} {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}} {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影、羽毛球\"} 单词搜索 POST /itcast/person/_search { \"query\":{ \"match\":{ \"hobby\":\"音乐\" } }, \"highlight\":{ \"fields\":{ \"hobby\":{ } } } } 查询出来的结果如下，并且还带有高亮 过程说明： 检查字段类型 爱好 hobby 字段是一个 text 类型（ 指定了IK分词器），这意味着查询字符串本身也应该被分词。 分析查询字符串 。 将查询的字符串 “音乐” 传入IK分词器中，输出的结果是单个项 音乐。因为只有一个单词项，所以 match 查询执行的是单个底层 term 查询。 查找匹配文档 。 用 term 查询在倒排索引中查找 “音乐” 然后获取一组包含该项的文档，本例的结果是文档：3 、5 。 为每个文档评分 。 用 term 查询计算每个文档相关度评分 _score ，这是种将 词频（term frequency，即词 “音乐” 在相关文档的hobby 字段中出现的频率）和 反向文档频率（inverse document frequency，即词 “音乐” 在所有文档的hobby 字段中出现的频率），以及字段的长度（即字段越短相关度越高）相结合的计算方式。 多词搜索 POST /itcast/person/_search { \"query\":{ \"match\":{ \"hobby\":\"音乐 篮球\" } }, \"highlight\":{ \"fields\":{ \"hobby\":{ } } } } 可以看到，包含了“音乐”、“篮球”的数据都已经被搜索到了。可是，搜索的结果并不符合我们的预期，因为我们想搜索的是既包含“音乐”又包含“篮球”的用户，显然结果返回的“或”的关系。在Elasticsearch中，可以指定词之间的逻辑关系，如下： POST /itcast/person/_search { \"query\":{ \"match\":{ \"hobby\":\"音乐 篮球\" \"operator\":\"and\" } }, \"highlight\":{ \"fields\":{ \"hobby\":{ } } } } 通过这样的话，就会让两个关键字之间存在and关系了 可以看到结果符合预期。 前面我们测试了“OR” 和 “AND”搜索，这是两个极端，其实在实际场景中，并不会选取这2个极端，更有可能是选取这种，或者说，只需要符合一定的相似度就可以查询到数据，在Elasticsearch中也支持这样的查询，通过 minimum_should_match来指定匹配度，如：70%； 示例： { \"query\":{ \"match\":{ \"hobby\":{ \"query\":\"游泳 羽毛球\", \"minimum_should_match\":\"80%\" } } }, \"highlight\": { \"fields\": { \"hobby\": {} } } } #结果：省略显示 \"hits\": { \"total\": 4, #相似度为80%的情况下，查询到4条数据 \"max_score\": 1.621458, \"hits\": [ } #设置40%进行测试： { \"query\":{ \"match\":{ \"hobby\":{ \"query\":\"游泳 羽毛球\", \"minimum_should_match\":\"40%\" } } }, \"highlight\": { \"fields\": { \"hobby\": {} } } } #结果： \"hits\": { \"total\": 5, #相似度为40%的情况下，查询到5条数据 \"max_score\": 1.621458, \"hits\": [ } 相似度应该多少合适，需要在实际的需求中进行反复测试，才可得到合理的值。 组合搜索 在搜索时，也可以使用过滤器中讲过的bool组合查询，示例： POST /itcast/person/_search { \"query\":{ \"bool\":{ \"must\":{ \"match\":{ \"hobby\":\"篮球\" } }, \"must_not\":{ \"match\":{ \"hobby\":\"音乐\" } }, \"should\":[ { \"match\":{ \"hobby\":\"游泳\" } } ] } }, \"highlight\":{ \"fields\":{ \"hobby\":{ } } } } 上面搜索的意思是： 搜索结果中必须包含篮球，不能包含音乐，如果包含了游泳，那么它的相似度更高。 结果： 评分的计算规则 bool 查询会为每个文档计算相关度评分 _score ， 再将所有匹配的 must 和 should 语句的分数 _score 求和，最后除以 must 和 should 语句的总数。 must_not 语句不会影响评分； 它的作用只是将不相关的文档排除。 默认情况下，should中的内容不是必须匹配的，如果查询语句中没有must，那么就会至少匹配其中一个。当然了，也可以通过minimum_should_match参数进行控制，该值可以是数字也可以的百分比。 示例： POST /itcast/person/_search { \"query\":{ \"bool\":{ \"should\":[ { \"match\":{ \"hobby\":\"游泳\" } }, { \"match\":{ \"hobby\":\"篮球\" } }, { \"match\":{ \"hobby\":\"音乐\" } } ], \"minimum_should_match\":2 } }, \"highlight\":{ \"fields\":{ \"hobby\":{ } } } } minimum_should_match为2，意思是should中的三个词，至少要满足2个。 权重 有些时候，我们可能需要对某些词增加权重来影响该条数据的得分。如下： 搜索关键字为“游泳篮球”，如果结果中包含了“音乐”权重为10，包含了“跑步”权重为2。 POST /itcast/person/_search { \"query\":{ \"bool\":{ \"must\":{ \"match\":{ \"hobby\":{ \"query\":\"游泳篮球\", \"operator\":\"and\" } } }, \"should\":[ { \"match\":{ \"hobby\":{ \"query\":\"音乐\", \"boost\":10 } } }, { \"match\":{ \"hobby\":{ \"query\":\"跑步\", \"boost\":2 } } } ] } }, \"highlight\":{ \"fields\":{ \"hobby\":{ } } } } ElasticSearch集群 集群节点 ELasticsearch的集群是由多个节点组成的，通过cluster.name设置集群名称，并且用于区分其它的集群，每个节点通过node.name指定节点的名称。 在Elasticsearch中，节点的类型主要有4种： master节点 配置文件中node.master属性为true(默认为true)，就有资格被选为master节点。master节点用于控制整个集群的操作。比如创建或删除索引，管理其它非master节点等。 data节点 配置文件中node.data属性为true(默认为true)，就有资格被设置成data节点。data节点主要用于执行数据相关的操作。比如文档的CRUD。 客户端节点 配置文件中node.master属性和node.data属性均为false。 该节点不能作为master节点，也不能作为data节点。 可以作为客户端节点，用于响应用户的请求，把请求转发到其他节点 部落节点 当一个节点配置tribe.*的时候，它是一个特殊的客户端，它可以连接多个集群，在所有连接的集群上执行 搜索和其他操作。 搭建集群 #启动3个虚拟机，分别在3台虚拟机上部署安装Elasticsearch mkdir /itcast/es-cluster #分发到其它机器 scp -r es-cluster elsearch@192.168.40.134:/itcast #node01的配置： cluster.name: es-itcast-cluster node.name: node01 node.master: true node.data: true network.host: 0.0.0.0 http.port: 9200 discovery.zen.ping.unicast.hosts: [\"192.168.40.133\",\"192.168.40.134\",\"192.168.40.135\"] # 最小节点数 discovery.zen.minimum_master_nodes: 2 # 跨域专用 http.cors.enabled: true http.cors.allow-origin: \"*\" #node02的配置： cluster.name: es-itcast-cluster node.name: node02 node.master: true node.data: true network.host: 0.0.0.0 http.port: 9200 discovery.zen.ping.unicast.hosts: [\"192.168.40.133\",\"192.168.40.134\",\"192.168.40.135\"] discovery.zen.minimum_master_nodes: 2 http.cors.enabled: true http.cors.allow-origin: \"*\" #node03的配置： cluster.name: es-itcast-cluster node.name: node02 node.master: true node.data: true network.host: 0.0.0.0 http.port: 9200 discovery.zen.ping.unicast.hosts: [\"192.168.40.133\",\"192.168.40.134\",\"192.168.40.135\"] discovery.zen.minimum_master_nodes: 2 http.cors.enabled: true http.cors.allow-origin: \"*\" #分别启动3个节点 ./elasticsearch 查看集群 创建索引： 查询集群状态：/_cluster/health 响应： 集群中有三种颜色 分片和副本 为了将数据添加到Elasticsearch，我们需要索引(index)——一个存储关联数据的地方。实际上，索引只是一个用来指向一个或多个分片(shards)的“逻辑命名空间(logical namespace)”. 一个分片(shard)是一个最小级别“工作单元(worker unit)”,它只是保存了索引中所有数据的一部分。 我们需要知道是分片就是一个Lucene实例，并且它本身就是一个完整的搜索引擎。应用程序不会和它直接通 信。 分片可以是主分片(primary shard)或者是复制分片(replica shard)。 索引中的每个文档属于一个单独的主分片，所以主分片的数量决定了索引最多能存储多少数据。 复制分片只是主分片的一个副本，它可以防止硬件故障导致的数据丢失，同时可以提供读请求，比如搜索或者从别的shard取回文档。 当索引创建完成的时候，主分片的数量就固定了，但是复制分片的数量可以随时调整。 故障转移 将data节点停止 这里选择将node02停止： 当前集群状态为黄色，表示主节点可用，副本节点不完全可用，过一段时间观察，发现节点列表中看不到node02，副本节点分配到了node01和node03，集群状态恢复到绿色。 将node02恢复： ./node02/1 bin/elasticsearch 可以看到，node02恢复后，重新加入了集群，并且重新分配了节点信息。 将master节点停止 接下来，测试将node01停止，也就是将主节点停止。 从结果中可以看出，集群对master进行了重新选举，选择node03为master。并且集群状态变成黄色。 等待一段时间后，集群状态从黄色变为了绿色： 恢复node01节点： ./node01/1 bin/elasticsearch 重启之后，发现node01可以正常加入到集群中，集群状态依然为绿色： 特别说明： 如果在配置文件中discovery.zen.minimum_master_nodes设置的不是N/2+1时，会出现脑裂问题，之前宕机 的主节点恢复后不会加入到集群。 分布式文档 路由 首先，来看个问题： 如图所示：当我们想一个集群保存文档时，文档该存储到哪个节点呢？ 是随机吗？ 是轮询吗？实际上，在ELasticsearch中，会采用计算的方式来确定存储到哪个节点，计算公式如下： shard = hash(routing) % number_1 of_primary_shards 其中： routing值是一个任意字符串，它默认是_id但也可以自定义。 这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量得到一个余数(remainder)，余数 的范围永远是0到number_of_primary_shards - 1，这个数字就是特定文档所在的分片 这就是为什么创建了主分片后，不能修改的原因。 文档的写操作 新建、索引和删除请求都是写（write）操作，它们必须在主分片上成功完成才能复制分片上 下面我们罗列在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤： 客户端给Node 1 发送新建、索引或删除请求。 节点使用文档的_id 确定文档属于分片0 。它转发请求到Node 3 ，分片0 位于这个节点上。 Node 3 在主分片上执行请求，如果成功，它转发请求到相应的位于Node 1 和Node 2 的复制节点上。当所有 的复制节点报告成功， Node 3 报告成功到请求的节点，请求的节点再报告给客户端。 客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。你的修改生效了。 搜索文档 文档能够从主分片或任意一个复制分片被检索。 下面我们罗列在主分片或复制分片上检索一个文档必要的顺序步骤： 客户端给Node 1 发送get请求。 节点使用文档的_id 确定文档属于分片0 。分片0 对应的复制分片在三个节点上都有。此时，它转发请求到 Node 2 。 Node 2 返回文档(document)给Node 1 然后返回给客户端。对于读请求，为了平衡负载，请求节点会为每个请求选择不同的分片——它会循环所有分片副本。可能的情况是，一个被索引的文档已经存在于主分片上却还没来得及同步到复制分片上。这时复制分片会报告文档未找到，主分片会成功返回文档。一旦索引请求成功返回给用户，文档则在主分片和复制分片都是可用的。 全文搜索 对于全文搜索而言，文档可能分散在各个节点上，那么在分布式的情况下，如何搜索文档呢？ 搜索，分为2个阶段， 搜索（query） 取回（fetch） 搜索（query） 查询阶段包含以下三步： 客户端发送一个search（搜索） 请求给Node 3 , Node 3 创建了一个长度为from+size 的空优先级队 Node 3 转发这个搜索请求到索引中每个分片的原本或副本。每个分片在本地执行这个查询并且结果将结果到 一个大小为from+size 的有序本地优先队列里去。 每个分片返回document的ID和它优先队列里的所有document的排序值给协调节点Node 3 。Node 3 把这些 值合并到自己的优先队列里产生全局排序结果。 取回 fetch 分发阶段由以下步骤构成： 协调节点辨别出哪个document需要取回，并且向相关分片发出GET 请求。 每个分片加载document并且根据需要丰富（enrich）它们，然后再将document返回协调节点。 一旦所有的document都被取回，协调节点会将结果返回给客户端。 Java客户端 在Elasticsearch中，为java提供了2种客户端，一种是REST风格的客户端，另一种是Java API的客户端 REST客户端 Elasticsearch提供了2种REST客户端，一种是低级客户端，一种是高级客户端。 Java Low Level REST Client：官方提供的低级客户端。该客户端通过http来连接Elasticsearch集群。用户在使 用该客户端时需要将请求数据手动拼接成Elasticsearch所需JSON格式进行发送，收到响应时同样也需要将返回的JSON数据手动封装成对象。虽然麻烦，不过该客户端兼容所有的Elasticsearch版本。 Java High Level REST Client：官方提供的高级客户端。该客户端基于低级客户端实现，它提供了很多便捷的 API来解决低级客户端需要手动转换数据格式的问题。 构造数据 POST /haoke/house/_bulk {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}} {\"id\":\"1001\",\"title\":\"整租 · 南丹大楼 1居室 7500\",\"price\":\"7500\"} {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}} {\"id\":\"1002\",\"title\":\"陆家嘴板块，精装设计一室一厅，可拎包入住诚意租。\",\"price\":\"8500\"} {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}} {\"id\":\"1003\",\"title\":\"整租 · 健安坊 1居室 4050\",\"price\":\"7500\"} {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}} {\"id\":\"1004\",\"title\":\"整租 · 中凯城市之光+视野开阔+景色秀丽+拎包入住\",\"price\":\"6500\"} {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}} {\"id\":\"1005\",\"title\":\"整租 · 南京西路品质小区 21213三轨交汇 配套齐* 拎包入住\",\"price\":\"6000\"} {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}} {\"id\":\"1006\",\"title\":\"祥康里 简约风格 *南户型 拎包入住 看房随时\",\"price\":\"7000\"} REST低级客户端 创建项目，加入依赖 4.0.0 org.example Study_ElasticSearch_Code 1.0-SNAPSHOT org.apache.maven.plugins maven-compiler-plugin 7 7 org.elasticsearch.client elasticsearch-rest-client 6.8.5 junit junit 4.12 test com.fasterxml.jackson.core jackson-databind 2.11.1 编写测试类 import com.fasterxml.jackson.core.JsonProcessingException; import com.fasterxml.jackson.databind.ObjectMapper; import org.apache.http.HttpHost; import org.apache.http.util.EntityUtils; import org.elasticsearch.client.Request; import org.elasticsearch.client.Response; import org.elasticsearch.client.RestClient; import org.elasticsearch.client.RestClientBuilder; import java.io.IOException; import java.util.HashMap; import java.util.Map; /** * 使用低级客户端 访问 * * @author: 陌溪 * @create: 2020-09-23-16:33 */ public class ESApi { private RestClient restClient; private static final ObjectMapper MAPPER = new ObjectMapper(); /** * 初始化 */ public void init() { RestClientBuilder restClientBuilder = RestClient.builder(new HttpHost(\"202.193.56.222\", 9200, \"http\")); this.restClient = restClientBuilder.build(); } /** * 查询集群状态 */ public void testGetInfo() throws IOException { Request request = new Request(\"GET\", \"/_cluster/state\"); request.addParameter(\"pretty\", \"true\"); Response response = this.restClient.performRequest(request); System.out.println(response.getStatusLine()); System.out.println(EntityUtils.toString(response.getEntity())); } /** * 根据ID查询数据 * @throws IOException */ public void testGetHouseInfo() throws IOException { Request request = new Request(\"GET\", \"/haoke/house/Z3CduXQBYpWein3CRFug\"); request.addParameter(\"pretty\", \"true\"); Response response = this.restClient.performRequest(request); System.out.println(response.getStatusLine()); System.out.println(EntityUtils.toString(response.getEntity())); } public void testCreateData() throws IOException { Request request = new Request(\"POST\", \"/haoke/house\"); Map data = new HashMap<>(); data.put(\"id\", \"2001\"); data.put(\"title\", \"张江高科\"); data.put(\"price\", \"3500\"); // 写成JSON request.setJsonEntity(MAPPER.writeValueAsString(data)); Response response = this.restClient.performRequest(request); System.out.println(response.getStatusLine()); System.out.println(EntityUtils.toString(response.getEntity())); } // 搜索数据 public void testSearchData() throws IOException { Request request = new Request(\"POST\", \"/haoke/house/_search\"); String searchJson = \"{\\\"query\\\": {\\\"match\\\": {\\\"title\\\": \\\"拎包入住\\\"}}}\"; request.setJsonEntity(searchJson); request.addParameter(\"pretty\",\"true\"); Response response = this.restClient.performRequest(request); System.out.println(response.getStatusLine()); System.out.println(EntityUtils.toString(response.getEntity())); } public static void main(String[] args) throws IOException { ESApi esApi = new ESApi(); esApi.init(); // esApi.testGetInfo(); // esApi.testGetHouseInfo(); esApi.testCreateData(); } } REST高级客户端 创建项目，引入依赖 org.elasticsearch.client elasticsearch-rest-high-level-client 6.8.5 编写测试用例 import com.fasterxml.jackson.databind.ObjectMapper; import org.apache.http.HttpHost; import org.apache.http.util.EntityUtils; import org.elasticsearch.action.ActionListener; import org.elasticsearch.action.delete.DeleteRequest; import org.elasticsearch.action.delete.DeleteResponse; import org.elasticsearch.action.get.GetRequest; import org.elasticsearch.action.get.GetResponse; import org.elasticsearch.action.index.IndexRequest; import org.elasticsearch.action.index.IndexResponse; import org.elasticsearch.action.search.SearchRequest; import org.elasticsearch.action.search.SearchResponse; import org.elasticsearch.action.update.UpdateRequest; import org.elasticsearch.action.update.UpdateResponse; import org.elasticsearch.client.*; import org.elasticsearch.common.Strings; import org.elasticsearch.common.unit.TimeValue; import org.elasticsearch.index.query.QueryBuilders; import org.elasticsearch.search.SearchHit; import org.elasticsearch.search.SearchHits; import org.elasticsearch.search.builder.SearchSourceBuilder; import org.elasticsearch.search.fetch.subphase.FetchSourceContext; import java.io.IOException; import java.util.HashMap; import java.util.Map; import java.util.concurrent.TimeUnit; /** * ES高级客户端 * * @author: 陌溪 * @create: 2020-09-23-16:56 */ public class ESHightApi { private RestHighLevelClient client; public void init() { RestClientBuilder restClientBuilder = RestClient.builder( new HttpHost(\"202.193.56.222\", 9200, \"http\")); this.client = new RestHighLevelClient(restClientBuilder); } public void after() throws Exception { this.client.close(); } /** * 新增文档，同步操作 * * @throws Exception */ public void testCreate() throws Exception { Map data = new HashMap<>(); data.put(\"id\", \"2002\"); data.put(\"title\", \"南京西路 拎包入住 一室一厅\"); data.put(\"price\", \"4500\"); IndexRequest indexRequest = new IndexRequest(\"haoke\", \"house\") .source(data); IndexResponse indexResponse = this.client.index(indexRequest, RequestOptions.DEFAULT); System.out.println(\"id->\" + indexResponse.getId()); System.out.println(\"index->\" + indexResponse.getIndex()); System.out.println(\"type->\" + indexResponse.getType()); System.out.println(\"version->\" + indexResponse.getVersion()); System.out.println(\"result->\" + indexResponse.getResult()); System.out.println(\"shardInfo->\" + indexResponse.getShardInfo()); } /** * 异步创建文档 * @throws Exception */ public void testCreateAsync() throws Exception { Map data = new HashMap<>(); data.put(\"id\", \"2003\"); data.put(\"title\", \"南京东路 最新房源 二室一厅\"); data.put(\"price\", \"5500\"); IndexRequest indexRequest = new IndexRequest(\"haoke\", \"house\") .source(data); this.client.indexAsync(indexRequest, RequestOptions.DEFAULT, new ActionListener() { @Override public void onResponse(IndexResponse indexResponse) { System.out.println(\"id->\" + indexResponse.getId()); System.out.println(\"index->\" + indexResponse.getIndex()); System.out.println(\"type->\" + indexResponse.getType()); System.out.println(\"version->\" + indexResponse.getVersion()); System.out.println(\"result->\" + indexResponse.getResult()); System.out.println(\"shardInfo->\" + indexResponse.getShardInfo()); } @Override public void onFailure(Exception e) { System.out.println(e); } }); System.out.println(\"ok\"); Thread.sleep(20000); } /** * 查询 * @throws Exception */ public void testQuery() throws Exception { GetRequest getRequest = new GetRequest(\"haoke\", \"house\", \"GkpdE2gBCKv8opxuOj12\"); // 指定返回的字段 String[] includes = new String[]{\"title\", \"id\"}; String[] excludes = Strings.EMPTY_ARRAY; FetchSourceContext fetchSourceContext = new FetchSourceContext(true, includes, excludes); getRequest.fetchSourceContext(fetchSourceContext); GetResponse response = this.client.get(getRequest, RequestOptions.DEFAULT); System.out.println(\"数据 -> \" + response.getSource()); } /** * 判断是否存在 * * @throws Exception */ public void testExists() throws Exception { GetRequest getRequest = new GetRequest(\"haoke\", \"house\", \"GkpdE2gBCKv8opxuOj12\"); // 不返回的字段 getRequest.fetchSourceContext(new FetchSourceContext(false)); boolean exists = this.client.exists(getRequest, RequestOptions.DEFAULT); System.out.println(\"exists -> \" + exists); } /** * 删除数据 * * @throws Exception */ public void testDelete() throws Exception { DeleteRequest deleteRequest = new DeleteRequest(\"haoke\", \"house\", \"GkpdE2gBCKv8opxuOj12\"); DeleteResponse response = this.client.delete(deleteRequest, RequestOptions.DEFAULT); System.out.println(response.status());// OK or NOT_FOUND } /** * 更新数据 * * @throws Exception */ public void testUpdate() throws Exception { UpdateRequest updateRequest = new UpdateRequest(\"haoke\", \"house\", \"G0pfE2gBCKv8opxuRz1y\"); Map data = new HashMap<>(); data.put(\"title\", \"张江高科2\"); data.put(\"price\", \"5000\"); updateRequest.doc(data); UpdateResponse response = this.client.update(updateRequest, RequestOptions.DEFAULT); System.out.println(\"version -> \" + response.getVersion()); } /** * 测试搜索 * * @throws Exception */ public void testSearch() throws Exception { SearchRequest searchRequest = new SearchRequest(\"haoke\"); searchRequest.types(\"house\"); SearchSourceBuilder sourceBuilder = new SearchSourceBuilder(); sourceBuilder.query(QueryBuilders.matchQuery(\"title\", \"拎包入住\")); sourceBuilder.from(0); sourceBuilder.size(5); sourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS)); searchRequest.source(sourceBuilder); SearchResponse search = this.client.search(searchRequest, RequestOptions.DEFAULT); System.out.println(\"搜索到 \" + search.getHits().totalHits + \" 条数据.\"); SearchHits hits = search.getHits(); for (SearchHit hit : hits) { System.out.println(hit.getSourceAsString()); } } public static void main(String[] args) throws Exception { ESHightApi esHightApi = new ESHightApi(); esHightApi.init(); esHightApi.testCreate(); } } new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 16:47:08 "},"hm/2_Beats入门简介/":{"url":"hm/2_Beats入门简介/","title":"2_Beats入门简介","keywords":"","body":"Beats入门简介项目需求业务流程部署NginxBeats简介Filebeat介绍为什么要用Filebeat？架构下载启动读取文件自定义字段输出到ElasticSearchFilebeat工作原理input启动命令参数说明读取Nginx中的配置文件ModuleMetricbeatMetricbeat组成下载启动system module配置Metricbeat ModuleNginx Module配置nginx module测试参考Beats入门简介 使用Beat收集nginx日志和指标数据 项目需求 Nginx是一款非常优秀的web服务器，往往nginx服务会作为项目的访问入口，那么，nginx的性能保障就变得非常重要了，如果nginx的运行出现了问题就会对项目有较大的影响，所以，我们需要对nginx的运行有监控措施，实时掌握nginx的运行情况，那就需要收集nginx的运行指标和分析nginx的运行日志了。 业务流程 说明： 通过Beats采集Nginx的指标数据和日志数据 Beats采集到数据后发送到Elasticsearch中 Kibana读取数据进行分析 用户通过Kibana进行查看分析报表 部署Nginx 部署教程可以参考这篇博客：CentOS下如何安装Nginx？ 部署完成后，我们就可以启动nginx了 启动完成后，我们通过下面命令，就可以获取到nginx中的内容了 tail -f /var/log/nginx/access.log Beats简介 通过查看ElasticStack可以发现，Beats主要用于采集数据 官网地址：https://www.elastic.co/cn/beats/ Beats平台其实是一个轻量性数据采集器，通过集合多种单一用途的采集器，从成百上千台机器中向Logstash或ElasticSearch中发送数据。 通过Beats包含以下的数据采集功能 Filebeat：采集日志文件 Metricbeat：采集指标 Packetbeat：采集网络数据 如果我们的数据不需要任何处理，那么就可以直接发送到ElasticSearch中 如果们的数据需要经过一些处理的话，那么就可以发送到Logstash中，然后处理完成后，在发送到ElasticSearch 最后在通过Kibana对我们的数据进行一系列的可视化展示 Filebeat 介绍 Filebeat是一个轻量级的日志采集器 为什么要用Filebeat？ 当你面对成百上千、甚至成千上万的服务器、虚拟机和溶气气生成的日志时，请告别SSH吧！Filebeat将为你提供一种轻量型方法，用于转发和汇总日志与文件，让简单的事情不再繁华，关于Filebeat的记住以下两点： 轻量级日志采集器 输送至ElasticSearch或者Logstash，在Kibana中实现可视化 架构 用于监控、收集服务器日志文件. 流程如下： 首先是input输入，我们可以指定多个数据输入源，然后通过通配符进行日志文件的匹配 匹配到日志后，就会使用Harvester（收割机），将日志源源不断的读取到来 然后收割机收割到的日志，就传递到Spooler（卷轴），然后卷轴就在将他们传到对应的地方 下载 官网地址：https://www.elastic.co/cn/downloads/beats/filebeat 选中对应版本的Filebeat，我这里是Centos部署的，所以下载Linux版本 下载后，我们上传到服务器上，然后创建一个文件夹 # 创建文件夹 mkdir -p /soft/beats # 解压文件 tar -zxvf filebeat-7.9.1-linux-x86_64.tar.gz # 重命名 mv filebeat-7.9.1-linux-x86_64/ filebeat 然后我们进入到filebeat目录下，创建对应的配置文件 # 进入文件夹 cd filebeats # 创建配置文件 vim mogublog.yml 添加如下内容 filebeat.inputs: # filebeat input输入 - type: stdin # 标准输入 enabled: true # 启用标准输入 setup.template.settings: index.number_of_shards: 3 # 指定下载数 output.console: # 控制台输出 pretty: true # 启用美化功能 enable: true 启动 在我们添加完配置文件后，我们就可以对filebeat进行启动了 ./filebeat -e -c mogublog.yml 然后我们在控制台输入hello，就能看到我们会有一个json的输出，是通过读取到我们控制台的内容后输出的 内容如下 { \"@timestamp\":\"2019-01-12T12:50:03.585Z\", \"@metadata\":{ #元数据信息 \"beat\":\"filebeat\", \"type\":\"doc\", \"version\":\"6.5.4\" }, \"source\":\"\", \"offset\":0, \"message\":\"hello\", #元数据信息 \"prospector\":{ \"type\":\"stdin\" #元数据信息 }, \"input\":{ #控制台标准输入 \"type\":\"stdin\" }, \"beat\":{ #beat版本以及主机信息 \"name\":\"itcast01\", \"hostname\":\"ElasticStack\", \"version\":\"6.5.4\" }, \"host\":{ \"name\":\"ElasticStack\" } } 读取文件 我们需要再次创建一个文件，叫 mogublog-log.yml，然后在文件里添加如下内容 filebeat.inputs: - type: log enabled: true paths: - /soft/beats/logs/*.log setup.template.settings: index.number_of_shards: 3 output.console: pretty: true enable: true 添加完成后，我们在到下面目录创建一个日志文件 # 创建文件夹 mkdir -p /soft/beats/logs # 进入文件夹 cd /soft/beats/logs # 追加内容 echo \"hello\" >> a.log 然后我们再次启动filebeat ./filebeat -e -c mogublog-log.yml 能够发现，它已经成功加载到了我们的日志文件 a.log 同时我们还可以继续往文件中追加内容 echo \"are you ok ?\" >> a.log 追加后，我们再次查看filebeat，也能看到刚刚我们追加的内容 可以看出，已经检测到日志文件有更新，立刻就会读取到更新的内容，并且输出到控制台。 自定义字段 但我们的元数据没办法支撑我们的业务时，我们还可以自定义添加一些字段 filebeat.inputs: - type: log enabled: true paths: - /soft/beats/logs/*.log tags: [\"web\", \"test\"] #添加自定义tag，便于后续的处理 fields: #添加自定义字段 from: test-web fields_under_root: true #true为添加到根节点，false为添加到子节点中 setup.template.settings: index.number_of_shards: 3 output.console: pretty: true enable: true 添加完成后，我们重启 filebeat ./filebeat -e -c mogublog-log.yml 然后添加新的数据到 a.log中 echo \"test-web\" >> a.log 我们就可以看到字段在原来的基础上，增加了两个 输出到ElasticSearch 我们可以通过配置，将修改成如下所示 filebeat.inputs: - type: log enabled: true paths: - /soft/beats/logs/*.log tags: [\"web\", \"test\"] fields: from: test-web fields_under_root: false setup.template.settings: index.number_of_shards: 1 output.elasticsearch: hosts: [\"127.0.0.1:9200\"] 启动成功后，我们就能看到它已经成功连接到了es了 然后我们到刚刚的 logs文件夹向 a.log文件中添加内容 echo \"hello mogublog\" >> a.log 在ES中，我们可以看到，多出了一个 filebeat的索引库 然后我们浏览对应的数据，看看是否有插入的数据内容 Filebeat工作原理 Filebeat主要由下面几个组件组成： harvester、prospector 、input harvester 负责读取单个文件的内容 harvester逐行读取每个文件（一行一行读取），并把这些内容发送到输出 每个文件启动一个harvester，并且harvester负责打开和关闭这些文件，这就意味着harvester运行时文件描述符保持着打开的状态。 在harvester正在读取文件内容的时候，文件被删除或者重命名了，那么Filebeat就会续读这个文件，这就会造成一个问题，就是只要负责这个文件的harvester没用关闭，那么磁盘空间就不会被释放，默认情况下，Filebeat保存问价你打开直到close_inactive到达 prospector prospector负责管理harvester并找到所有要读取的文件来源 如果输入类型为日志，则查找器将查找路径匹配的所有文件，并为每个文件启动一个harvester Filebeat目前支持两种prospector类型：log和stdin Filebeat如何保持文件的状态 Filebeat保存每个文件的状态并经常将状态刷新到磁盘上的注册文件中 该状态用于记住harvester正在读取的最后偏移量，并确保发送所有日志行。 如果输出（例如ElasticSearch或Logstash）无法访问，Filebeat会跟踪最后发送的行，并在输出再次可以用时继续读取文件。 在Filebeat运行时，每个prospector内存中也会保存的文件状态信息，当重新启动Filebat时，将使用注册文件的数量来重建文件状态，Filebeat将每个harvester在从保存的最后偏移量继续读取 文件状态记录在data/registry文件中 input 一个input负责管理harvester，并找到所有要读取的源 如果input类型是log，则input查找驱动器上与已定义的glob路径匹配的所有文件，并为每个文件启动一个harvester 每个input都在自己的Go例程中运行 下面的例子配置Filebeat从所有匹配指定的glob模式的文件中读取行 filebeat.inputs: - type: log paths: - /var/log/*.log - /var/path2/*.log 启动命令 ./filebeat -e -c mogublog-es.yml ./filebeat -e -c mogublog-es.yml -d \"publish\" 参数说明 -e：输出到标准输出，默认输出到syslog和logs下 -c：指定配置文件 -d：输出debug信息 读取Nginx中的配置文件 我们需要创建一个 mogublog-nginx.yml配置文件 filebeat.inputs: - type: log enabled: true paths: - /soft/nginx/*.log tags: [\"nginx\"] fields_under_root: false setup.template.settings: index.number_of_shards: 1 output.elasticsearch: hosts: [\"127.0.0.1:9200\"] 启动后，可以在Elasticsearch中看到索引以及查看数据 可以看到，在message中已经获取到了nginx的日志，但是，内容并没有经过处理，只是读取到原数据，那么对于我们后期的操作是不利的，有办法解决吗？ Module 前面要想实现日志数据的读取以及处理都是自己手动配置的，其实，在Filebeat中，有大量的Module，可以简化我们的配置，直接就可以使用，如下： ./filebeat modules list 得到的列表如下所示 Disabled: activemq apache auditd aws azure barracuda bluecoat cef checkpoint cisco coredns crowdstrike cylance elasticsearch envoyproxy f5 fortinet googlecloud gsuite haproxy ibmmq icinga iis imperva infoblox iptables juniper kafka kibana logstash microsoft misp mongodb mssql mysql nats netflow netscout nginx o365 okta osquery panw postgresql rabbitmq radware redis santa sonicwall sophos squid suricata system tomcat traefik zeek zscaler 可以看到，内置了很多的module，但是都没有启用，如果需要启用需要进行enable操作： #启动 ./filebeat modules enable nginx #禁用 ./filebeat modules disable nginx 可以发现，nginx的module已经被启用。 nginx module 配置 我们到下面的目录，就能看到module的配置了 # 进入到module目录 cd modules.d/ #查看文件 vim nginx.yml.disabled 得到的文件内容如下所示 # Module: nginx # Docs: https://www.elastic.co/guide/en/beats/filebeat/7.9/filebeat-module-nginx.html - module: nginx # Access logs access: enabled: true # 添加日志文件 var.paths: [\"/var/log/nginx/access.log*\"] # Set custom paths for the log files. If left empty, # Filebeat will choose the paths depending on your OS. #var.paths: # Error logs error: enabled: true var.paths: [\"/var/log/nginx/error.log*\"] 配置filebeat 我们需要修改刚刚的mogublog-nginx.yml文件，然后添加到我们的module filebeat.inputs: setup.template.settings: index.number_of_shards: 1 output.elasticsearch: hosts: [\"127.0.0.1:9200\"] filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false 测试 我们启动我们的filebeat ./filebeat -e -c itcast-nginx.yml 如果启动的时候发现出错了，错误如下所示，执行如图所示的脚本即可 【新版本的ES好像不会出现这个错误】 #启动会出错，如下 ERROR fileset/factory.go:142 Error loading pipeline: Error loading pipeline for fileset nginx/access: This module requires the following Elasticsearch plugins: ingest-user-agent, ingest-geoip. You can install them by running the following commands on all the Elasticsearch nodes: sudo bin/elasticsearch-plugin install ingest-user-agent sudo bin/elasticsearch-plugin install ingest-geoip 启动成功后，能看到日志记录已经成功刷新进去了 我们可以测试一下，刷新nginx页面，或者向错误日志中，插入数据 echo \"err\" >> error.log 能够看到，刚刚的记录已经成功插入了 关于module的其它使用，可以参考文档： https://www.elastic.co/guide/en/beats/filebeat/current/filebeat-modules.html Metricbeat 定期收集操作系统或应用服务的指标数据 存储到Elasticsearch中，进行实时分析 Metricbeat组成 Metricbeat有2部分组成，一部分是Module，另一个部分为Metricset Module 收集的对象：如 MySQL、Redis、Nginx、操作系统等 Metricset 收集指标的集合：如 cpu、memory，network等 以Redis Module为例： 下载 首先我们到官网，找到Metricbeat进行下载 下载完成后，我们通过xftp工具，移动到指定的目录下 # 移动到该目录下 cd /soft/beats # 解压文件 tar -zxvf # 修改文件名 mv metricbeat 然后修改配置文件 vim metricbeat.yml 添加如下内容 metricbeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.template.settings: index.number_of_shards: 1 index.codec: best_compression setup.kibana: output.elasticsearch: hosts: [\"\"127.0.0.1:9200\"] processors: - add_host_metadata: ~ - add_cloud_metadata: ~ 默认会指定的配置文件，就是在 ${path.config}/modules.d/*.yml 也就是 system.yml文件，我们也可以自行开启其它的收集 启动 在配置完成后，我们通过如下命令启动即可 ./metricbeat -e 在ELasticsearch中可以看到，系统的一些指标数据已经写入进去了： system module配置 - module: system period: 10s # 采集的频率，每10秒采集一次 metricsets: # 采集的内容 - cpu - load - memory - network - process - process_summary Metricbeat Module Metricbeat Module的用法和我们之前学的filebeat的用法差不多 #查看列表 ./metricbeat modules list 能够看到对应的列表 Enabled: system #默认启用 Disabled: aerospike apache ceph couchbase docker dropwizard elasticsearch envoyproxy etcd golang graphite haproxy http jolokia kafka kibana kubernetes kvm logstash memcached mongodb munin mysql nginx php_fpm postgresql prometheus rabbitmq redis traefik uwsgi vsphere windows Nginx Module 开启Nginx Module 在nginx中，需要开启状态查询，才能查询到指标数据。 #重新编译nginx ./configure --prefix=/usr/local/nginx --with-http_stub_status_module make make install ./nginx -V #查询版本信息 nginx version: nginx/1.11.6 built by gcc 4.4.7 20120313 (Red Hat 4.4.7-23) (GCC) configure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module #配置nginx vim nginx.conf location /nginx-status { stub_status on; access_log off; } # 重启nginx ./nginx -s reload 测试 结果说明： Active connections：正在处理的活动连接数 server accepts handled requests 第一个 server 表示Nginx启动到现在共处理了9个连接 第二个 accepts 表示Nginx启动到现在共成功创建 9 次握手 第三个 handled requests 表示总共处理了 21 次请求 请求丢失数 = 握手数 - 连接数 ，可以看出目前为止没有丢失请求 Reading: 0 Writing: 1 Waiting: 1 Reading：Nginx 读取到客户端的 Header 信息数 Writing：Nginx 返回给客户端 Header 信息数 Waiting：Nginx 已经处理完正在等候下一次请求指令的驻留链接（开启keep-alive的情况下，这个值等于 Active - (Reading+Writing)） 配置nginx module #启用redis module ./metricbeat modules enable nginx #修改redis module配置 vim modules.d/nginx.yml 然后修改下面的信息 # Module: nginx # Docs: https://www.elastic.co/guide/en/beats/metricbeat/6.5/metricbeat-modulenginx. html - module: nginx #metricsets: # - stubstatus period: 10s # Nginx hosts hosts: [\"http://127.0.0.1\"] # Path to server status. Default server-status server_status_path: \"nginx-status\" #username: \"user\" #password: \"secret\" 修改完成后，启动nginx #启动 ./metricbeat -e 测试 我们能看到，我们的nginx数据已经成功的采集到我们的系统中了 可以看到，nginx的指标数据已经写入到了Elasticsearch。 更多的Module使用参见官方文档： https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-modules.html 参考 Filebeat 模块与配置 Elastic Stack（ELK）从入门到实践new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 13:32:12 "},"hm/3_Kibana安装与介绍/":{"url":"hm/3_Kibana安装与介绍/","title":"3_Kibana安装与介绍","keywords":"","body":"Kibana入门配置和安装启动功能说明数据探索Metricbeat仪表盘Nginx指标仪表盘【Metricbeat】Nginx日志仪表盘Kibana自定义仪表盘开发者工具Kibana入门 Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，设计用于和 Elasticsearch 协作。您可以使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对数据进行多元化的分析和呈现。 官网：https://www.elastic.co/cn/kibana 配置和安装 到下载地址，选择对应的版本：https://www.elastic.co/cn/downloads/kibana 下载完成后，将文件拷贝到我们的服务器上，然后解压 # 解压 tar -zxvf kibana-7.9.1-linux-x86_64.tar.gz # 重命名 mv kibana-7.9.1-linux-x86_64 kibana 然后在进入kibana目录，找到config文件夹下的kibana.yml进行配置的修改 vim /soft/kibana/config/kibana.yml 然后找到下面的内容 #对外暴露服务的地址 server.host: \"0.0.0.0\" #配置Elasticsearch elasticsearch.url: \"http://127.0.0.1:9200\" 启动 修改配置完成后，我们就可以启动kibana了 #启动 ./bin/kibana 点击启动，发现报错了 原因是kibana不能使用root用户进行启动，所以我们切换到elsearch用户 # 将soft文件夹的所属者改成elsearch chown elsearch:elsearch /soft/ -R # 切换用户 su elsearch # 启动 ./bin/kibana 然后打开下面的地址，即可访问我们的kibana了 http://202.193.56.222:5601/ 功能说明 Discover：数据探索 Visualize：可视化 Dashboard：仪表盘 Timelion：时序控件 Canvas：画布 Machine Learning：机器学习 Infrastructure：基本信息 Logs：数据日志展示 APM：性能监控 Dev Tools：开发者工具 Monitoring：监控 Management：管理 数据探索 先添加索引信息 然后我们就输入匹配规则进行匹配 然后选择时间字段，一般选择第一个 索引创建完毕后 然后我们就可以往nginx error.log日志文件中，添加几天错误记录 echo \"hello error\" >> error.log 我们追加了两条数据，然后到kibana的discover中，刷新页面，就能够看到我们刚添加的日志了，同时我们点击右侧还可以选择需要展示的字段，非常的方便 点击右上角，我们还可以针对时间来进行过滤 Metricbeat仪表盘 现在将Metricbeat的数据展示在Kibana中，首先需要修改我们的MetricBeat配置 #修改metricbeat配置 setup.kibana: host: \"192.168.40.133:5601\" #安装仪表盘到Kibana【需要确保Kibana在正常运行，这个过程可能会有些耗时】 ./metricbeat setup --dashboards 安装完成后，如下所示 然后我们启动Metricbeat ./metricbeat -e 然后到kibana页面下，找到我们刚刚安装的仪表盘 然后我们就能够看到非常多的指标数据了 Nginx指标仪表盘【Metricbeat】 选择Metricbeat的nginx仪表盘即可 然后就能够看到Nginx的指标信息了 Nginx日志仪表盘 我们可以和刚刚Metricbeat的仪表盘一样，也可以将filebeat收集的日志记录，推送到Kibana中 首先我们需要修改filebeat的 mogublog-nginx.yml配置文件 filebeat.inputs: setup.template.settings: index.number_of_shards: 1 output.elasticsearch: hosts: [\"127.0.0.1:9200\"] filebeat.config.modules: path: ${path.config}/modules.d/*.yml reload.enabled: false setup.kibana: host: \"127.0.0.1:5601\" 然后按照仪表盘 ./filebeat -c mogublog-nginx.yml setup 等待一会后，仪表盘也安装成功了 然后我们启动filebeat即可 ./filebeat -e -c mogublog-nginx.yml 启动完成后，我们回到我们的Kibana中，找到Dashboard，添加我们的filebeat - nginx即可 然后就能看到我们的仪表盘了，上图就是请求的来源 需要注意的是，这些仪表盘本身是没有的，我们需要通过filebeat来进行安装 Kibana自定义仪表盘 在Kibana中，我们也可以自定义图标，如制作柱形图 我们选择最下面的 Vertical Bar，也就是柱形图，然后在选择我们的索引 这样就出来了 开发者工具 在Kibana中，为开发者的测试提供了便捷的工具使用，如下： 我们就可以在这里面写一些请求了 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 13:32:12 "},"hm/4_Logstash入门简介/":{"url":"hm/4_Logstash入门简介/","title":"4_Logstash入门简介","keywords":"","body":"Logstash入门简介介绍用途部署安装测试配置详解输入过滤输出读取自定义日志日志结构编写配置文件输出到ElasticsearchLogstash入门简介 介绍 Logstash是一个开源的服务器端数据处理管道，能够同时从多个来源采集数据，转换数据，然后将数据发送到最喜欢的存储库中（我们的存储库当然是ElasticSearch） 我们回到我们ElasticStack的架构图，可以看到Logstash是充当数据处理的需求的，当我们的数据需要处理的时候，会将它发送到Logstash进行处理，否则直接送到ElasticSearch中 用途 Logstash可以处理各种各样的输入，从文档，图表中=，数据库中，然后处理完后，发送到 部署安装 Logstash主要是将数据源的数据进行一行一行的处理，同时还直接过滤切割等功能。 首先到官网下载logstash：https://www.elastic.co/cn/downloads/logstash 选择我们需要下载的版本： 下载完成后，使用xftp工具，将其丢入到服务器中 #检查jdk环境，要求jdk1.8+ java -version #解压安装包 tar -xvf logstash-7.9.1.tar.gz #第一个logstash示例 bin/logstash -e 'input { stdin { } } output { stdout {} }' 其实原来的logstash的作用，就是为了做数据的采集，但是因为logstash的速度比较慢，所以后面使用beats来代替了Logstash，当我们使用上面的命令进行启动的时候，就可以发现了，因为logstash使用java写的，首先需要启动虚拟机，最后下图就是启动完成的截图 测试 我们在控制台输入 hello，马上就能看到它的输出信息 配置详解 Logstash的配置有三部分，如下所示 input { #输入 stdin { ... } #标准输入 } filter { #过滤，对数据进行分割、截取等处理 ... } output { #输出 stdout { ... } #标准输出 } 输入 采集各种样式、大小和来源的数据，数据往往以各种各样的形式，或分散或集中地存在于很多系统中。 Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地从您的日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据。 过滤 实时解析和转换数据 数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。 输出 Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。 读取自定义日志 前面我们通过Filebeat读取了nginx的日志，如果是自定义结构的日志，就需要读取处理后才能使用，所以，这个时候就需要使用Logstash了，因为Logstash有着强大的处理能力，可以应对各种各样的场景。 日志结构 2019-03-15 21:21:21|ERROR|1 读取数据出错|参数：id=1002 可以看到，日志中的内容是使用“|”进行分割的，使用，我们在处理的时候，也需要对数据做分割处理。 编写配置文件 vim mogublog-pipeline.conf 然后添加如下内容 input { file { path => \"/soft/beats/logs/app.log\" start_position => \"beginning\" } } filter { mutate { split => {\"message\"=>\"|\"} } } output { stdout { codec => rubydebug } } 启动 #启动 ./bin/logstash -f ./mogublog-pipeline.conf 然后我们就插入我们的测试数据 echo \"2019-03-15 21:21:21|ERROR|读取数据出错|参数：id=1002\" >> app.log 然后我们就可以看到logstash就会捕获到刚刚我们插入的数据，同时我们的数据也被分割了 输出到Elasticsearch 我们可以修改我们的配置文件，将我们的日志记录输出到ElasticSearch中 input { file { path => \"/soft/beats/logs/app.log\" start_position => \"beginning\" } } filter { mutate { split => {\"message\"=>\"|\"} } } output { elasticsearch { hosts => [\"127.0.0.1:9200\"] } } 然后在重启我们的logstash ./bin/logstash -f ./mogublog-pipeline.conf 然后向日志记录中，插入两条数据 echo \"2019-03-15 21:21:21|ERROR|读取数据出错|参数：id=1002\" >> app.log echo \"2019-03-15 21:21:21|ERROR|读取数据出错|参数：id=1002\" >> app.log 最后就能够看到我们刚刚插入的数据了 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 13:32:12 "},"hm/5_ElasticStack综合案例/":{"url":"hm/5_ElasticStack综合案例/","title":"5_ElasticStack综合案例","keywords":"","body":"ElasticStack综合案例流程说明App介绍配置Filebeat配置LogstashLogstash输出到控制台配置Logstash连接ElasticSearch遇到的问题1遇到的问题2启动ElasticSearch启动Kibana添加到索引库创建柱形图创建饼图数据表格制作DashboardElasticStack综合案例 本篇将我们前面学习到的技术：ElasticSearch、Beats、Kibana、Logstash 整合起来，做一个综合性的学习，目的是为了让小伙伴们能够更加深刻的理解ElasticStack的使用 流程说明 应用APP生产日志，用来记录用户的操作 [INFO] 2019-03-15 22:55:20 [Main] - DAU|5206|使用优惠券|2019-03-15 03:37:20 [INFO] 2019-03-15 22:55:21 [Main] - DAU|3880|浏览页面|2019-03-15 07:25:09 通过Filebeat读取日志文件中的内容，并且将内容发送给Logstash，原因是需要对内容做处理 Logstash接收到内容后，进行处理，如分割操作，然后将内容发送到Elasticsearch中 Kibana会读取Elasticsearch中的数据，并且在Kibana中进行设计Dashboard，最后进行展示 说明：日志格式、图表、Dashboard都是自定义的 App介绍 APP在生产环境应该是真实系统，然而，现在我们学习的话，为了简化操作，所以就做数据的模拟生成即可。 业务代码如下： package com.log; import lombok.extern.slf4j.Slf4j; import org.apache.commons.lang3.RandomUtils; import org.joda.time.DateTime; import org.springframework.boot.autoconfigure.SpringBootApplication; @Slf4j @SpringBootApplication public class Main { public static final String[] VISIT = new String[]{\"浏览页面\", \"评论商品\", \"加入收藏\", \"加入购物车\", \"提交订单\", \"使用优惠券\", \"领取优惠券\", \"搜索\", \"查看订单\"}; public static void main(String[] args) throws Exception { while(true){ Long sleep = RandomUtils.nextLong(200, 1000 * 5); Thread.sleep(sleep); Long maxUserId = 9999L; Long userId = RandomUtils.nextLong(1, maxUserId); String visit = VISIT[RandomUtils.nextInt(0, VISIT.length)]; DateTime now = new DateTime(); int maxHour = now.getHourOfDay(); int maxMillis = now.getMinuteOfHour(); int maxSeconds = now.getSecondOfMinute(); String date = now.plusHours(-(RandomUtils.nextInt(0, maxHour))) .plusMinutes(-(RandomUtils.nextInt(0, maxMillis))) .plusSeconds(-(RandomUtils.nextInt(0, maxSeconds))) .toString(\"yyyy-MM-dd HH:mm:ss\"); String result = \"DAU|\" + userId + \"|\" + visit + \"|\" + date; log.error(result); } } } 我们可以启动运行，就是不断的生成日志，模拟了我们的实际业务 09:18:32.721 [main] ERROR com.log.Main - DAU|8183|加入购物车|2020-09-25 06:10:25 09:18:33.599 [main] ERROR com.log.Main - DAU|7097|提交订单|2020-09-25 06:18:31 09:18:37.265 [main] ERROR com.log.Main - DAU|1468|查看订单|2020-09-25 02:04:10 09:18:39.634 [main] ERROR com.log.Main - DAU|7821|领取优惠券|2020-09-25 02:04:07 09:18:41.909 [main] ERROR com.log.Main - DAU|7962|提交订单|2020-09-25 03:02:39 09:18:43.596 [main] ERROR com.log.Main - DAU|3358|评论商品|2020-09-25 08:14:19 然后我们将该项目使用下面命令进行打包 mvn clean install 打包完成后，到target目录下，能够看到我们生成的jar包 我们将其复制到我们的服务器上，然后创建一个启动的脚本 startup.sh #!/bin/bash nohup java -Xms256m -Xmx512m -jar mogu-dashboard-generate-0.0.1-SNAPSHOT.jar > app.log 2>&1 & 然后就使用脚本进行启动 # 启动 ./startup.sh # 启动成功后，会看到一个日志 app.log，我们可以查看 tail -f app.log 配置Filebeat 在有了不断产生日志的应用程序后，我们就需要创建一个Filebeat的配置文件，用于日志的收集 # 打开配置文件 vim mogu-dashboard.yml # 写入数据 filebeat.inputs: - type: log enabled: true paths: - /soft/app/*.log setup.template.settings: index.number_of_shards: 1 output.logstash: hosts: [\"127.0.0.1:5044\"] 然后我们就可以启动了【需要我们把Logstash启动起来】 ./filebeat -e -c mogu-dashboard.yml 配置Logstash Logstash输出到控制台 Logstash的主要目的就是处理Filebeat发送过来的数据，进行数据的清洗，过滤等，我们首先简单的将logstash获得的数据输出到控制台 # 打开配置文件 vim mogu-dashboard.conf # 添加以下内容 input { beats { port => \"5044\" } } output { stdout { codec => rubydebug } } 然后启动我们的logstash 【注意，启动时间比较长，需要我们等待】 ./bin/logstash -f mogu-dashboard.conf 启动logstash完成后，我们需要再次启动filebeat，回到上面的启动步骤，然后就能看到logstash输出我们的日志 配置Logstash连接ElasticSearch 上面的数据，其实还是我们的原始数据，并没有经过处理，所以我们这个时候就需要使用到Logstash的其它功能了。我们继续修改配置文件 # 打开配置文件 vim mogu-dashboard.conf 然后修改一下的值 input { beats { port => \"5044\" } } filter { mutate { split => {\"message\"=>\"|\"} } mutate { add_field => { \"userId\" => \"%{[message][1]}\" \"visit\" => \"%{[message][2]}\" \"date\" => \"%{[message][3]}\" } } mutate { convert => { \"userId\" => \"integer\" \"visit\" => \"string\" \"date\" => \"string\" } } mutate { remove_field => [ \"host\" ] } } #output { # stdout { codec => rubydebug } #} output { elasticsearch { hosts => [ \"127.0.0.1:9200\"] } } 然后再次启动 ./bin/logstash -f mogu-dashboard.conf 其实能够看到，我们原来的数据，就经过了处理了，产生了新的字段 同时我们还可以对我们的数据，进行类型转换，为了方便我们的下游进行处理 mutate { convert => { \"userId\" => \"integer\" \"visit\" => \"string\" \"date\" => \"string\" } } 遇到的问题1 [2020-09-25T02:32:44,042][WARN ][logstash.filters.mutate ][main][5fd6a2f2f396816d849f2e3e2e0a53f2500a9b58c6819e23f42d2bfd34cde207] Exception caught while applying mutate filter {:exception=>\"Invalid FieldReference: `message[1]`\"} 不断的刷这个错误，配置文件没问题，但添加字段那一个mutate需要给message套一层中括号： mutate { add_field => { \"userId\" => \"%{[message][1]}\" \"visit\" => \"%{[message][2]}\" \"date\" => \"%{[message][3]}\" } } 遇到的问题2 filebeat 传输到host的字段中host是一个对象 failed to parse field [host] of type [text] in document 解决方法就是过滤掉host字段 mutate { remove_field => [ \"host\" ] } 启动ElasticSearch 在我们通过Logstash发送数据到ElasticSearch，所以我们还需要启动我们的ElasticSearch # 切换到elsearch用户 su elsearch # 到目录 cd /soft/elsearch/bin # 启动 ./elasticsearch 启动Kibana 我们最后就需要通过Kibana来展示我们的图形化数据 # 启动kibana ./bin/kibana # 通过浏览器访问 http://202.193.56.222:5601/app/kibana 添加到索引库 添加Logstash索引到Kibana中： http://202.193.56.222:5601/app/management/kibana/indexPatterns/create 输入我们的匹配规则，然后匹配到logstash，然后选择时间字段后创建 创建柱形图 我们点击右侧Visualizations，然后开始创建图标 然后选择柱形图 在选择我们的索引 最后我们定义我们的X轴，选择按照时间进行添加 最后更新我们的页面，然后在选择最近的30分钟 就能够看到我们的日志在源源不断的生成了，同时我们可以对我们的这个图表进行保存 创建饼图 我们继续选择饼图 然后选择我们的索引 添加完成后，我们就看到这样一个页面了 但是这样还不死很直观，所以我们还需要做处理，找到右侧的Buckets，然后选择Split Slices，然后把我们的每个字段都添加上去，其中visit指的是我们es中的属性 最后选择update，得到的效果如下所示 我们还可以继续给每个字段都添加label标签 添加完成后，更新页面，就得到非常不错的效果了~ 数据表格 在图标中，选择我们需要显示的字段即可 制作Dashboard new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 13:32:12 "},"hm/6_使用ELK搭建蘑菇博客日志收集/":{"url":"hm/6_使用ELK搭建蘑菇博客日志收集/","title":"6_使用ELK搭建蘑菇博客日志收集","keywords":"","body":"使用ELK搭建蘑菇博客日志收集前言拉取ElasticStack镜像制作容器启动ElasticSearch启动Logstash启动Beats启动filebeat启动Kibana使用ELK搭建蘑菇博客日志收集 前言 前阵子学习了ElasticStack的技术栈，其中包括ElasticSearch 、Beats、Kibana、Logstash。因为打算将其用于蘑菇博客的项目中，关于ElasticStack的技术栈学习，可以参考前面写的博客~ ElasticSearch介绍与安装 Beats入门简介 Kibana安装与介绍 Logstash入门简介 ElasticStack综合案例 拉取ElasticStack镜像 通过本教程，可以非常方便的给蘑菇博客项目，集成ELK用于分布式日志收集 为了更加方便的部署ELK环境，我已经提前将环境打包成了Docker镜像，发布到了DockerHub中，所以我们只需要拉取我提前制作的ElasticStack镜像即可 # 拉取镜像 docker pull moxi/elastic_stack # 查看镜像 docker images; 拉取完成后，查看我们的镜像信息，容量大概在4.16G左右 制作容器 在我们拉取完成后，就可以开始通过镜像制作我们的ElasticStack容器了 docker run --privileged -d -it -h elastic_stack --name elastic_stack -v /etc/localtime:/etc/localtime:ro -p 11122:22 -p 9200:9200 -p 5601:5601 -p 5044:5044 -p 9600:9600 moxi/elastic_stack /usr/sbin/init 其中这里主要使用的端口号有 11122：用于建立ssh连接内部容器 9200：ElasticSearch默认端口号 5601：Kibana默认端口号 5044：Logstash默认端口号 执行完上面的命令后，如果没有错误，那么就代表执行成功 然后我们就可以通过在启动一个xshell窗口，连接我们的容器了 输入你服务器的ip地址，以及端口号为 11122，然后点击确定，然后在输入服务器的账号和密码 账号：root 密码：mogu2018 即可进入到我们的容器内部，我们到/soft目录下，能看到里面安装的软件 ElasticSearch：分布式搜索引擎 jdk：java1.8 kibana：图形化工具 logstash：用于数据的过滤和处理 启动ElasticSearch 因为ElasticSearch的启动配置要求比较高，所以我们需要修改一些配置，首先我们到宿主机【是刚刚安装Docker的机器，不是现在容器里面！！】 # 到宿主机上打开文件 vim /etc/sysctl.conf # 增加这样一条配置，一个进程在VMAs(虚拟内存区域)创建内存映射最大数量 vm.max_map_count=655360 # 让配置生效 sysctl -p 然后再去启动ElasticSearch，因为ElasticSearch不能使用root用户直接启动，所以我们需要切换到elsearch # 切换用户 su elsearch # 进入到ElasticSearch目录 cd elsearch # 启动 ./bin/elasticsearch # 后台启动 ./bin/elasticsearch -d 启动完成后，我们就可以看到ElasticSearch运行在9200端口上 我们输入下面的地址到浏览器中访问 http://your_ip:9200/ 如果出现下面的内容，表示ElasticSearch服务已经正常启动~ 启动Logstash Logstash的作用就是收集Beats发送过来的数据，然后进行处理，处理完成后，在将其推送到ElasticSearch中，如果需要查看更多的关于Logstash，可以跳转到上面提到的博客中 我们首先到Logstash目录 cd /soft/logstash 然后我们可以查看配置文件 vim mogu-dashboard.conf 可以看到我之前配置的信息 input { beats { port => \"5044\" } } filter { mutate { split => {\"message\"=>\"|\"} } mutate { add_field => { \"userId\" => \"%{[message][1]}\" \"visit\" => \"%{[message][2]}\" \"date\" => \"%{[message][3]}\" } } mutate { convert => { \"userId\" => \"integer\" \"visit\" => \"string\" \"date\" => \"string\" } } mutate { remove_field => [ \"host\" ] } } #output { # stdout { codec => rubydebug } #} output { if [from] == 'mogu_web' { elasticsearch { hosts => [\"127.0.0.1:9200\"] index => \"logstash_mogu_web_%{+YYYY.MM.dd}\" } } if [from] == \"mogu_admin\" { elasticsearch { hosts => [\"127.0.0.1:9200\"] index => \"logstash_mogu_admin_%{+YYYY.MM.dd}\" } } if [from] == \"mogu_sms\" { elasticsearch { hosts => [\"127.0.0.1:9200\"] index => \"logstash_mogu_sms_%{+YYYY.MM.dd}\" } } if [from] == \"mogu_picture\" { elasticsearch { hosts => [\"127.0.0.1:9200\"] index => \"logstash_mogu_picture_%{+YYYY.MM.dd}\" } } if [from] == \"mogu_nginx\" { elasticsearch { hosts => [\"127.0.0.1:9200\"] index => \"logstash_mogu_nginx_%{+YYYY.MM.dd}\" } } } 我们可以通过获取到传递过来的from字段，就是在filebeat时候指定的 一个字段，代表是这条日志属于哪个模块的，然后在根据logstash的if判断，然后生成不同的ElasticSearch索引 下面，我们指定该配置文件后，然后启动项目 # 前台启动 ./bin/logstash -f ./mogu-dashboard.conf # 后台启动 nohup ./bin/logstash -f ./mogu-dashboard.conf > catalina.out 2>&1 & 注意：logstash的启动可能会比较慢，需要耐心的等待一会~ 启动完成后，会占用9600端口~，同时经过logstash的数据都会发送到ElasticSearch中 启动Beats 启动filebeat filebeat是一个轻量级的日志文件收集器，主要用于收集我们的一些日志文件【它和应用服务器存放在一起】 需要注意，Beats不在我们ELK服务器上进行启动了，我们需要到部署蘑菇博客的服务器上，然后找到Beats目录 我们首先需要到我们应用服务器中，然后启动filebeats 【如果你的目录下没有，可以参考 Beats入门简介 安装】 # 进入到filebeat目录 cd /soft/beats/filebeat 然后查看我们的配置文件 vim mogu-dashboard.yml 然后修改我们配置文件中logstash的地址，我们要把它改成刚刚部署的logstash服务器的ip即可 filebeat.inputs: - type: log enabled: true paths: - /home/mogu_blog/mogu_web/catalina.out fields: from: mogu_web fields_under_root: true - type: log enabled: true paths: - /home/mogu_blog/mogu_admin/catalina.out fields: from: mogu_admin fields_under_root: true - type: log enabled: true paths: - /home/mogu_blog/mogu_sms/catalina.out fields: from: mogu_sms fields_under_root: true - type: log enabled: true paths: - /home/mogu_blog/mogu_picture/catalina.out fields: from: mogu_picture fields_under_root: true setup.template.settings: index.number_of_shards: 1 output.logstash: hosts: [\"101.132.122.175:5044\"] 然后启动我们的filebeat # 前台启动 ./filebeat -e -c mogu-dashboard.yml # 后台启动 #!/bin/bash nohup ./filebeat -e -c mogu-dashboard.yml > catalina.out 2>&1 & 启动完成后，我们能够看到日志文件已经被加载 启动Kibana Kibana的作用就是对我们的数据进行图形化的显示，首先我们到Kibana目录 【回到ELK目录下】 # 到kibana安装目录 cd /soft/kibana 因为Kibana和ElasticSearch一样，不支持root用户启动，所以我们继续切换成elsearch用户 su elsearch 然后启动 ./bin/kibana 查看启动信息，我们发现Kibana启动在5601端口号 启动后，我们在浏览器中访问我们的地址 http://your_ip:5601 我们找到dashboard就可以看到蘑菇博客的日志记录了 tip：这里就只介绍了ElasticStack的日志收集，关于更多的Kibana图形化页面，小伙伴可以参考其它文件进行配置，这里就不列举出来啦~new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 13:32:12 "},"hm/0_pdf课件/note01.html":{"url":"hm/0_pdf课件/note01.html","title":"part01","keywords":"","body":" 课程介绍   Elastic Stack简介   Elasticsearch的介绍与安装   Elasticsearch的快速入门   Elasticsearch的核心讲解   中文分词   全文搜索   Elasticsearch集群   Java客户端讲解   ꢀ 1、Elastic Stack简介   如果你没有听说过Elastic Stack，那你一定听说过ELK，实际上ELK是三款软件的简称，分别是Elasticsearch、   Logstash、Kibana组成，在发展的过程中，又有新成员Beats的加入，所以就形成了Elastic Stack。所以说，ELK是   旧的称呼，Elastic Stack是新的名字。   全系的Elastic Stack技术栈包括：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   Elasticsearch   Elasticsearch 基于java，是个开源分布式搜索引擎，它的特点有：分布式，零配置，自动发现，索引自动分片，索引   副本机制，restful风格接口，多数据源，自动搜索负载等。   Logstash   Logstash 基于java，是一个开源的用于收集,分析和存储日志的工具。   Kibana   Kibana 基于nodejs，也是一个开源和免费的工具，Kibana可以为 Logstash 和 ElasticSearch 提供的日志分析友好的   Web 界面，可以汇总、分析和搜索重要数据日志。   Beats   Beats是elastic公司开源的一款采集系统监控数据的代理agent，是在被监控服务器上以客户端形式运行的数据收集   器的统称，可以直接把数据发送给Elasticsearch或者通过Logstash发送给Elasticsearch，然后进行后续的数据分析活   动。   Beats由如下组成:   Packetbeat：是一个网络数据包分析器，用于监控、收集网络流量信息，Packetbeat嗅探服务器之间的流量，   解析应用层协议，并关联到消息的处理，其支 持ICMP (v4 and v6)、DNS、HTTP、Mysql、PostgreSQL、   Redis、MongoDB、Memcache等协议；   Filebeat：用于监控、收集服务器日志文件，其已取代 logstash forwarder；   Metricbeat：可定期获取外部系统的监控指标信息，其可以监控、收集 Apache、HAProxy、MongoDB   MySQL、Nginx、PostgreSQL、Redis、System、Zookeeper等服务；   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   Winlogbeat：用于监控、收集Windows系统的日志信息；   2、Elasticsearch   2 .1、简介   官网：https://www.elastic.co/cn/products/elasticsearch   2 .2、安装   2 .2.1、版本说明   Elasticsearch的发展是非常快速的，所以在ES5.0之前，ELK的各个版本都不统一，出现了版本号混乱的状态，所以   从5.0开始，所有Elastic Stack中的项目全部统一版本号。目前最新版本是6.5.4，我们将基于这一版本进行学习。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   2 .2.2、下载   地址：https://www.elastic.co/cn/downloads/elasticsearch   或者，使用资料中提供的已下载好的安装包。   2 .2.3、单机版安装   1 2 3 4 5 #创建elsearch用户，Elasticsearch不支持root用户运行   useradd elsearch   #解压安装包   tar -xvf elasticsearch-6.5.4.tar.gz -C /itcast/es/   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6 7 8 9 0 #修改配置文件   vim conf/elasticsearch.yml   network.host: 0.0.0.0 ꢀ#设置ip地址，任意网络均可访问   1 1 1 #说明：在Elasticsearch中如果，network.host不是localhost或者127.0.0.1的话，就会认为是生产环境，   会对环境的要求比较高，我们的测试环境不一定能够满足，一般情况下需要修改2处配置，如下：   1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 2 #1：修改jvm启动参数   3 vim conf/jvm.options   4 -Xms128m #根据自己机器情况修改   5 -Xmx128m   6 #2：一个进程在VMAs(虚拟内存区域)创建内存映射最大数量   7 vim /etc/sysctl.conf   8 vm.max_map_count=655360   9 0 sysctl -p #配置生效   1 2 #启动ES服务   3 su - elsearch   4 cd bin   5 ./elasticsearch 或 ./elasticsearch -d #后台启动   6 7 #通过访问进行测试，看到如下信息，就说明ES启动成功了   8 {   9 ꢀ ꢀ\"name\": \"dSQV6I8\",   0 ꢀ ꢀ\"cluster_name\": \"elasticsearch\",   ꢀ ꢀ\"cluster_uuid\": \"v5GPTWAtT5emxFdjigFg-w\",   ꢀ ꢀ\"version\": {   1 2 3 ꢀ ꢀ ꢀ ꢀ\"number\": \"6.5.4\",   4 ꢀ ꢀ ꢀ ꢀ\"build_flavor\": \"default\",   ꢀ ꢀ ꢀ ꢀ\"build_type\": \"tar\",   5 6 ꢀ ꢀ ꢀ ꢀ\"build_hash\": \"d2ef93d\",   ꢀ ꢀ ꢀ ꢀ\"build_date\": \"2018-12-17T21:17:40.758843Z\",   ꢀ ꢀ ꢀ ꢀ\"build_snapshot\": false,   ꢀ ꢀ ꢀ ꢀ\"lucene_version\": \"7.5.0\",   ꢀ ꢀ ꢀ ꢀ\"minimum_wire_compatibility_version\": \"5.6.0\",   ꢀ ꢀ ꢀ ꢀ\"minimum_index_compatibility_version\": \"5.0.0\"   ꢀ },   7 8 9 0 1 2 3 ꢀ ꢀ\"tagline\": \"You Know, for Search\"   4 }   5 6 #停止服务   7 root@itcast:~# jps   8 68709 Jps   9 68072 Elasticsearch   0 1 kill 68072 ꢀ#通过kill结束进程   1 2 #启动出错，环境：Centos6   [1]: max file descriptors [4096] for elasticsearch process is too low, increase to at   least [65536]   3 4 #解决：切换到root用户，编辑limits.conf 添加类似如下内容   vi /etc/security/limits.conf   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   5 6 7 8 9 0 1 添加如下内容:   * soft nofile 65536   * hard nofile 131072   * soft nproc 2048   * hard nproc 4096   1 1 1 2 [2]: max number of threads [1024] for user [elsearch] is too low, increase to at least   4096]   [ 1 1 1 1 1 1 1 2 3 #解决：切换到root用户，进入limits.d目录下修改配置文件。   4 vi /etc/security/limits.d/90-nproc.conf   5 #修改如下内容：   6 * soft nproc 1024   7 #修改为   8 * soft nproc 4096   9 0 [3]: system call filters failed to install; check the logs and fix your configuration   or disable system call filters at your own risk   1 2 2 2 2 2 2 #解决：Centos6不支持SecComp，而ES5.2.0默认bootstrap.system_call_filter为true   3 vim config/elasticsearch.yml   4 添加：   5 bootstrap.system_call_filter: false   2 .2.4、elasticsearch-head   由于ES官方并没有为ES提供界面管理工具，仅仅是提供了后台的服务。elasticsearch-head是一个为ES开发的一个页   面客户端工具，其源码托管于GitHub，地址为：https://github.com/mobz/elasticsearch-head   head提供了4种安装方式：   源码安装，通过npm run start启动（不推荐）   通过docker安装（推荐）   通过chrome插件安装（推荐）   通过ES的plugin方式安装（不推荐）   通过docker安装   1 2 3 4 5 6 7 8 #拉取镜像   docker pull mobz/elasticsearch-head:5   #创建容器   docker create --name elasticsearch-head -p 9100:9100 mobz/elasticsearch-head:5   #启动容器   docker start elasticsearch-head   通过浏览器进行访问：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   注意：   由于前后端分离开发，所以会存在跨域问题，需要在服务端做CORS的配置，如下：   vim elasticsearch.yml   http.cors.enabled: true http.cors.allow-origin: \"*\"   chrome   chrome插件的方式安装   打开chrome的应用商店，即可安装https://chrome.google.com/webstore/detail/elasticsearch-head/ﬀmkiejjmec   olpﬂoofpjologoblkegm   建议：推荐使用chrome插件的方式安装，如果网络环境不允许，就采用其它方式安装。   2 .3、基本概念   索引   索引（index）是Elasticsearch对逻辑数据的逻辑存储，所以它可以分为更小的部分。   可以把索引看成关系型数据库的表，索引的结构是为快速有效的全文索引准备的，特别是它不存储原始值。   Elasticsearch可以把索引存放在一台机器或者分散在多台服务器上，每个索引有一或多个分片（shard），每个   分片可以有多个副本（replica）。   文档   存储在Elasticsearch中的主要实体叫文档（document）。用关系型数据库来类比的话，一个文档相当于数据库   表中的一行记录。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   Elasticsearch和MongoDB中的文档类似，都可以有不同的结构，但Elasticsearch的文档中，相同字段必须有相   同类型。   文档由多个字段组成，每个字段可能多次出现在一个文档里，这样的字段叫多值字段（multivalued）。   每个字段的类型，可以是文本、数值、日期等。字段类型也可以是复杂类型，一个字段包含其他子文档或者数   组。   映射   所有文档写进索引之前都会先进行分析，如何将输入的文本分割为词条、哪些词条又会被过滤，这种行为叫做   映射（mapping）。一般由用户自己定义规则。   文档类型   在Elasticsearch中，一个索引对象可以存储很多不同用途的对象。例如，一个博客应用程序可以保存文章和评   论。   每个文档可以有不同的结构。   不同的文档类型不能为相同的属性设置不同的类型。例如，在同一索引中的所有文档类型中，一个叫title的字段   必须具有相同的类型。   2 .4、RESTful API   在Elasticsearch中，提供了功能丰富的RESTful API的操作，包括基本的CRUD、创建索引、删除索引等操作。   2 .4.1、创建非结构化索引   在Lucene中，创建索引是需要定义字段名称以及字段的类型的，在Elasticsearch中提供了非结构化的索引，就是不   需要创建索引结构，即可写入数据到索引中，实际上在Elasticsearch底层会进行结构化操作，此操作对用户是透明   的。   创建空索引：   1 2 3 4 5 6 7 8 9 PUT /haoke   { ꢀ \"settings\": {   ꢀ ꢀ ꢀ\"index\": {   ꢀ ꢀ ꢀ ꢀ \"number_of_shards\": \"2\", #分片数   ꢀ ꢀ ꢀ ꢀ \"number_of_replicas\": \"0\" #副本数   ꢀ ꢀ }   ꢀ }   1 1 1 1 1 1 1 0 }   1 2 #删除索引   3 DELETE /haoke   4 {   5 ꢀ \"acknowledged\": true   6 }   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   2 .4.2、插入数据   URL规则：   POST /{索引}/{类型}/{id}   1 2 3 4 5 6 7 8 9 POST /haoke/user/1001   #数据   { ꢀ\"id\":1001,   ꢀ\"name\":\"张三\",   ꢀ\"age\":20,   ꢀ\"sex\":\"男\"   } 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 0 #响应   1 {   2 ꢀ ꢀ\"_index\": \"haoke\",   3 ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ\"_id\": \"1\",   4 5 ꢀ ꢀ\"_version\": 1,   ꢀ ꢀ\"result\": \"created\",   ꢀ ꢀ\"_shards\": {   6 7 8 ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ },   9 0 1 2 ꢀ ꢀ\"_seq_no\": 0,   ꢀ ꢀ\"_primary_term\": 1   3 4 }   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   说明：非结构化的索引，不需要事先创建，直接插入数据默认创建索引。   不指定id插入数据：   1 2 3 4 5 6 7 POST /haoke/user/   { ꢀ\"id\":1002,   ꢀ\"name\":\"张三\",   ꢀ\"age\":20,   ꢀ\"sex\":\"男\"   } 2 .4.3、更新数据   在Elasticsearch中，文档数据是不为修改的，但是可以通过覆盖的方式进行更新。   1 2 3 4 5 6 7 8 9 PUT /haoke/user/1001   { ꢀ\"id\":1001,   ꢀ\"name\":\"张三\",   ꢀ\"age\":21,   ꢀ\"sex\":\"女\"   } 更新结果如下：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   可以看到数据已经被覆盖了。   问题来了，可以局部更新吗？ -- 可以的。   前面不是说，文档数据不能更新吗？ 其实是这样的：   在内部，依然会查询到这个文档数据，然后进行覆盖操作，步骤如下：   1 . 从旧文档中检索JSON   . 修改它   . 删除旧文档   . 索引新文档   2 3 4 示例：   1 2 3 4 5 6 7 8 9 #注意：这里多了_update标识   POST /haoke/user/1001/_update   { \"doc\":{   ꢀ \"age\":23   } } 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   可以看到数据已经被局部更新了。   2 .4.4、删除数据   在Elasticsearch中，删除文档数据，只需要发起DELETE请求即可。   1 DELETE /haoke/user/1001   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   需要注意的是，result表示已经删除，version也更加了。   如果删除一条不存在的数据，会响应404：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   说明：   删除一个文档也不会立即从磁盘上移除，它只是被标记成已删除。Elasticsearch将会在你之后添加更多索引的   时候才会在后台进行删除内容的清理。   2 .4.5、搜索数据   根据id搜索数据   1 2 3 4 5 6 7 8 9 0 1 GET /haoke/user/BbPe_WcB9cFOnF3uebvr   #返回的数据如下   { ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ\"_id\": \"BbPe_WcB9cFOnF3uebvr\",   ꢀ ꢀ\"_version\": 8,   ꢀ ꢀ\"found\": true,   ꢀ ꢀ\"_source\": { ꢀ#原始数据在这里   ꢀ ꢀ ꢀ ꢀ\"id\": 1002,   1 1 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 1 1 1 1 2 ꢀ ꢀ ꢀ ꢀ\"name\": \"李四\",   ꢀ ꢀ ꢀ ꢀ\"age\": 40,   ꢀ ꢀ ꢀ ꢀ\"sex\": \"男\"   ꢀ }   3 4 5 6 }   搜索全部数据   1 GET /haoke/user/_search   响应：（默认返回10条数据）   1 2 3 4 5 6 7 8 9 10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   35   36   37   38   39   40   { ꢀ ꢀ\"took\": 26,   ꢀ ꢀ\"timed_out\": false,   ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ\"total\": 2,   ꢀ ꢀ ꢀ ꢀ\"successful\": 2,   ꢀ ꢀ ꢀ ꢀ\"skipped\": 0,   ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ },   ꢀ ꢀ\"hits\": {   ꢀ ꢀ ꢀ ꢀ\"total\": 4,   ꢀ ꢀ ꢀ ꢀ\"max_score\": 1,   ꢀ ꢀ ꢀ ꢀ\"hits\": [   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"BbPe_WcB9cFOnF3uebvr\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"id\": 1002,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"李四\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 40,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"sex\": \"男\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"1001\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"id\": 1001,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"张三\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 20,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"sex\": \"男\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 1 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"1003\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"id\": 1003,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"王五\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 30,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"sex\": \"男\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   2 3 4 5 6 7 8 9 ꢀ ꢀ ꢀ ꢀ ꢀ },   0 ꢀ ꢀ ꢀ ꢀ ꢀ {   1 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"1004\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"id\": 1004,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"赵六\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 30,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"sex\": \"男\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   2 3 4 5 6 7 8 9 0 1 ꢀ ꢀ ꢀ ꢀ ꢀ }   2 ꢀ ꢀ ꢀ ]   3 ꢀ }   4 }   关键字搜素数据   1 #查询年龄等于20的用户   2 3 GET /haoke/user/_search?q=age:20   结果：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   2 .4.6、DSL搜索   Elasticsearch提供丰富且灵活的查询语言叫做DSL查询(Query DSL),它允许你构建更加复杂、强大的查询。   DSL(Domain Speciﬁc Language特定领域语言)以JSON请求体的形式出现。   1 2 3 4 5 6 7 8 9 POST /haoke/user/_search   #请求体   { ꢀ ꢀ\"query\" : {   ꢀ ꢀ ꢀ ꢀ\"match\" : { ꢀ #match只是查询的一种   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\" : 20   ꢀ ꢀ ꢀ }   ꢀ }   10 }   响应数据：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   实现：查询年龄大于30岁的男性用户。   现有数据：   1 POST /haoke/user/_search   2 #请求数据   3 4 5 6 { ꢀ ꢀ\"query\": {   ꢀ ꢀ ꢀ ꢀ\"bool\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"filter\": {   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   7 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"range\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"gt\": 30   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   8 9 1 1 1 1 1 1 1 1 1 1 2 0 1 2 ꢀ ꢀ ꢀ ꢀ ꢀ },   3 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"must\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"match\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"sex\": \"男\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   4 5 6 7 ꢀ ꢀ ꢀ ꢀ ꢀ }   8 ꢀ ꢀ ꢀ }   9 ꢀ }   0 }   查询结果：   全文搜索   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 9 POST /haoke/user/_search   #请求数据   { ꢀ ꢀ\"query\": {   ꢀ ꢀ ꢀ ꢀ\"match\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"张三 李四\"   ꢀ ꢀ ꢀ }   ꢀ }   } POST /haoke/user/_search #请求数据 {   \" } query\": { \"match\": { \"name\": \"张三 李四\" } }   2 .4.7、高亮显示   1 2 3 4 5 6 POST /haoke/user/_search   { ꢀ ꢀ\"query\": {   ꢀ ꢀ ꢀ ꢀ\"match\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"张三 李四\"   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   7 ꢀ ꢀ ꢀ }   8 ꢀ },   9 ꢀ ꢀ\"highlight\": {   ꢀ ꢀ ꢀ ꢀ\"fields\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": {}   ꢀ ꢀ ꢀ }   1 1 1 1 1 0 1 2 3 ꢀ }   4 }   2 .4.8、聚合   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   在Elasticsearch中，支持聚合操作，类似SQL中的group by操作。   1 2 3 4 5 6 7 8 9 0 POST /haoke/user/_search   { ꢀ ꢀ\"aggs\": {   ꢀ ꢀ ꢀ ꢀ\"all_interests\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"terms\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"field\": \"age\"   ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ }   1 1 ꢀ }   1 }   结果：   从结果可以看出，年龄30的有2条数据，20的有一条，40的一条。   3、核心详解   3 .1、文档   在Elasticsearch中，文档以JSON格式进行存储，可以是复杂的结构，如：   1 2 3 4 5 6 { ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ\"_id\": \"1005\",   ꢀ ꢀ\"_version\": 1,   ꢀ ꢀ\"_score\": 1,   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   7 ꢀ ꢀ\"_source\": {   8 ꢀ ꢀ ꢀ ꢀ\"id\": 1005,   ꢀ ꢀ ꢀ ꢀ\"name\": \"孙七\",   ꢀ ꢀ ꢀ ꢀ\"age\": 37,   ꢀ ꢀ ꢀ ꢀ\"sex\": \"女\",   ꢀ ꢀ ꢀ ꢀ\"card\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"card_number\": \"123456789\"   ꢀ ꢀ ꢀ }   9 1 1 1 1 1 1 1 0 1 2 3 4 5 ꢀ }   6 }   其中，card是一个复杂对象，嵌套的Card对象。   元数据（metadata）   一个文档不只有数据。它还包含了元数据(metadata)——关于文档的信息。三个必须的元数据节点是：   节点   说明   _ _ _ index   文档存储的地方   文档代表的对象的类   文档的唯一标识   type   id   _index   索引(index)类似于关系型数据库里的“数据库”——它是我们存储和索引关联数据的地方。   提示：   事实上，我们的数据被存储和索引在分片(shards)中，索引只是一个把一个或多个分片分组在一起的逻辑空   间。然而，这只是一些内部细节——我们的程序完全不用关心分片。对于我们的程序而言，文档存储在索引   ( index)中。剩下的细节由Elasticsearch关心既可。   _type   在应用中，我们使用对象表示一些“事物”，例如一个用户、一篇博客、一个评论，或者一封邮件。每个对象都属于一   个类(class)，这个类定义了属性或与对象关联的数据。 user类的对象可能包含姓名、性别、年龄和Email地址。   在关系型数据库中，我们经常将相同类的对象存储在一个表里，因为它们有着相同的结构。同理，在Elasticsearch   中，我们使用相同类型(type)的文档表示相同的“事物”，因为他们的数据结构也是相同的。   每个类型(type)都有自己的映射(mapping)或者结构定义，就像传统数据库表中的列一样。所有类型下的文档被存储   在同一个索引下，但是类型的映射(mapping)会告诉Elasticsearch不同的文档如何被索引。   _type的名字可以是大写或小写，不能包含下划线或逗号。我们将使用 blog做为类型名。   _id   id仅仅是一个字符串，它与 _index和 _type组合时，就可以在Elasticsearch中唯一标识一个文档。当创建一个文   档，你可以自定义 _id，也可以让Elasticsearch帮你自动生成（32位长度）。   3 .2、查询响应   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 .2.1、pretty   可以在查询url后面添加pretty参数，使得返回的json更易查看。   3 .2.2、指定响应字段   在响应的数据中，如果我们不需要全部的字段，可以指定某些需要的字段进行返回。   1 2 3 4 5 6 7 8 9 0 1 2 GET /haoke/user/1005?_source=id,name   #响应   { ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ\"_id\": \"1005\",   ꢀ ꢀ\"_version\": 1,   ꢀ ꢀ\"found\": true,   ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ\"name\": \"孙七\",   ꢀ ꢀ ꢀ ꢀ\"id\": 1005   ꢀ }   1 1 1 1 3 }   如不需要返回元数据，仅仅返回原始数据，可以这样：   1 GET /haoke/user/1005/_source   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   还可以这样：   1 GET /haoke/user/1005/_source?_source=id,name   3 .3、判断文档是否存在   如果我们只需要判断文档是否存在，而不是查询文档内容，那么可以这样：   1 HEAD /haoke/user/1005   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 HEAD /haoke/user/1006   当然，这只表示你在查询的那一刻文档不存在，但并不表示几毫秒后依旧不存在。另一个进程在这期间可能创   建新文档。   3 .4、批量操作   有些情况下可以通过批量操作以减少网络请求。如：批量查询、批量插入数据。   3 .4.1、批量查询   1 2 3 4 5 POST /haoke/user/_mget   { } ꢀ \"ids\" : [ \"1001\", \"1003\" ]   结果：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   如果，某一条数据不存在，不影响整体响应，需要通过found的值进行判断是否查询到数据。   1 2 3 4 5 POST /haoke/user/_mget   { ꢀ \"ids\" : [ \"1001\", \"1006\" ]   } 结果：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 .4.2、_bulk操作   在Elasticsearch中，支持批量的插入、修改、删除操作，都是通过_bulk的api完成的。   请求格式如下：（请求格式不同寻常）   1 2 3 4 5 { action: { metadata }}\\n   { request body ꢀ ꢀ ꢀ }\\n   { action: { metadata }}\\n   { request body ꢀ ꢀ ꢀ }\\n   ...   批量插入数据：   1 {\"create\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2001}}   {\"id\":2001,\"name\":\"name1\",\"age\": 20,\"sex\": \"男\"}   {\"create\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2002}}   {\"id\":2002,\"name\":\"name2\",\"age\": 20,\"sex\": \"男\"}   {\"create\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2003}}   {\"id\":2003,\"name\":\"name3\",\"age\": 20,\"sex\": \"男\"}   2 3 4 5 6 7 注意最后一行的回车。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   响应结果：   1 2 3 4 5 6 7 8 9 10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   { ꢀ ꢀ\"took\": 17,   ꢀ ꢀ\"errors\": false,   ꢀ ꢀ\"items\": [   ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"create\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"2001\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_version\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"result\": \"created\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_seq_no\": 24,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_primary_term\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"status\": 201   ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"create\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"2002\",   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 7 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_version\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"result\": \"created\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   8 9 0 1 2 3 4 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_seq_no\": 0,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_primary_term\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"status\": 201   ꢀ ꢀ ꢀ ꢀ ꢀ }   5 6 7 8 ꢀ ꢀ ꢀ },   9 ꢀ ꢀ ꢀ {   0 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"create\": {   1 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"2003\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_version\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"result\": \"created\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   2 3 4 5 6 7 8 9 0 1 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_seq_no\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_primary_term\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"status\": 201   ꢀ ꢀ ꢀ ꢀ ꢀ }   2 3 4 5 ꢀ ꢀ ꢀ }   6 ꢀ ]   7 }   批量删除：   1 {\"delete\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2001}}   {\"delete\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2002}}   {\"delete\":{\"_index\":\"haoke\",\"_type\":\"user\",\"_id\":2003}}   2 3 4 由于delete没有请求体，所以，action的下一行直接就是下一个action。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 9 10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   { ꢀ ꢀ\"took\": 3,   ꢀ ꢀ\"errors\": false,   ꢀ ꢀ\"items\": [   ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"delete\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"2001\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_version\": 2,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"result\": \"deleted\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_seq_no\": 25,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_primary_term\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"status\": 200   ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"delete\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"2002\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_version\": 2,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"result\": \"deleted\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 2 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   3 4 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_seq_no\": 2,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_primary_term\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"status\": 200   ꢀ ꢀ ꢀ ꢀ ꢀ }   5 6 7 8 ꢀ ꢀ ꢀ },   9 ꢀ ꢀ ꢀ {   0 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"delete\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"haoke\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"user\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"2003\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_version\": 2,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"result\": \"deleted\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   1 2 3 4 5 6 7 8 9 0 1 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_seq_no\": 3,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_primary_term\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"status\": 200   ꢀ ꢀ ꢀ ꢀ ꢀ }   2 3 4 5 ꢀ ꢀ ꢀ }   6 ꢀ ]   7 }   其他操作就类似了。   一次请求多少性能最高？   整个批量请求需要被加载到接受我们请求节点的内存里，所以请求越大，给其它请求可用的内存就越小。有一   个最佳的bulk请求大小。超过这个大小，性能不再提升而且可能降低。   最佳大小，当然并不是一个固定的数字。它完全取决于你的硬件、你文档的大小和复杂度以及索引和搜索的负   载。   幸运的是，这个最佳点(sweetspot)还是容易找到的：试着批量索引标准的文档，随着大小的增长，当性能开始   降低，说明你每个批次的大小太大了。开始的数量可以在1000~5000个文档之间，如果你的文档非常大，可以   使用较小的批次。   通常着眼于你请求批次的物理大小是非常有用的。一千个1kB的文档和一千个1MB的文档大不相同。一个好的   批次最好保持在5-15MB大小间。   3 .5、分页   和SQL使用 LIMIT关键字返回只有一页的结果一样，Elasticsearch接受 from和 size参数：   1 2 size: 结果数，默认10   from: 跳过开始的结果数，默认0   如果你想每页显示5个结果，页码从1到3，那请求如下：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 GET /_search?size=5   GET /_search?size=5&from=5   GET /_search?size=5&from=10   应该当心分页太深或者一次请求太多的结果。结果在返回前会被排序。但是记住一个搜索请求常常涉及多个分   片。每个分片生成自己排好序的结果，它们接着需要集中起来排序以确保整体排序正确。   1 GET /haoke/user/_search?size=1&from=2   ꢀ 在集群系统中深度分页   为了理解为什么深度分页是有问题的，让我们假设在一个有5个主分片的索引中搜索。当我们请求结果的第一   页（结果1到10）时，每个分片产生自己最顶端10个结果然后返回它们给请求节点(requesting node)，它再   排序这所有的50个结果以选出顶端的10个结果。   现在假设我们请求第1000页——结果10001到10010。工作方式都相同，不同的是每个分片都必须产生顶端的   1 0010个结果。然后请求节点排序这50050个结果并丢弃50040个！   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   你可以看到在分布式系统中，排序结果的花费随着分页的深入而成倍增长。这也是为什么网络搜索引擎中任何   语句不能返回多于1000个结果的原因。   3 .6、映射   前面我们创建的索引以及插入数据，都是由Elasticsearch进行自动判断类型，有些时候我们是需要进行明确字段类型   的，否则，自动判断的类型和实际需求是不相符的。   自动判断的规则如下：   JSON type   Field type   \"boolean\"   \"long\"   Boolean: true or false   Whole number: 123   Floating point: 123.45   String, valid date: \"2014-09-15\"   String: \"foo bar\"   \"double\"   \"date\"   \"string\"   Elasticsearch中支持的类型如下：   类型   表示的数据类型   string, text, keyword   byte, short, integer, long   float, double   boolean   String   Whole number   Floating point   Boolean   Date   date   string类型在ElasticSearch 旧版本中使用较多，从ElasticSearch 5.x开始不再支持string，由text和   keyword类型替代。   text 类型，当一个字段是要被全文搜索的，比如Email内容、产品描述，应该使用text类型。设置text类型   以后，字段内容会被分析，在生成倒排索引以前，字符串会被分析器分成一个一个词项。text类型的字段   不用于排序，很少用于聚合。   keyword类型适用于索引结构化的字段，比如email地址、主机名、状态码和标签。如果字段需要进行过   滤(比如查找已发布博客中status属性为published的文章)、排序、聚合。keyword类型的字段只能通过精   确值搜索到。   创建明确类型的索引：   1 2 3 4 5 PUT /itcast   { ꢀ ꢀ\"settings\": {   ꢀ ꢀ ꢀ ꢀ\"index\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"number_of_shards\": \"2\",   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"number_of_replicas\": \"0\"   ꢀ ꢀ ꢀ }   7 8 ꢀ },   9 ꢀ ꢀ\"mappings\": {   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 0 ꢀ ꢀ ꢀ ꢀ\"person\": {   1 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"properties\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"text\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   2 3 4 5 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"integer\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   6 7 8 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"mail\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"keyword\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   9 0 1 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"text\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   2 3 4 ꢀ ꢀ ꢀ ꢀ ꢀ }   5 ꢀ ꢀ ꢀ }   6 ꢀ }   7 }   查看映射：   1 GET /itcast/_mapping   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   插入数据：   1 2 3 4 5 6 7 8 9 POST /itcast/_bulk   {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   {\"name\":\"张三\",\"age\": 20,\"mail\": \"111@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球\"}   {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   {\"name\":\"李四\",\"age\": 21,\"mail\": \"222@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球、篮球\"}   {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   {\"name\":\"王五\",\"age\": 22,\"mail\": \"333@qq.com\",\"hobby\":\"羽毛球、篮球、游泳、听音乐\"}   {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   10 {\"name\":\"赵六\",\"age\": 23,\"mail\": \"444@qq.com\",\"hobby\":\"跑步、游泳\"}   11 {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   12 {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影\"}   13   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   测试搜索：   1 2 3 4 5 6 7 8 POST /itcast/person/_search   { ꢀ ꢀ\"query\" : {   ꢀ ꢀ ꢀ ꢀ\"match\" : { ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\" : \"音乐\"   ꢀ ꢀ ꢀ }   ꢀ }   } 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 .7、结构化查询   3 .7.1、term查询   term主要用于精确匹配哪些值，比如数字，日期，布尔值或 not_analyzed的字符串(未经分析的文本数据类型)：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 ꢀ { \"term\": { \"age\": ꢀ ꢀ26 ꢀ ꢀ ꢀ ꢀ ꢀ }}   ꢀ { \"term\": { \"date\": ꢀ \"2014-09-01\" }}   ꢀ { \"term\": { \"public\": true ꢀ ꢀ ꢀ ꢀ }}   ꢀ { \"term\": { \"tag\": ꢀ ꢀ\"full_text\" }}   示例：   1 2 3 4 5 6 7 8 POST /itcast/person/_search   { ꢀ ꢀ\"query\" : {   ꢀ ꢀ ꢀ ꢀ\"term\" : { ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\" : 20   ꢀ ꢀ ꢀ }   ꢀ }   } 3 .7.2、terms查询   terms 跟 term 有点类似，但 terms 允许指定多个匹配条件。 如果某个字段指定了多个值，那么文档需要一起去   做匹配：   1 2 3 4 5 { ꢀ ꢀ\"terms\": {   ꢀ ꢀ ꢀ ꢀ\"tag\": [ \"search\", \"full_text\", \"nosql\" ]   ꢀ ꢀ ꢀ }   } 示例：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 POST /itcast/person/_search   { ꢀ ꢀ\"query\" : {   ꢀ ꢀ ꢀ ꢀ\"terms\" : { ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\" : [20,21]   ꢀ ꢀ ꢀ }   ꢀ }   } 3 .7.3、range查询   range过滤允许我们按照指定范围查找一批数据：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 { ꢀ ꢀ\"range\": {   ꢀ ꢀ ꢀ ꢀ\"age\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"gte\": ꢀ20,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"lt\": ꢀ 30   ꢀ ꢀ ꢀ }   ꢀ }   } 范围操作符包含：   gt :: 大于   gte:: 大于等于   lt :: 小于   lte:: 小于等于   示例：   1 2 3 4 5 6 7 8 9 0 POST /itcast/person/_search   { ꢀ ꢀ\"query\": {   ꢀ ꢀ ꢀ ꢀ\"range\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"gte\": 20,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"lte\": 22   ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ }   1 1 ꢀ }   1 }   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 .7.4、exists 查询   exists 查询可以用于查找文档中是否包含指定字段或没有某个字段，类似于SQL语句中的 IS_NULL条件   1 2 3 4 5 { ꢀ ꢀ\"exists\": ꢀ {   ꢀ ꢀ ꢀ ꢀ\"field\": ꢀ ꢀ\"title\"   ꢀ }   } 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   这两个查询只是针对已经查出一批数据来，但是想区分出某个字段是否存在的时候使用。   示例：   1 2 3 4 5 6 7 8 9 POST /haoke/user/_search   { ꢀ ꢀ\"query\": {   ꢀ ꢀ ꢀ ꢀ\"exists\": { ꢀ#必须包含   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"field\": \"card\"   ꢀ ꢀ ꢀ }   ꢀ }   } 3 .6.5、match查询   match查询是一个标准查询，不管你需要全文本查询还是精确查询基本上都要用到它。   如果你使用 match 查询一个全文本字段，它会在真正查询之前用分析器先分析 match一下查询字符：   1 2 3 4 5 { ꢀ ꢀ\"match\": {   ꢀ ꢀ ꢀ ꢀ\"tweet\": \"About Search\"   ꢀ }   } 如果用 match下指定了一个确切值，在遇到数字，日期，布尔值或者 not_analyzed 的字符串时，它将为你搜索你   给定的值：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 { \"match\": { \"age\": ꢀ ꢀ26 ꢀ ꢀ ꢀ ꢀ ꢀ }}   { \"match\": { \"date\": ꢀ \"2014-09-01\" }}   { \"match\": { \"public\": true ꢀ ꢀ ꢀ ꢀ }}   { \"match\": { \"tag\": ꢀ ꢀ\"full_text\" }}   3 .7.6、bool查询   bool 查询可以用来合并多个条件查询结果的布尔逻辑，它包含一下操作符：   must :: 多个查询条件的完全匹配,相当于 and。   must_not :: 多个查询条件的相反匹配，相当于 not。   should :: 至少有一个查询条件匹配, 相当于 or。   这些参数可以分别继承一个查询条件或者一个查询条件的数组：   1 2 3 4 5 6 7 8 9 { ꢀ ꢀ\"bool\": {   ꢀ ꢀ ꢀ ꢀ\"must\": ꢀ ꢀ { \"term\": { \"folder\": \"inbox\" }},   ꢀ ꢀ ꢀ ꢀ\"must_not\": { \"term\": { \"tag\": ꢀ ꢀ\"spam\" }},   ꢀ ꢀ ꢀ ꢀ\"should\": [   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ { \"term\": { \"starred\": true ꢀ }},   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ { \"term\": { \"unread\": ꢀtrue ꢀ }}   ꢀ ꢀ ꢀ ]   ꢀ }   10 }   3 .8、过滤查询   前面讲过结构化查询，Elasticsearch也支持过滤查询，如term、range、match等。   示例：查询年龄为20岁的用户。   1 2 3 4 5 6 7 8 9 0 1 POST /itcast/person/_search   { ꢀ ꢀ\"query\": {   ꢀ ꢀ ꢀ ꢀ\"bool\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"filter\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"term\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 20   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ }   1 1 1 ꢀ ꢀ ꢀ }   ꢀ }   2 }   结果：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   查询和过滤的对比   一条过滤语句会询问每个文档的字段值是否包含着特定值。   查询语句会询问每个文档的字段值与特定值的匹配程度如何。   一条查询语句会计算每个文档与查询语句的相关性，会给出一个相关性评分 _score，并且 按照相关性对匹   配到的文档进行排序。 这种评分方式非常适用于一个没有完全配置结果的全文本搜索。   一个简单的文档列表，快速匹配运算并存入内存是十分方便的， 每个文档仅需要1个字节。这些缓存的过滤结果   集与后续请求的结合使用是非常高效的。   查询语句不仅要查找相匹配的文档，还需要计算每个文档的相关性，所以一般来说查询语句要比 过滤语句更耗   时，并且查询结果也不可缓存。   建议：   做精确匹配搜索时，最好用过滤语句，因为过滤语句可以缓存数据。   4、中文分词   4 .1、什么是分词   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   分词就是指将一个文本转化成一系列单词的过程，也叫文本分析，在Elasticsearch中称之为Analysis。   举例：我是中国人 --> 我/是/中国人   4 .2、分词api   指定分词器进行分词   1 2 3 4 5 POST /_analyze   { ꢀ ꢀ \"analyzer\":\"standard\",   ꢀ ꢀ \"text\":\"hello world\"   } 结果：   在结果中不仅可以看出分词的结果，还返回了该词在文本中的位置。   指定索引分词   1 2 3 4 5 6 POST /itcast/_analyze   { ꢀ ꢀ\"analyzer\": \"standard\",   ꢀ ꢀ\"field\": \"hobby\",   ꢀ ꢀ\"text\": \"听音乐\"   } 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   4 .4、中文分词   中文分词的难点在于，在汉语中没有明显的词汇分界点，如在英语中，空格可以作为分隔符，如果分隔不正确就会造   成歧义。   如：   我/爱/炒肉丝   我/爱/炒/肉丝   常用中文分词器，IK、jieba、THULAC等，推荐使用IK分词器。   IK Analyzer是一个开源的，基于java语言开发的轻量级的中文分词工具包。从2006年12月推出1.0版开始，   IKAnalyzer已经推出了3个大版本。最初，它是以开源项目Luence为应用主体的，结合词典分词和文法分析算   法的中文分词组件。新版本的IK Analyzer 3.0则发展为面向Java的公用分词组件，独立于Lucene项目，同时提   供了对Lucene的默认优化实现。   采用了特有的“正向迭代最细粒度切分算法“，具有80万字/秒的高速处理能力 采用了多子处理器分析模式，支   持：英文字母（IP地址、Email、URL）、数字（日期，常用中文数量词，罗马数字，科学计数法），中文词汇   （ 姓名、地名处理）等分词处理。 优化的词典存储，更小的内存占用。   IK分词器 Elasticsearch插件地址：https://github.com/medcl/elasticsearch-analysis-ik   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 #安装方法：将下载到的elasticsearch-analysis-ik-6.5.4.zip解压到/elasticsearch/plugins/ik目录下   即可。   2 3 4 5 6 7 8 9 mkdir es/plugins/ik   cp elasticsearch-analysis-ik-6.5.4.zip ./es/plugins/ik   #解压   unzip elasticsearch-analysis-ik-6.5.4.zip   #重启   ./bin/elasticsearch   测试：   1 2 3 4 5 POST /_analyze   { ꢀ ꢀ\"analyzer\": \"ik_max_word\",   ꢀ ꢀ\"text\": \"我是中国人\"   } 结果：   1 2 3 4 5 6 7 8 9 { ꢀ ꢀ\"tokens\": [   ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"token\": \"我\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"start_offset\": 0,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"end_offset\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"CN_CHAR\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"position\": 0   ꢀ ꢀ ꢀ },   10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"token\": \"是\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"start_offset\": 1,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"end_offset\": 2,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"CN_CHAR\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"position\": 1   ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"token\": \"中国人\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"start_offset\": 2,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"end_offset\": 5,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"CN_WORD\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"position\": 2   ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"token\": \"中国\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"start_offset\": 2,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"end_offset\": 4,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"CN_WORD\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"position\": 3   ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ {   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 3 3 3 3 3 3 3 2 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"token\": \"国人\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"start_offset\": 3,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"end_offset\": 5,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"CN_WORD\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"position\": 4   ꢀ ꢀ ꢀ }   3 4 5 6 7 8 ꢀ ]   9 }   可以看到，已经对中文进行了分词。   5、全文搜索   全文搜索两个最重要的方面是：   相关性（Relevance） 它是评价查询与其结果间的相关程度，并根据这种相关程度对结果排名的一种能力，这   种计算方式可以是 TF/IDF 方法、地理位置邻近、模糊相似，或其他的某些算法。   分词（Analysis） 它是将文本块转换为有区别的、规范化的 token 的一个过程，目的是为了创建倒排索引以及   查询倒排索引。   5 .1、构造数据   1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 PUT /itcast   { ꢀ ꢀ\"settings\": {   ꢀ ꢀ ꢀ ꢀ\"index\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"number_of_shards\": \"1\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"number_of_replicas\": \"0\"   ꢀ ꢀ ꢀ }   ꢀ },   ꢀ ꢀ\"mappings\": {   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 ꢀ ꢀ ꢀ ꢀ\"person\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"properties\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"text\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"integer\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"mail\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"keyword\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"type\": \"text\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"analyzer\":\"ik_max_word\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ }   ꢀ }   8 }   批量插入数据：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 9 POST http://172.16.55.185:9200/itcast/_bulk   {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   {\"name\":\"张三\",\"age\": 20,\"mail\": \"111@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球\"}   {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   {\"name\":\"李四\",\"age\": 21,\"mail\": \"222@qq.com\",\"hobby\":\"羽毛球、乒乓球、足球、篮球\"}   {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   {\"name\":\"王五\",\"age\": 22,\"mail\": \"333@qq.com\",\"hobby\":\"羽毛球、篮球、游泳、听音乐\"}   {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   10 {\"name\":\"赵六\",\"age\": 23,\"mail\": \"444@qq.com\",\"hobby\":\"跑步、游泳、篮球\"}   11 {\"index\":{\"_index\":\"itcast\",\"_type\":\"person\"}}   12 {\"name\":\"孙七\",\"age\": 24,\"mail\": \"555@qq.com\",\"hobby\":\"听音乐、看电影、羽毛球\"}   13   结果：   5 .2、单词搜索   1 2 3 4 5 6 7 8 9 0 1 2 3 POST /itcast/person/_search   { \"query\":{   \"match\":{   \"hobby\":\"音乐\"   } },   \"highlight\": {   ꢀ ꢀ ꢀ ꢀ\"fields\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {}   ꢀ ꢀ ꢀ }   1 1 1 1 1 ꢀ }   4 }   结果：   1 2 3 4 5 6 7 8 9 { ꢀ ꢀ\"took\": 9,   ꢀ ꢀ\"timed_out\": false,   ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   ꢀ ꢀ ꢀ ꢀ\"skipped\": 0,   ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ },   10   ꢀ ꢀ\"hits\": {   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48   49   50 }   ꢀ ꢀ ꢀ ꢀ\"total\": 2,   ꢀ ꢀ ꢀ ꢀ\"max_score\": 0.6841192,   ꢀ ꢀ ꢀ ꢀ\"hits\": [   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"itcast\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"person\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"Uv0cDWgBR-bSw8-LpdkZ\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 0.6841192,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"王五\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 22,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"mail\": \"333@qq.com\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": \"羽毛球、篮球、游泳、听音乐\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"highlight\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": [   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"羽毛球、篮球、游泳、听音乐\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ]   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"itcast\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"person\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"VP0cDWgBR-bSw8-LpdkZ\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 0.6841192,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"孙七\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 24,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"mail\": \"555@qq.com\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": \"听音乐、看电影、羽毛球\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"highlight\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": [   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"听音乐、看电影、羽毛球\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ]   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ]   ꢀ }   过程说明：   . 检查字段类型   1 爱好 hobby 字段是一个 text 类型（ 指定了IK分词器），这意味着查询字符串本身也应该被分词。   . 分析查询字符串 。   2 将查询的字符串 “音乐” 传入IK分词器中，输出的结果是单个项 音乐。因为只有一个单词项，所以 match 查询执   行的是单个底层 term 查询。   3. 查找匹配文档 。   用 term 查询在倒排索引中查找 “音乐” 然后获取一组包含该项的文档，本例的结果是文档：3 、5 。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   4. 为每个文档评分 。   用 term 查询计算每个文档相关度评分 _score ，这是种将 词频（term frequency，即词 “音乐” 在相关文档的   hobby 字段中出现的频率）和 反向文档频率（inverse document frequency，即词 “音乐” 在所有文档的   hobby 字段中出现的频率），以及字段的长度（即字段越短相关度越高）相结合的计算方式。   5 .3、多词搜索   1 2 3 4 5 6 7 8 9 0 1 2 POST /itcast/person/_search   { \"query\":{   \"match\":{   \"hobby\":\"音乐 篮球\"   } },   \"highlight\": {   ꢀ ꢀ ꢀ ꢀ\"fields\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {}   ꢀ ꢀ ꢀ }   1 1 1 1 ꢀ }   3 }   结果：   1 2 3 4 5 6 7 8 9 { ꢀ ꢀ\"took\": 3,   ꢀ ꢀ\"timed_out\": false,   ꢀ ꢀ\"_shards\": {   ꢀ ꢀ ꢀ ꢀ\"total\": 1,   ꢀ ꢀ ꢀ ꢀ\"successful\": 1,   ꢀ ꢀ ꢀ ꢀ\"skipped\": 0,   ꢀ ꢀ ꢀ ꢀ\"failed\": 0   ꢀ },   10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   ꢀ ꢀ\"hits\": {   ꢀ ꢀ ꢀ ꢀ\"total\": 4,   ꢀ ꢀ ꢀ ꢀ\"max_score\": 1.3192271,   ꢀ ꢀ ꢀ ꢀ\"hits\": [   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"itcast\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"person\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"Uv0cDWgBR-bSw8-LpdkZ\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 1.3192271,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"王五\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 22,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"mail\": \"333@qq.com\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": \"羽毛球、篮球、游泳、听音乐\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"highlight\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": [   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"羽毛球、篮球、游泳、听音乐\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ]   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   29   30   31   32   33   34   35   36   37   38   39   40   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80   81   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"itcast\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"person\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"VP0cDWgBR-bSw8-LpdkZ\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 0.81652206,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"孙七\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 24,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"mail\": \"555@qq.com\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": \"听音乐、看电影、羽毛球\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"highlight\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": [   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"听音乐、看电影、羽毛球\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ]   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"itcast\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"person\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"Vf0gDWgBR-bSw8-LOdm_\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 0.6987338,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"赵六\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 23,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"mail\": \"444@qq.com\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": \"跑步、游泳、篮球\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"highlight\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": [   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"跑步、游泳、篮球\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ]   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_index\": \"itcast\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_type\": \"person\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_id\": \"Uf0cDWgBR-bSw8-LpdkZ\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_score\": 0.50270504,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"_source\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"name\": \"李四\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"age\": 21,   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"mail\": \"222@qq.com\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": \"羽毛球、乒乓球、足球、篮球\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"highlight\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": [   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"羽毛球、乒乓球、足球、篮球\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ]   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ }   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   8 8 8 2 ꢀ ꢀ ꢀ ]   ꢀ }   3 4 }   可以看到，包含了“音乐”、“篮球”的数据都已经被搜索到了。   可是，搜索的结果并不符合我们的预期，因为我们想搜索的是既包含“音乐”又包含“篮球”的用户，显然结果返回   的“或”的关系。   在Elasticsearch中，可以指定词之间的逻辑关系，如下：   1 POST /itcast/person/_search   2 { 3 \"query\":{   \"match\":{   \"hobby\":{   4 5 6 \"query\":\"音乐 篮球\",   \"operator\":\"and\"   7 8 } 9 } 1 1 1 1 1 1 1 0 },   1 \"highlight\": {   ꢀ ꢀ ꢀ ꢀ\"fields\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {}   ꢀ ꢀ ꢀ }   2 3 4 5 ꢀ }   6 }   结果：   可以看到结果符合预期。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   前面我们测试了“OR” 和 “AND”搜索，这是两个极端，其实在实际场景中，并不会选取这2个极端，更有可能是选取这   种，或者说，只需要符合一定的相似度就可以查询到数据，在Elasticsearch中也支持这样的查询，通过   minimum_should_match来指定匹配度，如：70%；   示例：   1 2 3 4 5 6 7 8 9 0 1 2 3 4 { \"query\":{   \"match\":{   \"hobby\":{   \"query\":\"游泳 羽毛球\",   \"minimum_should_match\":\"80%\"   } } },   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 \"highlight\": {   ꢀ ꢀ ꢀ ꢀ\"fields\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {}   ꢀ ꢀ ꢀ }   ꢀ }   5 }   6 7 #结果：省略显示   8 \"hits\": {   9 0 1 2 3 4 ꢀ ꢀ ꢀ ꢀ\"total\": 4, #相似度为80%的情况下，查询到4条数据   ꢀ ꢀ ꢀ ꢀ\"max_score\": 1.621458,   ꢀ ꢀ ꢀ ꢀ\"hits\": [   ꢀ ꢀ ꢀ .........   ꢀ ꢀ ꢀ }   5 #设置40%进行测试：   6 {   7 \"query\":{   8 \"match\":{   \"hobby\":{   \"query\":\"游泳 羽毛球\",   \"minimum_should_match\":\"40%\"   9 0 1 2 } 3 } 4 },   5 \"highlight\": {   ꢀ ꢀ ꢀ ꢀ\"fields\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {}   ꢀ ꢀ ꢀ }   6 7 8 9 ꢀ }   0 }   1 #结果：   2 3 4 5 6 7 \"hits\": {   ꢀ ꢀ ꢀ ꢀ\"total\": 5, ꢀ#相似度为40%的情况下，查询到5条数据   ꢀ ꢀ ꢀ ꢀ\"max_score\": 1.621458,   ꢀ ꢀ ꢀ ꢀ\"hits\": [   ꢀ ꢀ ꢀ ........   ꢀ }   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   相似度应该多少合适，需要在实际的需求中进行反复测试，才可得到合理的值。   5 .4、组合搜索   在搜索时，也可以使用过滤器中讲过的bool组合查询，示例：   1 POST /itcast/person/_search   2 3 { 4 \"query\":{   \"bool\":{   \"must\":{   \"match\":{   5 6 7 8 \"hobby\":\"篮球\"   9 } 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 0 },   1 \"must_not\":{   \"match\":{   2 3 \"hobby\":\"音乐\"   4 } 5 },   6 \"should\":[   { 7 8 \"match\": {   \"hobby\":\"游泳\"   9 0 } 1 } 2 ] 3 } 4 },   5 \"highlight\": {   6 ꢀ ꢀ ꢀ ꢀ\"fields\": {   7 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {}   8 ꢀ ꢀ ꢀ }   ꢀ }   9 0 }   上面搜索的意思是：   搜索结果中必须包含篮球，不能包含音乐，如果包含了游泳，那么它的相似度更高。   结果：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   评分的计算规则   bool 查询会为每个文档计算相关度评分 _score ， 再将所有匹配的 must 和 should 语句的分数 _score 求和，   最后除以 must 和 should 语句的总数。   must_not 语句不会影响评分； 它的作用只是将不相关的文档排除。   ꢀ 默认情况下，should中的内容不是必须匹配的，如果查询语句中没有must，那么就会至少匹配其中一个。当然了，   也可以通过minimum_should_match参数进行控制，该值可以是数字也可以的百分比。   示例：   1 2 3 4 5 6 POST /itcast/person/_search   { \"query\":{   \"bool\":{   \"should\":[   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   7 { 8 \"match\": {   \"hobby\":\"游泳\"   9 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 0 } 1 },   { 2 3 \"match\": {   4 \"hobby\":\"篮球\"   5 } 6 },   { 7 8 \"match\": {   9 \"hobby\":\"音乐\"   0 } 1 } 2 ],   \"minimum_should_match\":2   3 4 } 5 },   6 \"highlight\": {   ꢀ ꢀ ꢀ ꢀ\"fields\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {}   ꢀ ꢀ ꢀ }   7 8 9 0 ꢀ }   1 }   minimum_should_match为2，意思是should中的三个词，至少要满足2个。   结果：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   5 .5、权重   有些时候，我们可能需要对某些词增加权重来影响该条数据的得分。如下：   搜索关键字为“游泳篮球”，如果结果中包含了“音乐”权重为10，包含了“跑步”权重为2。   1 2 3 4 5 6 7 8 9 0 1 2 POST /itcast/person/_search   { ꢀ ꢀ\"query\": {   ꢀ ꢀ ꢀ ꢀ\"bool\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"must\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"match\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"query\": \"游泳篮球\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"operator\": \"and\"   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   1 1 1 ꢀ ꢀ ꢀ ꢀ ꢀ },   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"should\": [   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ {   4 5 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"match\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"query\": \"音乐\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"boost\": 10   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   6 7 8 9 0 1 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ },   2 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ {   3 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"match\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"query\": \"跑步\",   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"boost\": 2   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   4 5 6 7 8 9 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ }   0 ꢀ ꢀ ꢀ ꢀ ꢀ ]   1 ꢀ ꢀ ꢀ }   2 ꢀ },   3 ꢀ ꢀ\"highlight\": {   4 ꢀ ꢀ ꢀ ꢀ\"fields\": {   5 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ\"hobby\": {}   ꢀ ꢀ ꢀ }   6 7 ꢀ }   8 }   结果：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   如果不设置权重的查询结果是这样：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6、Elasticsearch集群   6 .1、集群节点   ELasticsearch的集群是由多个节点组成的，通过cluster.name设置集群名称，并且用于区分其它的集群，每个节点   通过node.name指定节点的名称。   在Elasticsearch中，节点的类型主要有4种：   master节点   配置文件中node.master属性为true(默认为true)，就有资格被选为master节点。   master节点用于控制整个集群的操作。比如创建或删除索引，管理其它非master节点等。   data节点   配置文件中node.data属性为true(默认为true)，就有资格被设置成data节点。   data节点主要用于执行数据相关的操作。比如文档的CRUD。   客户端节点   配置文件中node.master属性和node.data属性均为false。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   该节点不能作为master节点，也不能作为data节点。   可以作为客户端节点，用于响应用户的请求，把请求转发到其他节点   部落节点   当一个节点配置tribe.*的时候，它是一个特殊的客户端，它可以连接多个集群，在所有连接的集群上执行   搜索和其他操作。   6 .2、搭建集群   1 2 3 4 5 6 7 8 9 #启动3个虚拟机，分别在3台虚拟机上部署安装Elasticsearch   mkdir /itcast/es-cluster   #分发到其它机器   scp -r es-cluster elsearch@192.168.40.134:/itcast   #node01的配置：   cluster.name: es-itcast-cluster   node.name: node01   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 0 node.master: true   1 node.data: true   2 network.host: 0.0.0.0   3 http.port: 9200   4 discovery.zen.ping.unicast.hosts: [\"192.168.40.133\",\"192.168.40.134\",\"192.168.40.135\"]   5 discovery.zen.minimum_master_nodes: 2   6 http.cors.enabled: true   7 http.cors.allow-origin: \"*\"   8 9 #node02的配置：   0 cluster.name: es-itcast-cluster   1 node.name: node02   2 node.master: true   3 node.data: true   4 network.host: 0.0.0.0   5 http.port: 9200   6 discovery.zen.ping.unicast.hosts: [\"192.168.40.133\",\"192.168.40.134\",\"192.168.40.135\"]   7 discovery.zen.minimum_master_nodes: 2   8 http.cors.enabled: true   9 http.cors.allow-origin: \"*\"   0 1 #node03的配置：   2 cluster.name: es-itcast-cluster   3 node.name: node02   4 node.master: true   5 node.data: true   6 network.host: 0.0.0.0   7 http.port: 9200   8 discovery.zen.ping.unicast.hosts: [\"192.168.40.133\",\"192.168.40.134\",\"192.168.40.135\"]   9 discovery.zen.minimum_master_nodes: 2   0 http.cors.enabled: true   1 http.cors.allow-origin: \"*\"   2 3 #分别启动3个节点   4 ./elasticsearch   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   45   查看集群：   创建索引：   查询集群状态：/_cluster/health   响应：   1 { 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   2 ꢀ ꢀcluster_name: \"es-itcast-cluster\"   ꢀ ꢀstatus: \"green\"   3 4 ꢀ ꢀtimed_out: false   5 ꢀ ꢀnumber_of_nodes: 3   6 ꢀ ꢀnumber_of_data_nodes: 3   ꢀ ꢀactive_primary_shards: 5   ꢀ ꢀactive_shards: 10   7 8 9 ꢀ ꢀrelocating_shards: 0   1 1 1 1 1 1 1 1 0 ꢀ ꢀinitializing_shards: 0   ꢀ ꢀunassigned_shards: 0   1 2 ꢀ ꢀdelayed_unassigned_shards: 0   ꢀ ꢀnumber_of_pending_tasks: 0   ꢀ ꢀnumber_of_in_flight_fetch: 0   ꢀ ꢀtask_max_waiting_in_queue_millis: 0   ꢀ ꢀactive_shards_percent_as_number: 100   3 4 5 6 7 }   集群状态的三种颜色：   颜色   意义   green   yellow   red   所有主要分片和复制分片都可用   所有主要分片可用，但不是所有复制分片都可用   不是所有的主要分片都可用   6 .3、分片和副本   为了将数据添加到Elasticsearch，我们需要索引(index)——一个存储关联数据的地方。实际上，索引只是一个用来   指向一个或多个分片(shards)的“逻辑命名空间(logical namespace)”.   一个分片(shard)是一个最小级别“工作单元(worker unit)”,它只是保存了索引中所有数据的一部分。   我们需要知道是分片就是一个Lucene实例，并且它本身就是一个完整的搜索引擎。应用程序不会和它直接通   信。   分片可以是主分片(primary shard)或者是复制分片(replica shard)。   索引中的每个文档属于一个单独的主分片，所以主分片的数量决定了索引最多能存储多少数据。   复制分片只是主分片的一个副本，它可以防止硬件故障导致的数据丢失，同时可以提供读请求，比如搜索或者   从别的shard取回文档。   当索引创建完成的时候，主分片的数量就固定了，但是复制分片的数量可以随时调整。   6 .4、故障转移   6 .4.1、将data节点停止   这里选择将node02停止：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   说明：   当前集群状态为黄色，表示主节点可用，副本节点不完全可用   过一段时间观察，发现节点列表中看不到node02，副本节点分配到了node01和node03，集群状态恢复到绿色。   将node02恢复：   1 ./node02/bin/elasticsearch   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   可以看到，node02恢复后，重新加入了集群，并且重新分配了节点信息。   6 .4.2、将master节点停止   接下来，测试将node01停止，也就是将主节点停止。   从结果中可以看出，集群对master进行了重新选举，选择node03为master。并且集群状态变成黄色。   等待一段时间后，集群状态从黄色变为了绿色：   恢复node01节点：   1 ./node01/bin/elasticsearch   重启之后，发现node01可以正常加入到集群中，集群状态依然为绿色：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   特别说明：   如果在配置文件中discovery.zen.minimum_master_nodes设置的不是N/2+1时，会出现脑裂问题，之前宕机   的主节点恢复后不会加入到集群。   6 .5、分布式文档   6 .5.1、路由   首先，来看个问题：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   如图所示：当我们想一个集群保存文档时，文档该存储到哪个节点呢？ 是随机吗？ 是轮询吗？   实际上，在ELasticsearch中，会采用计算的方式来确定存储到哪个节点，计算公式如下：   1 shard = hash(routing) % number_of_primary_shards   routing值是一个任意字符串，它默认是_id但也可以自定义。   这个routing字符串通过哈希函数生成一个数字，然后除以主切片的数量得到一个余数(remainder)，余数   的范围永远是0到number_of_primary_shards - 1，这个数字就是特定文档所在的分片。   这就是为什么创建了主分片后，不能修改的原因。   6 .5.2、文档的写操作   新建、索引和删除请求都是写(write)操作，它们必须在主分片上成功完成才能复制到相关的复制分片上。   下面我们罗列在主分片和复制分片上成功新建、索引或删除一个文档必要的顺序步骤：   1 . 客户端给 Node 1发送新建、索引或删除请求。   . 节点使用文档的 _id确定文档属于分片 0。它转发请求到 Node 3，分片 0位于这个节点上。   . Node 3在主分片上执行请求，如果成功，它转发请求到相应的位于 Node 1和 Node 2的复制节点上。当所有   的复制节点报告成功， Node 3报告成功到请求的节点，请求的节点再报告给客户端。   2 3 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   客户端接收到成功响应的时候，文档的修改已经被应用于主分片和所有的复制分片。你的修改生效了。   6 .5.3、搜索文档（单个文档）   文档能够从主分片或任意一个复制分片被检索。   下面我们罗列在主分片或复制分片上检索一个文档必要的顺序步骤：   1 . 客户端给 Node 1发送get请求。   . 节点使用文档的 _id确定文档属于分片 0。分片 0对应的复制分片在三个节点上都有。此时，它转发请求到   Node 2。   2 3. Node 2返回文档(document)给 Node 1然后返回给客户端。   对于读请求，为了平衡负载，请求节点会为每个请求选择不同的分片——它会循环所有分片副本。   可能的情况是，一个被索引的文档已经存在于主分片上却还没来得及同步到复制分片上。这时复制分片会报告文档未   找到，主分片会成功返回文档。一旦索引请求成功返回给用户，文档则在主分片和复制分片都是可用的。   6 .5.4、全文搜索   对于全文搜索而言，文档可能分散在各个节点上，那么在分布式的情况下，如何搜索文档呢？   搜索，分为2个阶段，搜索（query）+取回（fetch）。   搜索（query）   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   查询阶段包含以下三步：   1 . 客户端发送一个 search（搜索） 请求给 Node 3, Node 3创建了一个长度为 from+size的空优先级队   . Node 3 转发这个搜索请求到索引中每个分片的原本或副本。每个分片在本地执行这个查询并且结果将结果到   一个大小为 from+size的有序本地优先队列里去。   2 3. 每个分片返回document的ID和它优先队列里的所有document的排序值给协调节点 Node 3。 Node 3把这些   值合并到自己的优先队列里产生全局排序结果。   取回（fetch）   分发阶段由以下步骤构成：   1 . 协调节点辨别出哪个document需要取回，并且向相关分片发出 GET请求。   . 每个分片加载document并且根据需要 enrich 它们，然后再将document返回协调节点。   . 一旦所有的document都被取回，协调节点会将结果返回给客户端。   2 3 7、Java客户端   在Elasticsearch中，为java提供了2种客户端，一种是REST风格的客户端，另一种是Java API的客户端。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   https://www.elastic.co/guide/en/elasticsearch/client/index.html   7 .1、REST客户端   Elasticsearch提供了2种REST客户端，一种是低级客户端，一种是高级客户端。   Java Low Level REST Client：官方提供的低级客户端。该客户端通过http来连接Elasticsearch集群。用户在使   用该客户端时需要将请求数据手动拼接成Elasticsearch所需JSON格式进行发送，收到响应时同样也需要将返回   的JSON数据手动封装成对象。虽然麻烦，不过该客户端兼容所有的Elasticsearch版本。   Java High Level REST Client：官方提供的高级客户端。该客户端基于低级客户端实现，它提供了很多便捷的   API来解决低级客户端需要手动转换数据格式的问题。   7 .2、构造数据   1 2 3 4 5 6 7 8 9 POST /haoke/house/_bulk   {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}}   {\"id\":\"1001\",\"title\":\"整租 · 南丹大楼 1居室 7500\",\"price\":\"7500\"}   {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}}   {\"id\":\"1002\",\"title\":\"陆家嘴板块，精装设计一室一厅，可拎包入住诚意租。\",\"price\":\"8500\"}   {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}}   {\"id\":\"1003\",\"title\":\"整租 · 健安坊 1居室 4050\",\"price\":\"7500\"}   {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}}   1 1 1 1 1 0 {\"id\":\"1004\",\"title\":\"整租 · 中凯城市之光+视野开阔+景色秀丽+拎包入住\",\"price\":\"6500\"}   1 {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}}   2 {\"id\":\"1005\",\"title\":\"整租 · 南京西路品质小区 21213三轨交汇 配套齐* 拎包入住\",\"price\":\"6000\"}   3 {\"index\":{\"_index\":\"haoke\",\"_type\":\"house\"}}   4 {\"id\":\"1006\",\"title\":\"祥康里 简约风格 *南户型 拎包入住 看房随时\",\"price\":\"7000\"}   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   15   7 .3、REST低级客户端   7 .3.1、创建工程   创建工程itcast-elasticsearch：   1 2 3 4   xmlns=\"http://maven.apache.org/POM/4.0.0\"   ꢀ ꢀ ꢀ ꢀ xmlns:xsi=\"http://www.w3.org/2001/XMLSchema-instance\"   ꢀ ꢀ ꢀ ꢀ xsi:schemaLocation=\"http://maven.apache.org/POM/4.0.0   http://maven.apache.org/xsd/maven-4.0.0.xsd\">   5 6 7 8 9 10   11   12   13   14   15   16   17   18   19   20   21   22   23   24   25   26   27   28   29   30   31   32   33   34   ꢀ ꢀ4.0.0   ꢀ ꢀcn.itcast.elasticsearch   ꢀ ꢀitcast-elasticsearch   ꢀ ꢀ1.0-SNAPSHOT   ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀorg.elasticsearch.client   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀelasticsearch-rest-client   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ6.5.4   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀjunit   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀjunit   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ4.12   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀcom.fasterxml.jackson.core   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀjackson-databind   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ2.9.4   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ   ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ编译插件 -->   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀorg.apache.maven.plugins   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 3 3 3 3 4 4 4 4 4 4 5 6 7 8 9 0 1 2 3 4 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀmaven-compiler-plugin   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ3.2   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ1.8   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ1.8   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀUTF-8   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ   5   7 .3.2、编写测试用例   1 2 3 4 5 6 7 8 9 0 package cn.itcast.es.rest;   import com.fasterxml.jackson.databind.ObjectMapper;   import org.apache.http.HttpHost;   import org.apache.http.util.EntityUtils;   import org.elasticsearch.client.*;   import org.junit.After;   import org.junit.Before;   import org.junit.Test;   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 1 import java.io.IOException;   2 import java.util.HashMap;   3 import java.util.Map;   4 5 public class TestESREST {   6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 ꢀ ꢀprivate static final ObjectMapper MAPPER = new ObjectMapper();   ꢀ ꢀprivate RestClient restClient;   ꢀ ꢀ@Before   ꢀ ꢀpublic void init() {   ꢀ ꢀ ꢀ ꢀRestClientBuilder restClientBuilder = RestClient.builder(   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀnew HttpHost(\"172.16.55.185\", 9200, \"http\"),   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀnew HttpHost(\"172.16.55.185\", 9201, \"http\"),   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀnew HttpHost(\"172.16.55.185\", 9202, \"http\"));   ꢀ ꢀ ꢀ ꢀrestClientBuilder.setFailureListener(new RestClient.FailureListener() {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ@Override   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀpublic void onFailure(Node node) {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(\"出错了 -> \" + node);   ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ });   ꢀ ꢀ ꢀ ꢀthis.restClient = restClientBuilder.build();   ꢀ }   ꢀ ꢀ@After   ꢀ ꢀpublic void after() throws IOException {   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   40   41   42   43   44   45   46   47   48   49   50   51   52   53   54   55   56   57   58   59   60   61   62   63   64   65   66   67   68   69   70   71   72   73   74   75   76   77   78   79   80   81   82   83   84   85   86   87   88   89   90   91   92   ꢀ ꢀ ꢀ ꢀrestClient.close();   ꢀ }   ꢀ ꢀ// 查询集群状态   ꢀ ꢀ@Test   ꢀ ꢀpublic void testGetInfo() throws IOException {   ꢀ ꢀ ꢀ ꢀRequest request = new Request(\"GET\", \"/_cluster/state\");   ꢀ ꢀ ꢀ ꢀrequest.addParameter(\"pretty\",\"true\");   ꢀ ꢀ ꢀ ꢀResponse response = this.restClient.performRequest(request);   ꢀ ꢀ ꢀ ꢀSystem.out.println(response.getStatusLine());   ꢀ ꢀ ꢀ ꢀSystem.out.println(EntityUtils.toString(response.getEntity()));   ꢀ }   ꢀ ꢀ// 新增数据   ꢀ ꢀ@Test   ꢀ ꢀpublic void testCreateData() throws IOException {   ꢀ ꢀ ꢀ ꢀRequest request = new Request(\"POST\", \"/haoke/house\");   ꢀ ꢀ ꢀ ꢀMapString, Object> data = new HashMap<>();   ꢀ ꢀ ꢀ ꢀdata.put(\"id\",\"2001\");   ꢀ ꢀ ꢀ ꢀdata.put(\"title\",\"张江高科\");   ꢀ ꢀ ꢀ ꢀdata.put(\"price\",\"3500\");   ꢀ ꢀ ꢀ ꢀrequest.setJsonEntity(MAPPER.writeValueAsString(data));   ꢀ ꢀ ꢀ ꢀResponse response = this.restClient.performRequest(request);   ꢀ ꢀ ꢀ ꢀSystem.out.println(response.getStatusLine());   ꢀ ꢀ ꢀ ꢀSystem.out.println(EntityUtils.toString(response.getEntity()));   ꢀ }   ꢀ ꢀ// 根据id查询数据   ꢀ ꢀ@Test   ꢀ ꢀpublic void testQueryData() throws IOException {   ꢀ ꢀ ꢀ ꢀRequest request = new Request(\"GET\", \"/haoke/house/G0pfE2gBCKv8opxuRz1y\");   ꢀ ꢀ ꢀ ꢀResponse response = this.restClient.performRequest(request);   ꢀ ꢀ ꢀ ꢀSystem.out.println(response.getStatusLine());   ꢀ ꢀ ꢀ ꢀSystem.out.println(EntityUtils.toString(response.getEntity()));   ꢀ }   ꢀ ꢀ// 搜索数据   ꢀ ꢀ@Test   ꢀ ꢀpublic void testSearchData() throws IOException {   ꢀ ꢀ ꢀ ꢀRequest request = new Request(\"POST\", \"/haoke/house/_search\");   ꢀ ꢀ ꢀ ꢀString searchJson = \"{\\\"query\\\": {\\\"match\\\": {\\\"title\\\": \\\"拎包入住\\\"}}}\";   ꢀ ꢀ ꢀ ꢀrequest.setJsonEntity(searchJson);   ꢀ ꢀ ꢀ ꢀrequest.addParameter(\"pretty\",\"true\");   ꢀ ꢀ ꢀ ꢀResponse response = this.restClient.performRequest(request);   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   9 9 9 9 9 9 9 3 ꢀ ꢀ ꢀ ꢀSystem.out.println(response.getStatusLine());   4 ꢀ ꢀ ꢀ ꢀSystem.out.println(EntityUtils.toString(response.getEntity()));   ꢀ }   5 6 7 8 }   9 从使用中，可以看出，基本和我们使用RESTful api使用几乎是一致的。   7 .4、REST高级客户端   7 .4.1、引入依赖   1 2 3 4 5   ꢀ ꢀorg.elasticsearch.client   ꢀ ꢀelasticsearch-rest-high-level-client   ꢀ ꢀ6.5.4     7 .4.2、编写测试用例   1 2 3 4 5 6 7 8 9 package cn.itcast.es.rest;   import org.apache.http.HttpHost;   import org.elasticsearch.action.ActionListener;   import org.elasticsearch.action.delete.DeleteRequest;   import org.elasticsearch.action.delete.DeleteResponse;   import org.elasticsearch.action.get.GetRequest;   import org.elasticsearch.action.get.GetResponse;   import org.elasticsearch.action.index.IndexRequest;   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 0 import org.elasticsearch.action.index.IndexResponse;   1 import org.elasticsearch.action.search.SearchRequest;   2 import org.elasticsearch.action.search.SearchResponse;   3 import org.elasticsearch.action.update.UpdateRequest;   4 import org.elasticsearch.action.update.UpdateResponse;   5 import org.elasticsearch.client.RequestOptions;   6 import org.elasticsearch.client.RestClient;   7 import org.elasticsearch.client.RestClientBuilder;   8 import org.elasticsearch.client.RestHighLevelClient;   9 import org.elasticsearch.common.Strings;   0 import org.elasticsearch.common.unit.TimeValue;   1 import org.elasticsearch.index.query.QueryBuilders;   2 import org.elasticsearch.search.SearchHit;   3 import org.elasticsearch.search.SearchHits;   4 import org.elasticsearch.search.builder.SearchSourceBuilder;   5 import org.elasticsearch.search.fetch.subphase.FetchSourceContext;   6 import org.junit.After;   7 import org.junit.Before;   8 import org.junit.Test;   9 0 import java.util.HashMap;   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 1 import java.util.Map;   2 import java.util.concurrent.TimeUnit;   3 4 public class TestRestHighLevel {   5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 ꢀ ꢀprivate RestHighLevelClient client;   ꢀ ꢀ@Before   ꢀ ꢀpublic void init() {   ꢀ ꢀ ꢀ ꢀRestClientBuilder restClientBuilder = RestClient.builder(   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀnew HttpHost(\"172.16.55.185\", 9200, \"http\"),   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀnew HttpHost(\"172.16.55.185\", 9201, \"http\"),   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀnew HttpHost(\"172.16.55.185\", 9202, \"http\"));   ꢀ ꢀ ꢀ ꢀthis.client = new RestHighLevelClient(restClientBuilder);   ꢀ }   ꢀ ꢀ@After   ꢀ ꢀpublic void after() throws Exception {   ꢀ ꢀ ꢀ ꢀthis.client.close();   ꢀ }   ꢀ ꢀ/**   ꢀ ꢀ * 新增文档，同步操作   ꢀ ꢀ *   ꢀ ꢀ * @throws Exception   ꢀ ꢀ */   ꢀ ꢀ@Test   ꢀ ꢀpublic void testCreate() throws Exception {   ꢀ ꢀ ꢀ ꢀMapString, Object> data = new HashMap<>();   ꢀ ꢀ ꢀ ꢀdata.put(\"id\", \"2002\");   ꢀ ꢀ ꢀ ꢀdata.put(\"title\", \"南京西路 拎包入住 一室一厅\");   ꢀ ꢀ ꢀ ꢀdata.put(\"price\", \"4500\");   ꢀ ꢀ ꢀ ꢀIndexRequest indexRequest = new IndexRequest(\"haoke\", \"house\")   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ .source(data);   ꢀ ꢀ ꢀ ꢀIndexResponse indexResponse = this.client.index(indexRequest,   RequestOptions.DEFAULT);   70   71   72   73   74   75   76   77   78   79   80   81   82   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"id->\" + indexResponse.getId());   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"index->\" + indexResponse.getIndex());   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"type->\" + indexResponse.getType());   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"version->\" + indexResponse.getVersion());   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"result->\" + indexResponse.getResult());   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"shardInfo->\" + indexResponse.getShardInfo());   ꢀ }   ꢀ ꢀ/**   ꢀ ꢀ * 新增文档，异步操作   ꢀ ꢀ *   ꢀ ꢀ * @throws Exception   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   83   84   85   86   87   88   89   90   91   92   93   94   95   ꢀ ꢀ */   ꢀ ꢀ@Test   ꢀ ꢀpublic void testCreateAsync() throws Exception {   ꢀ ꢀ ꢀ ꢀMapString, Object> data = new HashMap<>();   ꢀ ꢀ ꢀ ꢀdata.put(\"id\", \"2003\");   ꢀ ꢀ ꢀ ꢀdata.put(\"title\", \"南京东路 最新房源 二室一厅\");   ꢀ ꢀ ꢀ ꢀdata.put(\"price\", \"5500\");   ꢀ ꢀ ꢀ ꢀIndexRequest indexRequest = new IndexRequest(\"haoke\", \"house\")   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ .source(data);   ꢀ ꢀ ꢀ ꢀthis.client.indexAsync(indexRequest, RequestOptions.DEFAULT, new   ActionListenerIndexResponse>() {   9 9 9 9 6 7 8 9 ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ@Override   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀpublic void onResponse(IndexResponse indexResponse) {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(\"id->\" + indexResponse.getId());   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(\"index->\" + indexResponse.getIndex());   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(\"type->\" + indexResponse.getType());   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(\"version->\" + indexResponse.getVersion());   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(\"result->\" + indexResponse.getResult());   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(\"shardInfo->\" + indexResponse.getShardInfo());   ꢀ ꢀ ꢀ ꢀ ꢀ }   1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 1 00   01   02   03   04   05   06   07   08   09   10   11   12   13   14   15   16   17   18   19   20   21   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ@Override   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀpublic void onFailure(Exception e) {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(e);   ꢀ ꢀ ꢀ ꢀ ꢀ }   ꢀ ꢀ ꢀ });   ꢀ ꢀ ꢀ ꢀ   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"ok\");   ꢀ ꢀ ꢀ ꢀThread.sleep(20000);   ꢀ }   ꢀ ꢀ@Test   ꢀ ꢀpublic void testQuery() throws Exception {   ꢀ ꢀ ꢀ ꢀGetRequest getRequest = new GetRequest(\"haoke\", \"house\",   \"GkpdE2gBCKv8opxuOj12\");   122   123   124   125   126   127   128   129   130   131   132   133   ꢀ ꢀ ꢀ ꢀ// 指定返回的字段   ꢀ ꢀ ꢀ ꢀString[] includes = new String[]{\"title\", \"id\"};   ꢀ ꢀ ꢀ ꢀString[] excludes = Strings.EMPTY_ARRAY;   ꢀ ꢀ ꢀ ꢀFetchSourceContext fetchSourceContext =   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀnew FetchSourceContext(true, includes, excludes);   ꢀ ꢀ ꢀ ꢀgetRequest.fetchSourceContext(fetchSourceContext);   ꢀ ꢀ ꢀ ꢀGetResponse response = this.client.get(getRequest, RequestOptions.DEFAULT);   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"数据 -> \" + response.getSource());   ꢀ }   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   134   135   136   137   138   139   140   141   142   ꢀ ꢀ/**   ꢀ ꢀ * 判断是否存在   ꢀ ꢀ *   ꢀ ꢀ * @throws Exception   ꢀ ꢀ */   ꢀ ꢀ@Test   ꢀ ꢀpublic void testExists() throws Exception {   ꢀ ꢀ ꢀ ꢀGetRequest getRequest = new GetRequest(\"haoke\", \"house\",   GkpdE2gBCKv8opxuOj12\");   \" 143   144   145   146   147   148   149   150   151   152   153   154   155   156   157   158   159   ꢀ ꢀ ꢀ ꢀ// 不返回的字段   ꢀ ꢀ ꢀ ꢀgetRequest.fetchSourceContext(new FetchSourceContext(false));   ꢀ ꢀ ꢀ ꢀboolean exists = this.client.exists(getRequest, RequestOptions.DEFAULT);   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"exists -> \" + exists);   ꢀ }   ꢀ ꢀ/**   ꢀ ꢀ * 删除数据   ꢀ ꢀ *   ꢀ ꢀ * @throws Exception   ꢀ ꢀ */   ꢀ ꢀ@Test   ꢀ ꢀpublic void testDelete() throws Exception {   ꢀ ꢀ ꢀ ꢀDeleteRequest deleteRequest = new DeleteRequest(\"haoke\", \"house\",   GkpdE2gBCKv8opxuOj12\");   \" 160   ꢀ ꢀ ꢀ ꢀDeleteResponse response = this.client.delete(deleteRequest,   RequestOptions.DEFAULT);   161   162   163   164   165   166   167   168   169   170   171   ꢀ ꢀ ꢀ ꢀSystem.out.println(response.status());// OK or NOT_FOUND   ꢀ }   ꢀ ꢀ/**   ꢀ ꢀ * 更新数据   ꢀ ꢀ *   ꢀ ꢀ * @throws Exception   ꢀ ꢀ */   ꢀ ꢀ@Test   ꢀ ꢀpublic void testUpdate() throws Exception {   ꢀ ꢀ ꢀ ꢀUpdateRequest updateRequest = new UpdateRequest(\"haoke\", \"house\",   \"G0pfE2gBCKv8opxuRz1y\");   172   173   174   175   176   177   178   179   ꢀ ꢀ ꢀ ꢀMapString, Object> data = new HashMap<>();   ꢀ ꢀ ꢀ ꢀdata.put(\"title\", \"张江高科2\");   ꢀ ꢀ ꢀ ꢀdata.put(\"price\", \"5000\");   ꢀ ꢀ ꢀ ꢀupdateRequest.doc(data);   ꢀ ꢀ ꢀ ꢀUpdateResponse response = this.client.update(updateRequest,   RequestOptions.DEFAULT);   1 80   81   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"version -> \" + response.getVersion());   ꢀ }   1 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   182   183   184   185   186   187   188   189   190   191   192   193   194   195   196   197   198   199   200   201   ꢀ ꢀ/**   ꢀ ꢀ * 测试搜索   ꢀ ꢀ *   ꢀ ꢀ * @throws Exception   ꢀ ꢀ */   ꢀ ꢀ@Test   ꢀ ꢀpublic void testSearch() throws Exception {   ꢀ ꢀ ꢀ ꢀSearchRequest searchRequest = new SearchRequest(\"haoke\");   ꢀ ꢀ ꢀ ꢀsearchRequest.types(\"house\");   ꢀ ꢀ ꢀ ꢀSearchSourceBuilder sourceBuilder = new SearchSourceBuilder();   ꢀ ꢀ ꢀ ꢀsourceBuilder.query(QueryBuilders.matchQuery(\"title\", \"拎包入住\"));   ꢀ ꢀ ꢀ ꢀsourceBuilder.from(0);   ꢀ ꢀ ꢀ ꢀsourceBuilder.size(5);   ꢀ ꢀ ꢀ ꢀsourceBuilder.timeout(new TimeValue(60, TimeUnit.SECONDS));   ꢀ ꢀ ꢀ ꢀsearchRequest.source(sourceBuilder);   ꢀ ꢀ ꢀ ꢀSearchResponse search = this.client.search(searchRequest,   RequestOptions.DEFAULT);   2 2 2 2 2 2 2 2 2 02   03   04   05   06   07   08   ꢀ ꢀ ꢀ ꢀSystem.out.println(\"搜索到 \" + search.getHits().totalHits + \" 条数据.\");   ꢀ ꢀ ꢀ ꢀSearchHits hits = search.getHits();   ꢀ ꢀ ꢀ ꢀfor (SearchHit hit : hits) {   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀSystem.out.println(hit.getSourceAsString());   ꢀ ꢀ ꢀ }   ꢀ }   09 }   10   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 13:32:12 "},"hm/0_pdf课件/note02.html":{"url":"hm/0_pdf课件/note02.html","title":"part02","keywords":"","body":" 课程介绍   Nginx日志分析系统   Filebeat入门学习   Metricbeat入门学习   Kibana入门学习   Logstash入门学习   综合练习   1、Nginx日志分析系统   1 .1、项目需求   Nginx是一款非常优秀的web服务器，往往nginx服务会作为项目的访问入口，那么，nginx的性能保障就变得非常重   要了，如果nginx的运行出现了问题就会对项目有较大的影响，所以，我们需要对nginx的运行有监控措施，实时掌握   nginx的运行情况，那就需要收集nginx的运行指标和分析nginx的运行日志了。   1 .2、业务流程   说明：   通过Beats采集Nginx的指标数据和日志数据   Beats采集到数据后发送到Elasticsearch中   Kibana读取数据进行分析   用户通过Kibana进行查看分析报表   2、部署安装Nginx   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 9 tar -xvf nginx-1.11.6.tar.gz   yum -y install pcre-devel zlib-devel   ./configure   make install   #启动   cd /usr/local/nginx/sbin/   ./nginx   #通过浏览器访问页面并且查看日志   10 #访问地址：http://192.168.40.133/   11 tail -f /usr/local/nginx/logs/access.log   3、Beats 简介   官网：https://www.elastic.co/cn/products/beats   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   Beats系列产品：   4、Filebeat   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   4 .1、架构   用于监控、收集服务器日志文件.   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   4 .2、部署与运行   下载（或使用资料中提供的安装包，版本为：ﬁlebeat-6.5.4）：https://www.elastic.co/downloads/beats   1 2 3 4 5 6 7 8 9 0 mkdir /itcast/beats   tar -xvf filebeat-6.5.4-linux-x86_64.tar.gz   cd filebeat-6.5.4-linux-x86_64   #创建如下配置文件 itcast.yml   filebeat.inputs:   - type: stdin   enabled: true   setup.template.settings:   index.number_of_shards: 3   1 1 1 1 1 1 1 1 1 1 1 output.console:   2 3 4 pretty: true   enable: true   ꢀ 5 #启动filebeat   6 ./filebeat -e -c itcast.yml   7 8 #输入hello运行结果如下：   9 hello   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 0 {   1 ꢀ\"@timestamp\": \"2019-01-12T12:50:03.585Z\",   ꢀ\"@metadata\": { #元数据信息   ꢀ ꢀ\"beat\": \"filebeat\",   ꢀ ꢀ\"type\": \"doc\",   ꢀ ꢀ\"version\": \"6.5.4\"   },   2 3 4 5 6 7 ꢀ\"source\": \"\",   8 ꢀ\"offset\": 0,   9 ꢀ\"message\": \"hello\", ꢀ#输入的内容   ꢀ\"prospector\": { #标准输入勘探器   ꢀ ꢀ\"type\": \"stdin\"   },   0 1 2 3 ꢀ\"input\": { ꢀ#控制台标准输入   ꢀ ꢀ\"type\": \"stdin\"   },   4 5 6 ꢀ\"beat\": { #beat版本以及主机信息   ꢀ ꢀ\"name\": \"itcast01\",   ꢀ ꢀ\"hostname\": \"itcast01\",   ꢀ ꢀ\"version\": \"6.5.4\"   },   7 8 9 0 1 ꢀ\"host\": {   2 ꢀ ꢀ\"name\": \"itcast01\"   } 3 4 }   5 4 .3、读取文件   1 2 3 4 5 6 7 8 9 #配置读取文件项 itcast-log.yml   filebeat.inputs:   - type: log   enabled: true   paths:   - /itcast/beats/logs/*.log   setup.template.settings:   index.number_of_shards: 3   1 1 1 1 1 1 1 1 1 1 2 2 2 2 0 output.console:   1 2 3 pretty: true   enable: true   ꢀ 4 #启动filebeat   5 ./filebeat -e -c itcast-log.yml   6 7 #/haoke/beats/logs下创建a.log文件，并输入如下内容   8 hello   9 world   0 1 #观察filebeat输出   2 {   3 ꢀ\"@timestamp\": \"2019-01-12T14:16:10.192Z\",   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 5 5 5 5 5 5 6 6 6 6 6 6 6 6 6 6 7 7 7 4 ꢀ\"@metadata\": {   ꢀ ꢀ\"beat\": \"filebeat\",   ꢀ ꢀ\"type\": \"doc\",   ꢀ ꢀ\"version\": \"6.5.4\"   },   5 6 7 8 9 ꢀ\"host\": {   0 ꢀ ꢀ\"name\": \"itcast01\"   },   1 2 ꢀ\"source\": \"/haoke/beats/logs/a.log\",   ꢀ\"offset\": 0,   3 4 ꢀ\"message\": \"hello\",   ꢀ\"prospector\": {   ꢀ ꢀ\"type\": \"log\"   },   5 6 7 8 ꢀ\"input\": {   9 ꢀ ꢀ\"type\": \"log\"   },   0 1 ꢀ\"beat\": {   2 ꢀ ꢀ\"version\": \"6.5.4\",   ꢀ ꢀ\"name\": \"itcast01\",   ꢀ ꢀ\"hostname\": \"itcast01\"   } 3 4 5 6 }   7 {   8 ꢀ\"@timestamp\": \"2019-01-12T14:16:10.192Z\",   9 ꢀ\"@metadata\": {   ꢀ ꢀ\"beat\": \"filebeat\",   ꢀ ꢀ\"type\": \"doc\",   ꢀ ꢀ\"version\": \"6.5.4\"   },   0 1 2 3 4 ꢀ\"prospector\": {   ꢀ ꢀ\"type\": \"log\"   },   5 6 7 ꢀ\"input\": {   8 ꢀ ꢀ\"type\": \"log\"   },   9 0 ꢀ\"beat\": {   1 ꢀ ꢀ\"version\": \"6.5.4\",   ꢀ ꢀ\"name\": \"itcast01\",   ꢀ ꢀ\"hostname\": \"itcast01\"   },   2 3 4 5 ꢀ\"host\": {   6 ꢀ ꢀ\"name\": \"itcast01\"   },   7 8 ꢀ\"source\": \"/haoke/beats/logs/a.log\",   ꢀ\"offset\": 6,   9 0 ꢀ\"message\": \"world\"   1 }   2 可以看出，已经检测到日志文件有更新，立刻就会读取到更新的内容，并且输出到控制台。   4 .4、自定义字段   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 9 0 1 #配置读取文件项 itcast-log.yml   filebeat.inputs:   - type: log   enabled: true   paths:   ꢀ ꢀ- /itcast/beats/logs/*.log   tags: [\"web\"] ꢀ #添加自定义tag，便于后续的处理   fields: ꢀ#添加自定义字段   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 4 4 4 4 4 4 4 5 5 5 5 ꢀ from: itcast-im   fields_under_root: true #true为添加到根节点，false为添加到子节点中   2 setup.template.settings:   index.number_of_shards: 3   4 output.console:   3 5 6 7 pretty: true   enable: true   ꢀ 8 #启动filebeat   9 ./filebeat -e -c itcast-log.yml   0 1 #/haoke/beats/logs下创建a.log文件，并输入如下内容   2 123   3 4 #执行效果   5 {   6 ꢀ\"@timestamp\": \"2019-01-12T14:37:19.845Z\",   7 ꢀ\"@metadata\": {   ꢀ ꢀ\"beat\": \"filebeat\",   ꢀ ꢀ\"type\": \"doc\",   ꢀ ꢀ\"version\": \"6.5.4\"   },   8 9 0 1 2 ꢀ\"offset\": 0,   ꢀ\"tags\": [   3 4 ꢀ ꢀ\"haoke-im\"   ],   5 6 ꢀ\"prospector\": {   ꢀ ꢀ\"type\": \"log\"   },   7 8 9 ꢀ\"beat\": {   0 ꢀ ꢀ\"name\": \"itcast01\",   ꢀ ꢀ\"hostname\": \"itcast01\",   ꢀ ꢀ\"version\": \"6.5.4\"   },   1 2 3 4 ꢀ\"host\": {   5 ꢀ ꢀ\"name\": \"itcast01\"   },   6 7 ꢀ\"source\": \"/itcast/beats/logs/a.log\",   ꢀ\"message\": \"123\",   ꢀ\"input\": {   8 9 0 ꢀ ꢀ\"type\": \"log\"   },   1 2 ꢀ\"from\": \"haoke-im\"   3 }   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   4 .5、输出到Elasticsearch   1 2 3 4 5 6 7 8 9 0 # itcast-log.yml   filebeat.inputs:   - type: log   enabled: true   paths:   ꢀ - /itcast/beats/logs/*.log   tags: [\"haoke-im\"]   fields:   ꢀ from: haoke-im   fields_under_root: false   1 1 1 1 1 1 setup.template.settings:   index.number_of_shards: 3 #指定索引的分区数   3 output.elasticsearch: #指定ES的配置   hosts: [\"192.168.1.7:9200\",\"192.168.1.7:9201\",\"192.168.1.7:9202\"]   2 4 在日志文件中输入新的内容进行测试：   查看数据：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   4 .6、Filebeat工作原理   Filebeat由两个主要组件组成：prospector 和 harvester。   harvester：   负责读取单个文件的内容。   如果文件在读取时被删除或重命名，Filebeat将继续读取文件。   prospector   prospector 负责管理harvester并找到所有要读取的文件来源。   如果输入类型为日志，则查找器将查找路径匹配的所有文件，并为每个文件启动一个harvester。   Filebeat目前支持两种prospector类型：log和stdin。   Filebeat如何保持文件的状态   Filebeat 保存每个文件的状态并经常将状态刷新到磁盘上的注册文件中。   该状态用于记住harvester正在读取的最后偏移量，并确保发送所有日志行。   如果输出（例如Elasticsearch或Logstash）无法访问，Filebeat会跟踪最后发送的行，并在输出再次可用   时继续读取文件。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   在Filebeat运行时，每个prospector内存中也会保存的文件状态信息，当重新启动Filebeat时，将使用注册   文件的数据来重建文件状态，Filebeat将每个harvester在从保存的最后偏移量继续读取。   文件状态记录在data/registry文件中。   启动命令：   1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 ./filebeat -e -c itcast.yml   ./filebeat -e -c itcast.yml -d \"publish\"   #参数说明   -e: 输出到标准输出，默认输出到syslog和logs下   -c: 指定配置文件   -d: 输出debug信息   #测试： ./filebeat -e -c itcast-log.yml -d \"publish\"   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 DEBUG ꢀ [publish] ꢀ ꢀ ꢀ pipeline/processor.go:308 ꢀ ꢀ ꢀ Publish event: {   ꢀ\"@timestamp\": \"2019-01-12T15:03:50.820Z\",   ꢀ\"@metadata\": {   ꢀ ꢀ\"beat\": \"filebeat\",   ꢀ ꢀ\"type\": \"doc\",   ꢀ ꢀ\"version\": \"6.5.4\"   },   ꢀ\"offset\": 0,   ꢀ\"tags\": [   ꢀ ꢀ\"haoke-im\"   ],   ꢀ\"input\": {   ꢀ ꢀ\"type\": \"log\"   },   ꢀ\"prospector\": {   ꢀ ꢀ\"type\": \"log\"   },   ꢀ\"beat\": {   ꢀ ꢀ\"name\": \"itcast01\",   ꢀ ꢀ\"hostname\": \"itcast01\",   ꢀ ꢀ\"version\": \"6.5.4\"   },   ꢀ\"source\": \"/haoke/beats/logs/a.log\",   ꢀ\"fields\": {   ꢀ ꢀ\"from\": \"haoke-im\"   },   ꢀ\"host\": {   ꢀ ꢀ\"name\": \"itcast01\"   },   ꢀ\"message\": \"456\"   0 }   1 4 .7、读取Nginx日志文件   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 9 # itcast-nginx.yml   filebeat.inputs:   - type: log   enabled: true   paths:   ꢀ ꢀ- /usr/local/nginx/logs/*.log   tags: [\"nginx\"]   setup.template.settings:   index.number_of_shards: 3 #指定索引的分区数   10 output.elasticsearch: #指定ES的配置   11   hosts: [\"192.168.40.133:9200\",\"192.168.40.134:9200\",\"192.168.40.135:9200\"]   1 2 #启动   ./filebeat -e -c itcast-nginx.yml   启动后，可以在Elasticsearch中看到索引以及查看数据：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   可以看到，在message中已经获取到了nginx的日志，但是，内容并没有经过处理，只是读取到原数据，那么对于我   们后期的操作是不利的，有办法解决吗？   4 .7、Module   前面要想实现日志数据的读取以及处理都是自己手动配置的，其实，在Filebeat中，有大量的Module，可以简化我   们的配置，直接就可以使用，如下：   1 2 3 4 5 6 7 8 9 ./filebeat modules list   Enabled:   Disabled:   apache2   auditd   elasticsearch   haproxy   1 1 1 0 icinga   1 iis   2 kafka   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 1 1 1 1 1 1 2 2 2 2 2 3 kibana   4 logstash   5 mongodb   6 mysql   7 nginx   8 osquery   9 postgresql   0 redis   1 suricata   2 system   3 traefik   4 可以看到，内置了很多的module，但是都没有启用，如果需要启用需要进行enable操作：   1 2 3 4 5 6 7 8 9 ./filebeat modules enable nginx #启动   ./filebeat modules disable nginx #禁用   Enabled:   nginx   Disabled:   apache2   auditd   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 0 elasticsearch   1 haproxy   2 icinga   3 iis   4 kafka   5 kibana   6 logstash   7 mongodb   8 mysql   9 redis   0 osquery   1 postgresql   2 suricata   3 system   4 traefik   可以发现，nginx的module已经被启用。   4 .7.1、nginx module 配置   1 2 3 4 5 6 7 8 - module: nginx   ꢀ# Access logs   access:   ꢀ enabled: true   ꢀ var.paths: [\"/usr/local/nginx/logs/access.log*\"]   ꢀ ꢀ# Set custom paths for the log files. If left empty,   ꢀ ꢀ# Filebeat will choose the paths depending on your OS.   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   9 10   11   12   13   14   15   16   17   18   ꢀ ꢀ#var.paths:   ꢀ# Error logs   error:   ꢀ enabled: true   ꢀ var.paths: [\"/usr/local/nginx/logs/error.log*\"]   ꢀ ꢀ# Set custom paths for the log files. If left empty,   ꢀ ꢀ# Filebeat will choose the paths depending on your OS.   ꢀ ꢀ#var.paths:   4 .7.2、配置ﬁlebeat   1 2 3 4 5 6 7 8 9 0 #vim itcast-nginx.yml   filebeat.inputs:   #- type: log   # enabled: true   # paths:   # ꢀ - /usr/local/nginx/logs/*.log   # tags: [\"nginx\"]   setup.template.settings:   index.number_of_shards: 3   1 1 1 1 1 1 1 output.elasticsearch:   hosts: [\"192.168.40.133:9200\",\"192.168.40.134:9200\",\"192.168.40.135:9200\"]   3 filebeat.config.modules:   2 4 path: ${path.config}/modules.d/*.yml   reload.enabled: false   5 4 .7.3、测试   1 2 3 4 ./filebeat -e -c itcast-nginx.yml   #启动会出错，如下   ERROR ꢀ fileset/factory.go:142 Error loading pipeline: Error loading pipeline for   fileset nginx/access: This module requires the following Elasticsearch plugins:   ingest-user-agent, ingest-geoip. You can install them by running the following   commands on all the Elasticsearch nodes:   5 6 7 8 9 ꢀ ꢀsudo bin/elasticsearch-plugin install ingest-user-agent   ꢀ ꢀsudo bin/elasticsearch-plugin install ingest-geoip   ꢀ ꢀ   #解决：需要在Elasticsearch中安装ingest-user-agent、ingest-geoip插件   #在资料中可以找到，ingest-user-agent.tar、ingest-geoip.tar、ingest-geoip-conf.tar 3个文件   10 #其中，ingest-user-agent.tar、ingest-geoip.tar解压到plugins下   11 #ingest-geoip-conf.tar解压到config下   12 #问题解决。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   测试发现，数据已经写入到了Elasticsearch中，并且拿到的数据更加明确了：   当然了，其他的Module的用法参加官方文档：   https://www.elastic.co/guide/en/beats/ﬁlebeat/current/ﬁlebeat-modules.html   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   5、Metricbeat   定期收集操作系统或应用服务的指标数据   存储到Elasticsearch中，进行实时分析   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   5 .1、Metricbeat组成   Metricbeat有2部分组成，一部分是Module，另一部分为Metricset。   Module   收集的对象，如：mysql、redis、nginx、操作系统等；   Metricset   收集指标的集合，如：cpu、memory、network等；   以Redis Module为例：   5 .2、部署与收集系统指标   1 2 3 4 5 6 7 8 9 0 tar -xvf metricbeat-6.5.4-linux-x86_64.tar.gz   cd metricbeat-6.5.4-linux-x86_64   vim metricbeat.yml   metricbeat.config.modules:   path: ${path.config}/modules.d/*.yml   reload.enabled: false   setup.template.settings:   index.number_of_shards: 1   index.codec: best_compression   1 1 1 1 1 1 1 1 1 1 1 setup.kibana:   2 output.elasticsearch:   3 hosts: [\"192.168.40.133:9200\",\"192.168.40.134:9200\",\"192.168.40.135:9200\"]   4 processors:   5 6 7 ꢀ- add_host_metadata: ~   ꢀ- add_cloud_metadata: ~   ꢀ 8 #启动   9 ./metricbeat -e   在ELasticsearch中可以看到，系统的一些指标数据已经写入进去了：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   system module配置：   1 2 3 root@itcast01:modules.d# cat system.yml   # Module: system   # Docs: https://www.elastic.co/guide/en/beats/metricbeat/6.5/metricbeat-module-   system.html   4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 - module: system   period: 10s   metricsets:   ꢀ - cpu   ꢀ - load   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 ꢀ - memory   ꢀ - network   ꢀ - process   ꢀ - process_summary   ꢀ ꢀ#- core   ꢀ ꢀ#- diskio   ꢀ ꢀ#- socket   process.include_top_n:   ꢀ by_cpu: 5 ꢀ ꢀ ꢀ# include top 5 processes by CPU   ꢀ by_memory: 5 ꢀ # include top 5 processes by memory   1 - module: system   2 3 4 5 6 7 8 9 period: 1m   metricsets:   ꢀ - filesystem   ꢀ - fsstat   processors:   - drop_event.when.regexp:   ꢀ ꢀ system.filesystem.mount_point: '^/(sys|cgroup|proc|dev|etc|host|lib)($|/)'   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   3 3 3 3 3 3 3 3 3 3 0 - module: system   1 2 3 4 period: 15m   metricsets:   ꢀ - uptime   5 #- module: system   6 # period: 5m   7 # metricsets:   8 # ꢀ - raid   9 # raid.mount_point: '/'   5 .3、Module   1 2 3 4 5 6 7 8 9 ./metricbeat modules list ꢀ#查看列表   Enabled:   system #默认启用   Disabled:   aerospike   apache   ceph   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 0 couchbase   1 docker   2 dropwizard   3 elasticsearch   4 envoyproxy   5 etcd   6 golang   7 graphite   8 haproxy   9 http   0 jolokia   1 kafka   2 kibana   3 kubernetes   4 kvm   5 logstash   6 memcached   7 mongodb   8 munin   9 mysql   0 nginx   1 php_fpm   2 postgresql   3 prometheus   4 rabbitmq   5 redis   6 traefik   7 uwsgi   8 vsphere   9 windows   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   40 zookeeper   5 .4、Nginx Module   5 .4.1、开启nginx的状态查询   在nginx中，需要开启状态查询，才能查询到指标数据。   1 2 3 4 5 6 7 8 9 0 #重新编译nginx   ./configure --prefix=/usr/local/nginx --with-http_stub_status_module   make   make install   ./nginx -V ꢀ#查询版本信息   nginx version: nginx/1.11.6   built by gcc 4.4.7 20120313 (Red Hat 4.4.7-23) (GCC)   configure arguments: --prefix=/usr/local/nginx --with-http_stub_status_module   1 1 1 1 1 1 1 1 #配置nginx   2 vim nginx.conf   3 location /nginx-status {   4 stub_status on;   access_log off;   5 6 }   测试：   结果说明：   Active connections：正在处理的活动连接数   server accepts handled requests   第一个 server 表示Nginx启动到现在共处理了9个连接   第二个 accepts 表示Nginx启动到现在共成功创建 9 次握手   第三个 handled requests 表示总共处理了 21 次请求   请求丢失数 = 握手数 - 连接数 ，可以看出目前为止没有丢失请求   Reading: 0 Writing: 1 Waiting: 1   Reading：Nginx 读取到客户端的 Header 信息数   Writing：Nginx 返回给客户端 Header 信息数   Waiting：Nginx 已经处理完正在等候下一次请求指令的驻留链接（开启keep-alive的情况下，这个值等于   Active - (Reading+Writing)）   5 .4.2、配置Nginx Module   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 #启用redis module   ./metricbeat modules enable nginx   #修改redis module配置   vim modules.d/nginx.yml   # Module: nginx   # Docs: https://www.elastic.co/guide/en/beats/metricbeat/6.5/metricbeat-module-   nginx.html   9 1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 0 - module: nginx   1 2 3 4 5 6 7 8 9 0 1 2 3 4 ꢀ#metricsets:   ꢀ# - stubstatus   period: 10s   ꢀ# Nginx hosts   hosts: [\"http://192.168.40.133\"]   ꢀ# Path to server status. Default server-status   server_status_path: \"nginx-status\"   ꢀ#username: \"user\"   ꢀ#password: \"secret\"   5 #启动   6 ./metricbeat -e   测试：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   可以看到，nginx的指标数据已经写入到了Elasticsearch。   更多的Module使用参见官方文档：   https://www.elastic.co/guide/en/beats/metricbeat/current/metricbeat-modules.html   6、Kibana   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   Kibana 是一款开源的数据分析和可视化平台，它是 Elastic Stack 成员之一，设计用于和 Elasticsearch 协作。您可以   使用 Kibana 对 Elasticsearch 索引中的数据进行搜索、查看、交互操作。您可以很方便的利用图表、表格及地图对   数据进行多元化的分析和呈现。   官网：https://www.elastic.co/cn/products/kibana   6 .1、配置安装   1 2 3 4 5 6 7 8 9 #解压安装包   tar -xvf kibana-6.5.4-linux-x86_64.tar.gz   #修改配置文件   vim config/kibana.yml   server.host: \"192.168.40.133\" ꢀ#对外暴露服务的地址   elasticsearch.url: \"http://192.168.40.133:9200\" ꢀ#配置Elasticsearch   1 1 1 1 1 0 #启动   1 ./bin/kibana   2 3 #通过浏览器进行访问   4 http://192.168.40.133:5601/app/kibana   可以看到kibana页面，并且可以看到提示，导入数据到Kibana。   6 .2、功能说明   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6 .3、数据探索   首先先添加索引信息：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   即可查看索引数据：   6 .4、Metricbeat 仪表盘   可以将Metricbeat的数据在Kibana中展示。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 #修改metricbeat配置   setup.kibana:   host: \"192.168.40.133:5601\"   ꢀ #安装仪表盘到Kibana   ./metricbeat setup --dashboards   即可在Kibana中看到仪表盘数据：   查看系统信息：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6 .5、Nginx 指标仪表盘   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6 .6、Nginx 日志仪表盘   1 2 3 4 5 6 7 8 9 #修改配置文件 vim itcast-nginx.yml   filebeat.inputs:   #- type: log   # enabled: true   # paths:   # ꢀ - /usr/local/nginx/logs/*.log   # tags: [\"nginx\"]   setup.template.settings:   index.number_of_shards: 3   1 1 1 1 1 1 1 1 1 1 0 output.elasticsearch:   hosts: [\"192.168.40.133:9200\",\"192.168.40.134:9200\",\"192.168.40.135:9200\"]   2 filebeat.config.modules:   1 3 4 path: ${path.config}/modules.d/*.yml   reload.enabled: false   5 setup.kibana:   6 7 8 host: \"192.168.40.133:5601\"   ꢀ 9 #安装仪表盘到kibana   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   20 ./filebeat -c itcast-nginx.yml setup   可以看到nginx的FileBeat的仪表盘了：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6 .7、自定义图表   在Kibana中，也可以进行自定义图表，如制作柱形图：   将图表添加到自定义Dashboard中：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6 .8、开发者工具   在Kibana中，为开发者的测试提供了便捷的工具使用，如下：   7、Logstash   7 .1、简介   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   用途：   7 .2、部署安装   1 2 3 4 5 6 7 8 #检查jdk环境，要求jdk1.8+   java -version   #解压安装包   tar -xvf logstash-6.5.4.tar.gz   #第一个logstash示例   bin/logstash -e 'input { stdin { } } output { stdout {} }'   执行效果如下：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   7 .3、配置详解   Logstash的配置有三部分，如下：   1 2 3 4 5 6 7 8 9 0 input { #输入   stdin { ... } #标准输入   } filter { #过滤，对数据进行分割、截取等处理   ꢀ ...   } output { #输出   1 1 stdout { ... } #标准输出   1 }   7 .3.1、输入   采集各种样式、大小和来源的数据，数据往往以各种各样的形式，或分散或集中地存在于很多系统中。   Logstash 支持各种输入选择 ，可以在同一时间从众多常用来源捕捉事件。能够以连续的流式传输方式，轻松地   从您的日志、指标、Web 应用、数据存储以及各种 AWS 服务采集数据。   7 .3.2、过滤   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   实时解析和转换数据   数据从源传输到存储库的过程中，Logstash 过滤器能够解析各个事件，识别已命名的字段以构建结构，并将它   们转换成通用格式，以便更轻松、更快速地分析和实现商业价值。   7 .3.3、输出   Logstash 提供众多输出选择，您可以将数据发送到您要指定的地方，并且能够灵活地解锁众多下游用例。   7 .4、读取自定义日志   前面我们通过Filebeat读取了nginx的日志，如果是自定义结构的日志，就需要读取处理后才能使用，所以，这个时   候就需要使用Logstash了，因为Logstash有着强大的处理能力，可以应对各种各样的场景。   7 .4.1、日志结构   1 2019-03-15 21:21:21|ERROR|读取数据出错|参数：id=1002   可以看到，日志中的内容是使用“|”进行分割的，使用，我们在处理的时候，也需要对数据做分割处理。   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   7 .4.2、编写配置文件   1 2 3 4 5 6 7 8 9 #vim itcast-pipeline.conf   input {   ꢀ file {   ꢀ ꢀ path => \"/itcast/logstash/logs/app.log\"   ꢀ ꢀ start_position => \"beginning\"   ꢀ }   } 1 1 1 1 1 1 1 1 1 0 filter {   1 ꢀ mutate {   2 ꢀ ꢀ split => {\"message\"=>\"|\"}   ꢀ }   3 4 }   5 6 output {   7 ꢀ stdout { codec => rubydebug }   8 }   7 .4.3、启动测试   1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 #启动   ./bin/logstash -f ./itcast-pipeline.conf   #写日志到文件   echo \"2019-03-15 21:21:21|ERROR|读取数据出错|参数：id=1002\" >> app.log   #输出的结果   { ꢀ ꢀ\"@timestamp\" => 2019-03-15T08:44:04.749Z,   ꢀ ꢀ ꢀ ꢀ ꢀ\"path\" => \"/itcast/logstash/logs/app.log\",   ꢀ ꢀ ꢀ\"@version\" => \"1\",   ꢀ ꢀ ꢀ ꢀ ꢀ\"host\" => \"node01\",   ꢀ ꢀ ꢀ \"message\" => [   1 1 1 1 1 1 1 1 1 1 ꢀ ꢀ ꢀ [0] \"2019-03-15 21:21:21\",   ꢀ ꢀ ꢀ [1] \"ERROR\",   ꢀ ꢀ ꢀ [2] \"读取数据出错\",   ꢀ ꢀ ꢀ [3] \"参数：id=1002\"   ꢀ ]   9 }   可以看到，数据已经被分割了。   7 .4.5、输出到Elasticsearch   1 2 3 4 5 input {   ꢀ file {   ꢀ ꢀ path => \"/itcast/logstash/logs/app.log\"   ꢀ ꢀ ꢀ#type => \"system\"   ꢀ ꢀ start_position => \"beginning\"   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   6 7 8 9 0 1 2 ꢀ }   } filter {   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 ꢀ mutate {   ꢀ ꢀ split => {\"message\"=>\"|\"}   ꢀ }   3 }   4 5 output {   6 ꢀ elasticsearch {   7 ꢀ ꢀ ꢀ hosts => [ \"192.168.40.133:9200\",\"192.168.40.134:9200\",\"192.168.40.135:9200\"]   ꢀ }   8 9 }   0 1 2 #启动   3 ./bin/logstash -f ./itcast-pipeline.conf   4 5 #写入数据   6 echo \"2019-03-15 21:21:21|ERROR|读取数据出错|参数：id=1003\" >> app.log   测试：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   8、综合练习   下面我们将前面所学习到的Elasticsearch + Logstash + Beats + Kibana整合起来做一个综合性的练习，目的就是让   学生们能够更加深刻的理解Elastic Stack的使用。   8 .1、流程说明   应用APP生产日志，用来记录用户的操作   [ INFO] 2019-03-15 22:55:20 [cn.itcast.dashboard.Main] - DAU|5206|使用优惠券|2019-03-15   3:37:20   INFO] 2019-03-15 22:55:21 [cn.itcast.dashboard.Main] - DAU|3880|浏览页面|2019-03-15 07:25:09   0 [ 通过Filebeat读取日志文件中的内容，并且将内容发送给Logstash，原因是需要对内容做处理   Logstash接收到内容后，进行处理，如分割操作，然后将内容发送到Elasticsearch中   Kibana会读取Elasticsearch中的数据，并且在Kibana中进行设计Dashboard，最后进行展示   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   说明：日志格式、图表、Dashboard都是自定义的。   8 .2、APP介绍   APP在生产环境应该是真实的系统，然而，我们现在仅仅的学习，为了简化操作，所以就做数据的模拟生成即可。   业务代码如下：   1 2 3 4 5 6 7 8 9 package cn.itcast.dashboard;   import org.apache.commons.lang3.RandomUtils;   import org.joda.time.DateTime;   import org.slf4j.Logger;   import org.slf4j.LoggerFactory;   import org.springframework.boot.autoconfigure.SpringBootApplication;   @SpringBootApplication   1 1 1 1 1 0 public class Main {   1 2 3 4 ꢀ ꢀprivate static final Logger LOGGER = LoggerFactory.getLogger(Main.class);   ꢀ ꢀpublic static final String[] VISIT = new String[]{\"浏览页面\", \"评论商品\", \"加入收藏\",   加入购物车\", \"提交订单\", \"使用优惠券\", \"领取优惠券\", \"搜索\", \"查看订单\"};   \" 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 ꢀ ꢀpublic static void main(String[] args) throws Exception {   ꢀ ꢀ ꢀ ꢀwhile(true){   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀLong sleep = RandomUtils.nextLong(200, 1000 * 5);   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀThread.sleep(sleep);   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀLong maxUserId = 9999L;   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀLong userId = RandomUtils.nextLong(1, maxUserId);   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀString visit = VISIT[RandomUtils.nextInt(0, VISIT.length)];   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀDateTime now = new DateTime();   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀint maxHour = now.getHourOfDay();   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀint maxMillis = now.getMinuteOfHour();   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀint maxSeconds = now.getSecondOfMinute();   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀString date = now.plusHours(-(RandomUtils.nextInt(0, maxHour)))   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ .plusMinutes(-(RandomUtils.nextInt(0, maxMillis)))   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ .plusSeconds(-(RandomUtils.nextInt(0, maxSeconds)))   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ ꢀ .toString(\"yyyy-MM-dd HH:mm:ss\");   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀString result = \"DAU|\" + userId + \"|\" + visit + \"|\" + date;   ꢀ ꢀ ꢀ ꢀ ꢀ ꢀLOGGER.info(result);   ꢀ ꢀ ꢀ }   ꢀ }   7 }   8 运行结果：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   1 2 3 4 5 6 7 8 9 [INFO] 2019-03-15 22:54:42 [cn.itcast.dashboard.Main] - DAU|4645|领取优惠券|2019-03-15   7:40:29   [INFO] 2019-03-15 22:54:44 [cn.itcast.dashboard.Main] - DAU|3482|领取优惠券|2019-03-15   8:34:04   [INFO] 2019-03-15 22:54:48 [cn.itcast.dashboard.Main] - DAU|5607|加入收藏|2019-03-15   2:44:09   [INFO] 2019-03-15 22:54:50 [cn.itcast.dashboard.Main] - DAU|9619|加入收藏|2019-03-15   1:39:47   [INFO] 2019-03-15 22:54:53 [cn.itcast.dashboard.Main] - DAU|7666|加入收藏|2019-03-15   7:47:18   [INFO] 2019-03-15 22:54:54 [cn.itcast.dashboard.Main] - DAU|4871|提交订单|2019-03-15   2:36:27   [INFO] 2019-03-15 22:54:55 [cn.itcast.dashboard.Main] - DAU|7126|加入收藏|2019-03-15   6:11:06   [INFO] 2019-03-15 22:55:00 [cn.itcast.dashboard.Main] - DAU|9606|评论商品|2019-03-15   2:12:00   [INFO] 2019-03-15 22:55:02 [cn.itcast.dashboard.Main] - DAU|7698|查看订单|2019-03-15   8:17:02   0 1 2 2 1 0 1 0 0 代码在资料中可以找到，itcast-dashboard-generate.zip。   部署：   1 2 3 #打包成jar包，在linux上运行   java -jar itcast-dashboard-generate-1.0-SNAPSHOT.jar   #运行之后，就可以将日志写入到/itcast/logs/app.log文件中   8 .3、Filebeat   1 2 3 4 5 6 7 8 9 #vim itcast-dashboard.yml   filebeat.inputs:   - type: log   enabled: true   paths:   ꢀ ꢀ- /itcast/logs/*.log   setup.template.settings:   index.number_of_shards: 3   1 1 1 1 1 1 0 output.logstash:   1 2 3 hosts: [\"192.168.40.133:5044\"]   ꢀ ꢀ 4 #启动   5 ./filebeat -e -c itcast-dashboard.yml   8 .4、Logstash   1 2 3 #vim itcast-dashboard.conf   input {   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 9 0 1 2 3 4 5 6 7 8 ꢀ beats {   ꢀ ꢀ port => \"5044\"   ꢀ }   } filter {   1 1 1 1 1 1 1 1 1 1 2 2 2 2 2 2 2 2 2 2 3 3 3 3 3 3 3 3 3 3 4 4 4 ꢀ mutate { ꢀ   ꢀ ꢀ split => {\"message\"=>\"|\"}   ꢀ }   ꢀ mutate {   ꢀ ꢀ add_field => {   ꢀ ꢀ ꢀ ꢀ\"userId\" => \"%{message[1]}\"   ꢀ ꢀ ꢀ ꢀ\"visit\" => \"%{message[2]}\"   ꢀ ꢀ ꢀ ꢀ\"date\" => \"%{message[3]}\"   ꢀ ꢀ ꢀ }   ꢀ }   ꢀ mutate {   ꢀ ꢀ convert => {   ꢀ ꢀ ꢀ ꢀ\"userId\" => \"integer\"   ꢀ ꢀ ꢀ ꢀ\"visit\" => \"string\"   ꢀ ꢀ ꢀ ꢀ\"date\" => \"string\"   ꢀ ꢀ }   ꢀ }   9 }   0 1 #output {   2 # ꢀ stdout { codec => rubydebug }   3 #}   4 5 output {   6 ꢀ elasticsearch {   7 ꢀ ꢀ ꢀ hosts => [ \"192.168.40.133:9200\",\"192.168.40.134:9200\",\"192.168.40.135:9200\"]   ꢀ }   8 9 }   0 1 #启动   2 ./bin/logstash -f itcast-dashboard.conf   8 .5、Kibana   启动Kibana：   1 2 3 4 5 #启动   ./bin/kibana   #通过浏览器进行访问   http://192.168.40.133:5601/app/kibana   添加Logstash索引到Kibana中：   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   8 .5.1、时间间隔的柱形图   说明：x轴是时间，以天为单位，y轴是count数   保存：（my-dashboard-时间间隔的柱形图）   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   8 .5.2、各个操作的饼图分布   统计各个操作的数量，形成饼图。   保存：（my-dashboard-各个操作的饼图）   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   8 .5.3、数据表格   在数据探索中进行保存，并且保存，将各个操作的数据以表格的形式展现出来。   保存：（my-dashboard-表格）   北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   8 .5.4、制作Dashboard   ꢀ 北京市昌平区建材城西路金燕龙办公楼一层   电话：400-618-9090   new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-04-01 13:32:12 "},"base/01-elasticsearch-catlog.html":{"url":"base/01-elasticsearch-catlog.html","title":"catlog","keywords":"","body":" 狂神聊ElasticSearch(库,表,记录)(初级阶段) E L K 版本:Elasticsearch7.6.1 (全网最新的) 6.X 和 7.X 区别十分大(原生API,RestFul高级) 我们要讲解什么? SQL: like查询%狂神说%,如果是大数据,就十分慢!索引! Elasticsearch:搜索(百度,github,淘宝电商!) 聊一个人 货比三家 安装 生态圈 分词器 ik RestFul操作 ES CRUD SpringBoot 集成 ElasticSearch(从原理分析!) 爬虫爬取数据(京东) 实战,模拟全文检索! 以后你只要需要用到搜索,就可以用ES!(大数据量的情况下使用!) 学了这个就不需要用MySQL来查了 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/02-elasticsearch-聊DougCutting.html":{"url":"base/02-elasticsearch-聊DougCutting.html","title":"聊DougCutting","keywords":"","body":"聊聊DougCutting聊聊DougCutting 为什么要讲这个人,后面要聊大数据 本故事内容来自公众号 1998年9月4号,google公司在美国硅谷成立.正如大家所知,它是一家搜索引擎起家的公司 无独有偶,一位名叫DougCutting的美国工程师,也迷上了搜索引擎.他做了一个用于文本搜索的函数库(姑且理解为软件的功能组件),命名为Lucene. Lucene使用Java写的,目标是为各种中小型应用软件加入全文检索功能.因为好用而且开源(代码公开),非常受程序员们稀罕) 在这个过程中,google确实找到了不少好的办法,并且无私地分享了出来. 开源是一种精神! 2003年,google发表了一篇技术学术论文,公开介绍了自己的谷歌文件系统GFS(google File System).这是google公司为了存储海量搜素数据而设计的专用文件系统 第二年,2004年,Doug Cutting基于google的GFS论文,实现了分布式文件存储系统,并将它命名为NDFS(Nutch Distributed File System) 还是2004年,google又发表了一篇技术学术论文,介绍自己的MapReduce编程模型.这个编程模型,用于大规模数据集(大于1TB)的并行分析运算. 2005年,Doug Cutting 又基于MapReduce,在Nutch搜索引擎实现了该功能. ![1596610274356](D:\\IdeaProjects\\StudyRecord\\Elasticsearch\\img\\1596610274356.png 2006年,当时依然很厉害的Yahoo(雅虎)公司,招安了Doug Cutting 截图 我们继续往下说. 还是2006年,google有发表论文了 这次,他们介绍自己的BigTable,这是一种分布式的数据存储系统,一种用来处理海量数据的非关系型数据库. Doug Cutting 当然没有放过,在自己的hadoop系统里面,引入了BigTable,并命名为HBase. 好吧,反正就是紧跟Google时代步伐,你出什么,我学什么 所有,Hadoop的核心部分,基本上都有Google的影子. 2008年1月,Hadoop成功上位,成为Apache基金会的顶级项目. 同年2月,Yahoo宣布建成了一个拥有1W个内核的Hadoop集群,并将自己的搜索引擎产品部署在上面. 7月,Hadoop打破世界纪录,成为最快排序1TB数据的系统,用时209秒. 生存法则: 不断学习(虚心学习! ) 优胜劣汰! 三体里面的片段 会到主题 Lucene是一套信息检索工具包!jar包! 不包含搜索引擎系统!Solr 包含的是索引结构!读写索引的工具!基本的常用的网站搜素排序功能,搜素规则功能...工具类! Lucene好elasticsearch的关系: Elasticsearch是基于Lucene工具包做了一些封装和增强(我们上手是十分简单!) HashMap比这个难多了 讲课风格:学习更多的是培养大家的学习兴趣! 教学风格:开源,免费,授人以鱼new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/03-elasticsearch-概述.html":{"url":"base/03-elasticsearch-概述.html","title":"概述","keywords":"","body":"Elasticsearch概述Elasticsearch概述 elasticsearch,简称为es,es是一个开源的扩展的分布式全文检索引擎,他可以近乎实时的存储,检索数据;本身扩展性很好,可以扩展到上百台服务器,处理PB级别(大数据时代)的数据.es也使用Java并发使用Lucene作为其核心来实现所有索引和搜索的功能,但是它的目的是通过简单的RESTful API 来隐藏Lucene的复杂性,从而让全文搜索变得简单. 据国际权威的数据库产品评测机构DB Engines的统计,在2016年1月,ElasticSearch已超过Solr等,成为排名第一的搜索引擎类应用 历史 多年前,一个叫做shay banon的刚结婚不久的失业开发者,由于妻子要去伦敦学习厨师,他便跟着去了.在他找工作的过程中,为了给妻子构建一个食谱的搜索引擎,他开始构建一个早期版本的Lucene 直接 基于Lucene工作会比较困难,所以Shay开始抽象Lucene代码以便Java程序员可以在应用中添加搜索功能.他发布了他的第一个开源项目,叫做\"compass\" 后来Shay找到一份工作,这个工作处在高性能和内存数据网络的分布式环境中,因此高性能的,实时的,分布式的搜索引擎也是理所当然需要的.然后他决定重写Compass库,使其成为一个独立的服务叫做Elasticsearch.第一个公开版本出现在2010年2月,在那之后Elasticsearch已经成为Github上最受欢迎的项目之一,代码贡献者超过300人.一家主营Elasticsearch的公司就此成立,他们一边提供商业支持,一边开发新功能,不过Elasticsearch将永远开源且对所有人可用 Shay的妻子依然等待着他的食谱搜索....... 谁在使用 维基百科(百度百科,全文高亮,排序搜素推荐,权重,百度!) The Guardian Stack Overflow(国外的程序异常处理网站)IT 问题,程序的报错,提交上去,有人会跟你讨论和回答 Github 电商网站 淘宝京东 日志数据分析,logstash采集日志,ES进行复杂的数据分析,ELK技术,elasticsearch+logstach+kibana 商品价格监控网站,用户设定 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/04-elasticsearch-和solr对比.html":{"url":"base/04-elasticsearch-和solr对比.html","title":"和solr对比","keywords":"","body":"Elasticsearch和Solr差别ElasticSearch vs Solr 总结Elasticsearch和Solr差别 Elasticsearch是一个实时分布式搜索和分析引擎.它让你以前所未有的速度处理大数据成为可能. 维基百科使用它提供全文搜索并高亮关键字,以及输入实时搜索 Solr简介 Solr是Apache下的一个顶级开源项目,采用Java开发,它是基于Lucene的全文搜索服务器.solr提供了比Lucene更为丰富的查询语言,同时实现了可配置,可扩展,并对索引,搜索性能进行优化 他可以独立运行,运行在tomcat ,jety等这些Servlet容器中 solr对外提供类似于Web-server的API接口 随着数据量的增加,solr的搜索 50倍的效率 ElasticSearch vs Solr 总结 es基本是开箱即用(解压就可以用了!),非常简单.solr安装略微复杂一丢丢! Solr利用Zookeeper进行分布式管理,而Elasticsearch自身带有分布式协调管理功能. solr支持更多格式的数据,比如JSON,XML,CSV, 而elasticsearch仅仅支持json文件格式 Solr官网提供的功能很多,儿elasticsearch本身更注重核心功能,高级功能多有第三方插件提供,例如图形化界面需要kibana友好质层支撑 Solr查询块,但更新索引时慢(即插入删除慢),用于电商等查询多的应用; ES建立索引块(即查询慢),即实时性查询快,用于facebook新浪等搜索. Solr是传统搜索应用的有力解决方案,但Elasticsearch更适用于新兴的实时搜索应用. Solr比较成熟,有一个更大,更成熟的用户,开发好贡献者社区,而Elasticsearch相对开发维护者较少,更新太快,学习使用成本较高. new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/05-elasticsearch-安装和head插件.html":{"url":"base/05-elasticsearch-安装和head插件.html","title":"安装和head插件","keywords":"","body":"Elasticsearch安装Elasticsearch安装 声明:JDK1.8, 最低要求 , Elasticsearch客户端,界面工具! Java开发,elasticsearch的版本和我们之后对应的Java的核心jar包! 版本对应! JDK环境是正常的 这里一定要保证 下载 一定要在服务器上面搭建 下载地址:https://www.elastic.co/cn/downloads/elasticsearch 官网下载巨慢,翻墙,网盘中下载即可 华为云: https://mirrors.huaweicloud.com/elasticsearch/7.6.2/ 我们学习的话Window和Linux都可以学习 ==我们这里现在window下学习== ELK三剑客,解压即用!(web项目! 前端环境! npm 下载依赖) Node.js python2 window下安装! 解压 解压就可以使用 熟悉目录 bin 启动文件 config 配置文件 log4j2 日志配置文件 jvm.options java 虚拟机相关的配置 elasticsearch.yml elasticsearch的配置文件! 默认 9200 端口! 跨域! lib 相关jar包 modules 功能模块 plugins 插件! ik logs 日志 启动 访问测试 老师,能不能给我个可视化界面啊 安装可视化界面 es head的插件 下载地址: https://github.com/mobz/elasticsearch-head 启动 npm install npm run start 连接测试发现,存在跨域问题:配置es http.cors.enabled: true http.cors.allow-origin: \"*\" 重启es服务器,然后再次连接 你们初学,你就把es的当做一个数据库!(可以建立索引(库),文档(库中的数据)) 你就把索引当做数据库(表,文档,类型) 这个head我们就把他当做数据展示工具,我们后面所有的查询,kibana new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/06-elasticsearch-kibana安装.html":{"url":"base/06-elasticsearch-kibana安装.html","title":"kibana安装","keywords":"","body":"kibana安装kibana安装 了解elk,ELasticsearch ,logstash,kibana三大开奥运框架首字母缩写 收集,清洗数据-->搜索,存储-->分析-->kibana 安装kibana kibana是针对elasticsearch的开源分析及可视化平台,用来搜索 kibana版本要和ES版本一致才可以 嗯 现在要有这些 这个下载完毕后,解压需要很久,是一个标准的工程,这里面内容非常多,你要是解压挺快你就指正下载错了 好处:elk基本上都是拆箱使用 启动测试 1, 解压后的目录 看到这种bat直接就打开 这个默认是5601端口 进入页面 访问测试 开发工具(POST curl ,head,google浏览器插件测试) 但是呢我们需要使用kibana来进行测试 我们之后都在这个里面操作 汉化 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/07-elasticsearch-es核心概念理解.html":{"url":"base/07-elasticsearch-es核心概念理解.html","title":"es核心概念理解","keywords":"","body":"ES核心概念理解物理设计逻辑设计物理设计: 节点和分片 如何工作ES核心概念理解 概述 在前面的学习中,我们掌握了es是什么,同时也把es的服务已经安装启动,那么es是如何去存储数据,数据结构是什么,又是如何实现搜索的呢?我们先来聊聊Elasticsearch的相关概念吧! 集群,节点,索引,类型,文档,分片,映射是什么 elasticsearch是面向文档的,关系行数据库和elasticsearch客观的对比! 一切都是json RelationalDB Elasticsearch 数据库(database) 索引(indices) 表(tables) types 行(rows) documents 字段(columns) fields 面向文档 面向文档 面向文档 ~~~~ elasticsearch(集群)中可以包含多个索引(数据库),每个索引中可以包含多个类型(表),每个类型先又包含多个文档(行),每个文档中又包含多个字段(列). 物理设计 elasticsearch在后台吧每个索引划分成多个分片,每个分片可以在集群中的不同服务器间迁移 逻辑设计 一个索引类型中,包含多个文档,比如所文档1,文档2.当我们索引一篇文章时,可以通过这样的一各顺序找到它:索引>类型 >文档id,通过这个组合我们就能索引到某个具体的文档. 注意: id不必是整数,实际上他是一个字符串. 文档 user name age 1 zhasna 18 2 kaugshen 23 3 之前说elasticsearch是面向文档的,name就也为这索引和搜索数据的最小单位是文档,elasticsearch中,文档有几个重要属性: 自我包含,一篇文档同时包含字段和对应值,也就是同时包含key:value! 可以是层次型的,一个文档中包含文档,复杂的逻辑实体就是这么来的! 灵活的结构,文档不依赖预先定义的模式,我们知道关系型数据库中,要提前定义字段才能使用,在elasticsearch中,对于字段是非常灵活的,有时候,我们可以忽略该字段,或者动态的添加一个新的字段. 尽管我们可以随意的新增或者忽略某个字段,但是,每个字段的类型非常重要,比如一个年龄字段类型,可以是字符串也可以是整型.因为elasticsearch会保存字段和类型之间的映射及其他的设置.这种映射具体到每个映射的每种类型,这也是为什么在elasticsearch中,类型有时候也称为映射类型. 类型 类型是文档的逻辑容器,就像关系型数据库一样,表格是行的容器.类型中对于字段的定义称为映射,比如name映射为字符串类型.我们说文档是无模式的,他们不需要拥有映射中所定义的所有字段,比如新增一个字段,那么elasticsearch是怎么做的呢? elasticsearch会自动的将新的字段加入映射,但是这个字段的不确定它是什么类型,elasticsearch就开始猜,如果这个值是18,那么elasticsearch会认为他是整型.但是elasticsearch也可能猜不对,所有最安全的方式就是提前定义好所需要的映射,这点跟关系型数据库殊途同归了,先定义好字段,然后在使用,别整什么幺蛾子. 索引 就是数据库 索引是映射类型的容器,elasticsearch中的索引是一个非常大的文档集合.索引存储了映射类型字段和其他设置,然后他们呗存储到了各个分片上了.我们来研究下分片是如何工作的. 物理设计: 节点和分片 如何工作 一个集群至少要有一个节点,儿一个节点就是一个elasticsearch进程,节点可以有多个索引默认的,如果你创建索引,那么索引将会有5个分片(primary shard,又称主分片) 构成的,每个主分片会有一个副本(replica shard,又称复制分片) 倒排索引 elasticsearch使用的是一种称为倒排索引的结构,采用Lucene倒排索引作为底层.这种结构适用于快速的全文搜索,一个索引由文档中所有不重复的列表构成,对于每一个词,都有一个包含它的文档列表.例如,现在有两个文档,每个文档包含如下内容. 为了创建倒排索引,我们首先要将每个文档拆分成独立的词(或称为词条或者tokens),然后创建一个包含所有不重复的词条的排序列表,然后列出每个词条出现在哪个文档: 两个文档都匹配,但是第一个文档比第二个匹配程度更高.如果没有别的条件,现在,这两个包含关键字的文档都将返回. 再来看一个示例,比如我们通过博客标签来搜索博客文章.那么倒排索引列表就是这样的一个结构: 如果要搜索含有python标签的文章,那相对查找所有原始数据而言,查找倒排索引后的数据将会快的多.只需要查看标签这一栏,然后获取相关文章id即可. elasticsearch的索引和lucene的索引对比 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/08-elasticsearch-IK分词器插件.html":{"url":"base/08-elasticsearch-IK分词器插件.html","title":"IK分词器插件","keywords":"","body":"IK分词器插件IK分词器插件 狂神说 什么是分词器 如果使用中文,建议使用ik分词器 IK体用了两个分词算法:ik_smart和ik_max_word,其中ik_smart为最少(ˉ▽￣～) 切~~分,ik_max_word为最细粒度划分! 一会我们测试 安装 https://github.com/medcl/elasticsearch-analysis-ik 下载完毕之后,放入到我们的elasticsearch插件即可 重启观察ES elasticsearch-plugin 可以通过这个命令来查看加载的插件 使用kibana测试! 查看不同的分词器效果 其中ik_smart为最细粒度划分! 穷尽词库的可能! 字典 ! ![1596675058784](08-elasticsearch-IK%E5%88%86%E8%AF%8D%E5%99%A8%E6%8F%92%E4%BB%B6.assets/1596675058784.png) ``` 我们输入超级喜欢狂神说Java ``` ![1596675178617](08-elasticsearch-IK%E5%88%86%E8%AF%8D%E5%99%A8%E6%8F%92%E4%BB%B6.assets/1596675178617.png) 发现问题: 狂神说被拆开了! 这种自己需要的词,需要自己加到我们的分词器字典中! ik分词器增加我们自己的配置 重启ES,看细节 再次测试一下狂神说, 以后的话我们需要自己配置自己的词,只需要在自定义的dic文件中进行配置即可! new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/09-elasticsearch-Rest风格.html":{"url":"base/09-elasticsearch-Rest风格.html","title":"Rest风格","keywords":"","body":"Rest风格说明关于索引的基本操作Rest风格说明 一种软件架构风格,而不是标准,只是提供了一组设计原则和约束条件.它主要用于客户端和服务器交互类的软件.基于这个风格设计的软件可以更简洁,更有层次,更易于实现缓存等机制. 基础测试 关于索引的基本操作 创建一个索引! PUT /索引名/~类型名~/文档id {请求体} 完成了自动增加了索引! 数据也成功的添加了,这就是我说大家在初期可以把它当做数据库学习的原因 以后查询可以直接查,不走数据库 那么name这个字段用不用指定类型呢,毕竟我们关系型数据库 是需要指定类型的啊 指定字段的类型 获得这个规则! 可通过GET请求获取具体的信息 查看默认的信息 就是你不写的话,有一个默认的不可分割的类型 如果自己的文档字段没有指定,那么ES就会给我们配置字段类型 虚心学习,这个世界上大佬很多! 扩展:通过命令elasticsearch索引情况! 通过get_cat/可以获得es当前的很多信息 ![1596676751370](09-elasticsearch-Rest%E9%A3%8E%E6%A0%BC.assets/1596676751370.png) ``` 修改索引 提交哈哈四使用PUT即可! 然后覆盖! 最新办法 ``` 曾经! 是这样的 ![1596677004607](09-elasticsearch-Rest%E9%A3%8E%E6%A0%BC.assets/1596677004607.png) 现在的方法 ![1596677026606](09-elasticsearch-Rest%E9%A3%8E%E6%A0%BC.assets/1596677026606.png) 删除索引 通过DELETE 命令实现删除,根据你的请求是删除索引还是删除文档记录 使用ERSTFUL风格是我们推荐大家使用的 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/10-elasticsearch-文档基本操作.html":{"url":"base/10-elasticsearch-文档基本操作.html","title":"文档基本操作","keywords":"","body":"关于文档的基本操作集成SpringBoot实战demo关于文档的基本操作 https://www.bilibili.com/video/BV17a4y1x7zq?p=10 基本操作 添加数据 获取数据 更新数据 PUT Post _update,推荐使用这种更新方式! 简单地搜索! GET kuangshen/user/1 简单的条件查询,可以根据默认的映射规则,产生基本的查询 集成SpringBoot 实战demo 爬虫 前后端分离 搜索高亮new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/11_花式查询详解.html":{"url":"base/11_花式查询详解.html","title":"花式查询详解","keywords":"","body":"关于文档的查询关于文档的查询 复杂操作搜索 select(排序,分页,高亮,模糊查询,精准查询! ) 输出结果不想要那么多,select * 现在是select name,age 可以指定字段 结果的过滤 我们之后使用Java操作ES,所有的方法和对象就是这里面的key! 排序 分页查询 数据下标还是从0开始,和之前所学的数据结构都是一样的! 布尔值查询 must(and) ,所有条件都要符合 where id=1 and name=xxx should (or) ,所有条件都要符合 where id=1 or name = xxx must not (not) 过滤器 filter gt 大于 gte 大于等于 lt 小于 lte 小于等于 匹配多个条件 用空格分隔也行 精确查询 term 查询时直接通过倒排索引指定的词条进程精确查找的! 关于分词: term,直接查询精确的 match,会使用分词器解析! (先分析分档,然后再通过分析的分档进行查询! ) 两个类型 text keyword 多个值匹配精确查询 高亮查询! 搜索的高亮条件,会在HTML里面自动的加上标签 这些其实MySQL也可以做,只是MySQL效率比较低 匹配 安装条件匹配 精确匹配 区间范围匹配 匹配字段过滤 多条件查询 高亮查询 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/12_SpringBoot集成ES详解.html":{"url":"base/12_SpringBoot集成ES详解.html","title":"SpringBoot集成ES详解","keywords":"","body":"集成SpringBoot 找文档! https://proxies.app.aidoru.net/-----https://www.elastic.co/guide/index.html 找到原生的依赖 找对象 分析这个类中的方法即可 配置基本的项目 问题:一定要保证我们导入的依赖和我们的ES版本一致 按照官网的操作我们要构建一个对象 分析源码 狂神的Spring步骤: 找对象 放到spring中待用 如果是springboot,那就先分析源码 xxxAutoConfiguration,xxxProperties 源码中提供的对象 虽然这里导入了3个类,静态内部类,核心类就一个 具体的api测试 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/13_关于索引的API操作详解.html":{"url":"base/13_关于索引的API操作详解.html","title":"关于索引的API操作详解","keywords":"","body":" 具体的Api测试! 创建索引 判断索引是否存在 删除索引 创建文档 crud文档 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/14_关于文档的API操作详解.html":{"url":"base/14_关于文档的API操作详解.html","title":"关于文档的API操作详解","keywords":"","body":" 文档操作Api void testAddDocument(){ // 创建对象 User user = new User(\"狂神说\",3); //创建请求 IndexRequest kuang_index = new IndexRequest(\"kuang_index\"); // 规则 put /kuang_index/_doc/1 request.id(\"1\") request.timeout(TimeValue.timeValueSeconds(1)); request.timeout(\"1s\"); // 将我们的数据放入请求 json IndexRequest source = request.source(JSON.toJSONString(user),XContentType.JSON); // 客户端发送请求 IndexResponse indexResponse = client.index(request,RequestOptions.DEFAULT); System.out.println(indexResponse.toString()); System.out.println(indexResponse.status()); } 结果 这里的返回的全部内容和我们的命令是一样的 更新文档信息 删除文档记录 特殊的,真的项目一般都会批量插入数据 是否失败,最后返回false 代表成功 如果你不设置id,默认id随机 // 查询 注意点 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/15_京东搜索_项目搭建.html":{"url":"base/15_京东搜索_项目搭建.html","title":"京东搜索_项目搭建","keywords":"","body":"准备开始爬虫 这里我我们使用前后端分离的项目 先要关闭thymeleaf缓存 爬虫 > > 数据问题? 数据库获取,消息队列中获取,都可以成为数据源,爬虫! new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/16_京东搜索_爬取数据.html":{"url":"base/16_京东搜索_爬取数据.html","title":"京东搜索_爬取数据","keywords":"","body":"爬取数据 jsoup包,来进行解析网页 tika包来爬电源爬图片 public class HtmlParseUtil{ public static void main(String[] args){ // 等你看完这节,你就会发现Jsoup你以前见过,就是Java中的css选择器 // 获取请求 https://search.jd.com/Search?keyword=java // 前提,需要联网! String url = \"https://search.jd.com/Search?keyword=java\" // 解析网页(Jsoup返回Document就是浏览器Document对象) Document document = Jsoup.parse(new URL(url),30000); // 所有你在JS中的方法,这里面都可以用 Element element = document.getElementById(\"J_goodsList\"); // 获取所有的li元素 Element elements = element.getElementByTag(\"li\"); // 获取元素中的内容,这里el 就是每个li标签了! for(Element el : elements){ // 关于这种图片特别多的网站,所有的图片都是延迟加载的! // source-data-lazy-img String img = el.getElementByTag(\"img\").eq(0).attr(\"src); String price = el.getElementByClass(\"p-price\").eq(0).text(); String title = el.getElementByClass(\"p-name\").eq(0).text(); System.out.println(img,price,title); } } } 懒加载,为了让页面刷新速度变快 所以直接在页面中是拿不到里面的jd的大图的 加上可以自定义的keywords 再定义一个实体类 上面可以自己添加属性 执行工具类 可以搜索到 如果要支持中文 需要设置url解析,charset的参数 配置 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/17_京东搜索_业务编写.html":{"url":"base/17_京东搜索_业务编写.html","title":"京东搜索_业务编写","keywords":"","body":" 业务编写 后端有数据了 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/18_京东搜索_前后端交互.html":{"url":"base/18_京东搜索_前后端交互.html","title":"京东搜索_前后端交互","keywords":"","body":"前后端交互 Vue数据绑定 完成 这些数据从elasticsearch中来的 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/19_京东搜索_关键字高亮实现.html":{"url":"base/19_京东搜索_关键字高亮实现.html","title":"京东搜索_关键字高亮实现","keywords":"","body":" 关键字高亮 现在不行,标签没有解析 我们需要换成v-html标签 以后大家学习完我的ES就可以编写基本的ES业务了 ES还将在大数据中和大家分享 ES集群 ES docker ... new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"base/20_狂神聊ES小结.html":{"url":"base/20_狂神聊ES小结.html","title":"狂神聊ES小结","keywords":"","body":"完结撒花 小结 资料获取:公众号关注狂神说 回复 es 获取资料 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-23 14:15:17 "},"qf_es/01_ES介绍.html":{"url":"qf_es/01_ES介绍.html","title":"ES介绍","keywords":"","body":"一,Elasticsearch介绍 一,Elasticsearch介绍 1.1 引言 在海量数据中执行搜索功能时,如果使用mysqlo,效率太低. 如果关键字输入的不准确,一样可以搜索到想要的数据 将搜索关键字,以红色字体展示 1.2 ES的介绍 ES是一个使用Java语言并且基于Lucene编写的搜索引擎框架,他提供了分布式的全文搜索功能, 提供了一个同意的基于RERTful风格的WEB接口,官方客户端也对多种语言都提供了响应的API. Lucene: Lucene本身就是一个搜索引擎的底层.(你可以理解为一个jar包) ES就是基于Lucene封装出来的 Lucene的官方:http://lucene.apache.org apache官方也不推荐你直接使用Lucene 在他的下面有一个Solr,而这个Solr也是基于Lucene实现的. 分布式:ES主要是为了突出他的横向扩展能力 全文检索:将一段词语进行分词,并且将分出的单个词语统一的放到一个分词库中,在搜索中,根据关键字去分词库中检索,找到匹配的内容(倒排索引) RESTful风格的WEB接口:操作ES很简单,只需要发送一个HTTP请求,并且根据请求方式的不同,携带参数的不同,执行响应的功能. 应用广泛:Github.com, WIKI, Gold Man用ES每天维护将近10TB数据 1.3 关于ES诞生的那点儿事儿: new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-25 21:02:17 "},"qf_es/02_ES和Solr的区别.html":{"url":"qf_es/02_ES和Solr的区别.html","title":"ES和Solr的区别","keywords":"","body":" 1.4 ES和Slor区别 Solr在查询死数据时,速度相对ES更快一些,但是数据如果是实时改变的,Solr查询的速度会降低很多, ES的查询的效率基本没有变化. Solr搭建基于需要依赖Zookeeper来帮助管理.ES本身就支持集群的搭建,不需要第三方介入. 最开始Solr的社区可以说是非常火爆,针对国内的文档并不是很多.在ES出现之后,ES的社区火爆程度直线上升,ES的文档非常健全. ES对现在云计算和大数据支持的特别好. new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-25 21:03:02 "},"qf_es/03_倒排索引.html":{"url":"qf_es/03_倒排索引.html","title":"倒排索引","keywords":"","body":" 1.5 倒排索引 将你存放的数据,以一定的方式记性分词,并且将分词的内容存放到一个单独的分词库中 当用户去查询数据时,会将用户的查询关键字记性分词 然后去分词库中匹配内容,最终得到数据的id标识 根据id标识去存放数据的位置拉去到指定的数据 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-25 21:04:46 "},"qf_es/04_安装ES和Kibana.html":{"url":"qf_es/04_安装ES和Kibana.html","title":"安装ES和Kibana","keywords":"","body":"二.Elasticsearch安装2.1 ES 安装&Kibana准备部分一起来操作https://www.bilibili.com/video/BV1Qz411e7yx?p=5 二.Elasticsearch安装 2.1 ES 安装&Kibana 准备部分 可以在http://hub.docker.com/里面搜索 elasticsearch和kibana 咱们统一一下版本 用6.5.4的版本 一起来操作 在服务器的/opt/路径下面创建docker_es目录 创建文件docker-compose.yml,内容如下: version: \"3.1\" services: elasticsearch: image: daocloud.io/library/elasticsearch:6.5.4 restart: always container_name: elasticsearch ports: - 9200:9200 kibana: image: daocloud.io/library/kibana:6.5.4 restart: always container_name: kibana ports: - 5601:5601 environment: - elasticsearch_url=http://39.106.139.40:9200 # 上面要填上你自己的虚拟机的ip和端口 depends_on: - elasticsearch 上面要注意yml文件的冒号后面的空格要有,不能有tab缩进,都是踩过的坑,汗水经验 然后在目录中运行命令 docker-compose up -d 试一下 [root@iz8g9301trfnpxz docker_es]# docker-compose up -d Creating network \"docker_es_default\" with the default driver Pulling elasticsearch (daocloud.io/library/elasticsearch:6.5.4)... 6.5.4: Pulling from library/elasticsearch a02a4930cb5d: Already exists dd8a94cca3f9: Pull complete bd73f551dee4: Pull complete 70de352c4efc: Pull complete 0b5ae4c7310f: Pull complete 489d9f8b18f1: Pull complete 8ba96caf5951: Pull complete f1df04f27c5f: Pull complete Digest: sha256:5ca85697b6273f63196b44c32311c5a2d1135af9cfd919e5922e49c5045d04b8 Status: Downloaded newer image for daocloud.io/library/elasticsearch:6.5.4 Pulling kibana (daocloud.io/library/kibana:6.5.4)... 6.5.4: Pulling from library/kibana a02a4930cb5d: Already exists 39999a66d2b5: Pull complete 4b2aeb7c30c9: Pull complete 00616cdd3c09: Pull complete e98987d4a5ba: Pull complete 5dfef65737c6: Pull complete a8d538f84d1a: Pull complete 961861c10f7a: Pull complete 5ccab4bdbc02: Pull complete Digest: sha256:632ecebdf89a36052e3eba281fdfa621a2afe5cd6b8061ad380ba3b3f0b25c01 Status: Downloaded newer image for daocloud.io/library/kibana:6.5.4 Creating elasticsearch ... done Creating kibana ... done 如果是上面这样就成了 如果你不放心,你可以执行 docker-compose logs -f 查看一下 。。。 卡了 [root@iz8g9301trfnpxz docker_es]# docker dockre s [root@iz8g9301trfnpxz docker_es]# [root@iz8g9301trfnpxz docker_es]# [root@iz8g9301trfnpxz docker_es]# docker dokxer dokxer 然后咱们访问一下ES 出现返回的json字符串,说明ES启动成功 然后我们访问一下kibana 进来之后就是我们的kibana的面板 我们主要关注dev Tools 咱们可以在这样的Dev Tools中,去编写基于RESful风格的WEB接口,去访问ES 这样就可以进行测试了 还有一个需要关注的就是Management 这里面能看到关于ES的信息new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-25 20:59:58 "},"qf_es/05_安装IK分词器.html":{"url":"qf_es/05_安装IK分词器.html","title":"安装IK分词器","keywords":"","body":" 2.2 安装IK分词器 我们可以在github上面搜索一下ik 我们选择与之前的版本保持一样的 下载IK分词器地址: https://github.com/medcl/elasticsearch-analysis-ik/releases/download/v6.5.4/elasticsearch-analysis-ik-6.5.4.zip 官方这个会很慢,我们使用qf提供的地址下载就快了 http://tomcat01.qfjava.cn:81/elasticsearch-analysis-ik-6.5.4.zip 进入到容器内部,跳转到bin目录下,执行bin目录下的脚本文件: ./elasticsearch-plugin install http://tomcat01.qfjava.cn:81/elasticsearch-analysis-ik-6.5.4.zip 有图有真相 然后我们test一下 这就尴尬了￣□￣｜｜ 这里重新启动服务,再运行就OK了 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-25 21:38:37 "},"qf_es/06_Redis的结构.html":{"url":"qf_es/06_Redis的结构.html","title":"Redis的结构","keywords":"","body":"三.elasticsearch基本操作3.1 ES结构3.1.2 类型 type3.1.3 文档doc3.1.4属性field https://www.bilibili.com/video/BV1Qz411e7yx?p=7 三.elasticsearch基本操作 3.1 ES结构 3.1.1 索引Index ES的服务中,可以创建多个索引 每一个索引默认被分成5片存储. 每一个分片都会存在至少一个备份分片 备份的分片默认不会帮助检索数据,当ES检索压力特别大的时候,备份分片才会帮助检索数据. 备份的分片必须放在不同的服务器中. 3.1.2 类型 type 一个索引下,可以创建多个类型 PS:根据版本不同,类型的创建也不同 3.1.3 文档doc 一个类型下,可以有多个文档,这个文档类似于MySQL表中的多行数据 3.1.4属性field 一个文档中,可以包含多个属性,类似于MySQL表中的一行数据存在多个列 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/07_ES的RESTful语法.html":{"url":"qf_es/07_ES的RESTful语法.html","title":"ES的RESTful语法","keywords":"","body":" 3.2 操作ES的RESTful语法 GET请求: http://ip:port/index: 查询索引信息 http://ip:port/index/type/doc_id: 查询指定的文档信息 POST请求: http://ip:port/index/type/_search: 查询,可以在请求体中添加json字符串来代表查询条件 http://ip:port/index/type/doc_id/_update: 修改文档,在请求体中指定json字符串来代表修改的具体信息 PUT请求 http://ip:port/index: 创建一个索引,需要在请求体中指定索引的信息 http://ip:port/index/type/_mappings: 代表创建索引时,指定索引的文档存储属性的信息 DELETE请求: http://ip:port/index: 删库跑路 http://ip:port/index/type/doc_id: 删除指定的文档 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/08_ES的索引操作.html":{"url":"qf_es/08_ES的索引操作.html","title":"ES的索引操作","keywords":"","body":" 3.3 索引的操作 3.3.1 创建一个索引 # 创建一个索引 PUT /person { \"settings\"{ \"number_of_shards\": 5, \"number_of_replicas\": 1 } } 3.3.2 查看索引信息 # 查看索引信息 GET /person 注意: 这里面要让你的鼠标光标放在GET这一行上面才行,否则执行空了 然后就有结果了 或者直接查看 3.3.3 删除索引 # 删除索引 DELETE /person 直接执行就行 或者我们直接management操作 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/09_ES的Field类型.html":{"url":"qf_es/09_ES的Field类型.html","title":"ES的Field类型","keywords":"","body":" 3.4 ES中field可以指定类型 String text and keyword Numeric datatypes long`, `integer`, `short`, `byte`, `double`, `float`, `half_float`, `scaled_float Date datatype date Boolean datatype boolean Binary datatype binary Range datatypes integer_range`, `float_range`, `long_range`, `double_range`, `date_range 字符串: > ​ text: 一把被用于全文检索.将当前Field进行分词. ​ keyword: 当前Field不会被分词 数值类型: ​ long: ​ Integer: ​ short: ​ byte: ​ double: ​ float: ​ half_float: 精度比float小一半. ​ scaled_float: 根据一个long和scaled来表达一个浮点型,long-345,scaled-100 -> 3.45 时间类型: ​ date类型,针对时间类型指定具体格式 布尔类型: boolean类型,表达true和false 二进制类型: ​ binary类型暂时支持Base64 encode string 范围类型: ​ long_range: 赋值时,无序指定具体内容,只需要存储一个范围即可,指定gt,lt,gte,lte ​ integer_range: ​ double_range: ​ date_range: ​ ip_range: ​ float_range: 经纬度类型: ​ geo_point: 用来存储经纬度的 ip类型: ​ ip: 可以存储IPV4或者IPV6 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/10_ES创建索引指定数据结构.html":{"url":"qf_es/10_ES创建索引指定数据结构.html","title":"ES创建索引指定数据结构","keywords":"","body":" 3.5 创建索引并指定结构 # 创建索引,指定数据结构 PUT /book { \"settings\":{ # 分片数 \"number_of_shards\":5, # 备份数 \"number_of_replicas\":1 }， # 指定数据结构 \"mappings\":{ # 类型 Type \"novel\": { # 文档存储的field \"properties\": { # field属性名 \"name\":{ # 类型 \"type\":\"text\", # 指定分词器 \"analyzer\": \"ik_max_word\", # 指定当前Field可以被作为查询的条件 \"index\": true, # 是否需要额外存储 \"store\": false, }, \"author\":{ \"type\":\"keyword\" }, \"count\":{ \"type\":\"long\" }, \"onSale\":{ \"type\":\"date\", # 时间的格式化方式 \"format\":\"yyyy-MM-dd HH:mm:ss||yyyy-MM-dd||epoch_millis\" }, \"descr\":{ \"type\":\"text\" }, } } } } new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/11_ES的文档操作.html":{"url":"qf_es/11_ES的文档操作.html","title":"ES的文档操作","keywords":"","body":" 3.6 文档的操作 文档在ES服务中的唯一标识,_index, _type, _id三个内容为符合,锁定一个文档,操作是添加还是修改操作. 3.6.1 新建文档 自动生成id # 添加文档,自动生成id POST /book/novel { \"name\":\"盘龙\", \"author\":\"我吃西红柿\", \"count\":100000, \"on-sale\":\"2020-01-01\", \"dercr\":\"xixiixhh233333\" } 手动指定id # 添加文档,手动指定id POST /book/novel { \"name\":\"红楼梦\", \"author\":\"曹雪芹\", \"count\":10890000, \"on-sale\":\"1089-01-01\", \"dercr\":\"xixmeinviixh56733\" } 3.6.2 修改文档 覆盖式修改 # 添加文档,手动指定id POST /book/novel { \"name\":\"红楼梦\", \"author\":\"曹雪芹\", \"count\":10890078, \"on-sale\":\"1089-03-01\", \"dercr\":\"xixmeinviixh56733\" } doc修改方式(推荐使用) # 修改文档,基于doc方式 POST /index/novel/1/_update { \"doc\":{ \"count\":\"1235207200\" } } 3.6.3 删除文档 # 根据id删除文档 DELETE /book/novel/_id new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/12_Java操作ES.html":{"url":"qf_es/12_Java操作ES.html","title":"Java操作ES","keywords":"","body":"四.Java操作elasticsearch4.1 Java连接ES四.Java操作elasticsearch 4.1 Java连接ES 创建一个maven工程 导入依赖 elasticsearch官方jar包 elasticsearch的高级API junit lombok pom.xml org.elasticsearch elasticsearch 6.5.4 org.elasticsearch.client elasticsearch-rest-high-level-client 6.5.4 junit junit 4.12 org.projectlombok lombok 1.16.22 创建类ESClient.java 测试连接 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/13_Java代码操作索引_create.html":{"url":"qf_es/13_Java代码操作索引_create.html","title":"Java代码操作索引_create","keywords":"","body":" new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/14_Java代码操作索引_exists_delete.html":{"url":"qf_es/14_Java代码操作索引_exists_delete.html","title":"Java代码操作索引_exists_delete","keywords":"","body":"4.3 检查索引是否存在&删除索引 检查索引是否存在 删除索引 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/15_Java操作文档_添加文档.html":{"url":"qf_es/15_Java操作文档_添加文档.html","title":"Java操作文档_添加文档","keywords":"","body":"4.3 Java操作文档 4.3.1 添加文档操作 准备一个json数据 准备一个request对象 通过client对象执行添加 输出返回结果 https://www.bilibili.com/video/BV1Qz411e7yx?p=16new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:55:13 "},"qf_es/16_Java操作文档_修改删除文档.html":{"url":"qf_es/16_Java操作文档_修改删除文档.html","title":"Java操作文档_修改删除文档","keywords":"","body":"4.3.2 修改文档 @Test public void updateDoc() throws IOException{ // 1. 创建一个Map, 指定需要修改的内容 Map doc = new HashMap<>(); doc.put(\"name\",\"长大三\"); String docId = \"1\"; // 2. 创建request对象,封装数据 UpdateRequest request = new UpdateRequest(index，type,docId); request.doc(doc); // 3. 通过client对象执行 UpdateResponse update = client.update(request, RequestOptions.DEFAULT); // 4. 输出返回结果 System.out.println(update.getResult().toString()) } 4.3.3 删除文档 @Test public void deleteDoc(){ // 1. 封装Request对象 DeleteRequest request = new DeleteRequest(index,type,\"1\"); // 2. client执行 DeleteResponse resp = client.delete(request, ResquestOptions.DEFAULT); // 3. 输出结果 System.out.println(resp.getResult().toString()); } new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 19:14:48 "},"qf_es/17_Java操作文档_批量操作.html":{"url":"qf_es/17_Java操作文档_批量操作.html","title":"Java操作文档_批量操作","keywords":"","body":"4.4 Java批量操作文档 4.4.1 批量添加 @Test public void bulkCreateDoc(){ // 1. 准备多个json数据 Person p1 = new Person(1,\"张三\",23,new Date()); Person p1 = new Person(2,\"李四\",26,new Date()); Person p1 = new Person(3,\"王五\",27,new Date()); String json1 = mapper.writeValueAsString(p1); String json2 = mapper.writeValueAsString(p2); String json3 = mapper.writeValueAsString(p3); // 2.创建Request,将准备好的数据封装进去 BulkRequest request = new BulkRequest(); request.add( new IndexRequest( index,type,p1.getId().toString() ).source(json1,XContentType.JSON) ); request.add( new IndexRequest( index,type,p2.getId().toString() ).source(json2,XContentType.JSON) ); request.add( new IndexRequest( index,type,p3.getId().toString() ).source(json3,XContentType.JSON) ); // 3. 用client执行 BulkResponse resp = client.bulk(request, RequestOption.DEFAULT); // 4. 输出结果 System.out.println(resp.toString()); } 刷新,查看结果 4.4.2 批量删除 @Test public void bulkDeleteDoc throws IOException(){ // 1.封装Request对象 BulkRequest request = new BulkRequest(); request.add( new DeleteRequest(index,type,\"1\") ); request.add( new DeleteRequest(index,type,\"2\") ); request.add( new DeleteRequest(index,type,\"3\") ); // 2.client执行 BulkRequest resp = client.bulk(request, RequestOptions.DEFAULT) // 3.输出 System.out.println(resp.toString()); } 查看结果,果然没了 new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 19:20:22 "},"qf_es/18_准备测试数据.html":{"url":"qf_es/18_准备测试数据.html","title":"准备测试数据","keywords":"","body":"五. Elasticsearch练习五. Elasticsearch练习 首先要构建索引 索引:sms-logs-index 类型:sms-logs-type new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 19:26:13 "},"qf_es/19_ES查询_term查询.html":{"url":"qf_es/19_ES查询_term查询.html","title":"ES查询_term查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/20_ES查询_terms查询.html":{"url":"qf_es/20_ES查询_terms查询.html","title":"ES查询_terms查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/21_ES查询_match_all查询.html":{"url":"qf_es/21_ES查询_match_all查询.html","title":"ES查询_match_all查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/22_ES查询_布尔matchl查询.html":{"url":"qf_es/22_ES查询_布尔matchl查询.html","title":"ES查询_布尔matchl查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/23_ES查询_multiMatch查询.html":{"url":"qf_es/23_ES查询_multiMatch查询.html","title":"ES查询_multiMatch查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/24_ES查询_id_ids查询.html":{"url":"qf_es/24_ES查询_id_ids查询.html","title":"ES查询_id_ids查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/25_ES查询_prefix查询.html":{"url":"qf_es/25_ES查询_prefix查询.html","title":"ES查询_prefix查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/26_ES查询_fuzzy查询.html":{"url":"qf_es/26_ES查询_fuzzy查询.html","title":"ES查询_fuzzy查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/27_ES查询_wildcard查询.html":{"url":"qf_es/27_ES查询_wildcard查询.html","title":"ES查询_wildcard查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/28_ES查询_range查询.html":{"url":"qf_es/28_ES查询_range查询.html","title":"ES查询_range查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/29_ES查询_regexp查询.html":{"url":"qf_es/29_ES查询_regexp查询.html","title":"ES查询_regexp查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/30_ES深分页scroll介绍.html":{"url":"qf_es/30_ES深分页scroll介绍.html","title":"ES深分页scroll介绍","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/31_ES深分页RESTful实现.html":{"url":"qf_es/31_ES深分页RESTful实现.html","title":"ES深分页RESTful实现","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/32_ES深分页scroll的Java实现.html":{"url":"qf_es/32_ES深分页scroll的Java实现.html","title":"ES深分页scroll的Java实现","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/33_ES的delete_by_query.html":{"url":"qf_es/33_ES的delete_by_query.html","title":"ES的delete_by_query","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/34_ES的复合查询_bool查询.html":{"url":"qf_es/34_ES的复合查询_bool查询.html","title":"ES的复合查询_bool查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/35_ES的复合查询_boostringl查询.html":{"url":"qf_es/35_ES的复合查询_boostringl查询.html","title":"ES的复合查询_boostringl查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/36_ES的filter查询.html":{"url":"qf_es/36_ES的filter查询.html","title":"ES的filter查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/37_ES的高亮查询.html":{"url":"qf_es/37_ES的高亮查询.html","title":"ES的高亮查询","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/38_ES的聚合查询-cardinality.html":{"url":"qf_es/38_ES的聚合查询-cardinality.html","title":"ES的聚合查询-cardinality","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/39_ES的聚合查询-range.html":{"url":"qf_es/39_ES的聚合查询-range.html","title":"ES的聚合查询-range","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/40_ES的聚合查询-extended_stats.html":{"url":"qf_es/40_ES的聚合查询-extended_stats.html","title":"ES的聚合查询-extended_stats","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/41_ES的经纬度查询_介绍.html":{"url":"qf_es/41_ES的经纬度查询_介绍.html","title":"ES的经纬度查询_介绍","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/42_ES的经纬度查询_准备测试数据.html":{"url":"qf_es/42_ES的经纬度查询_准备测试数据.html","title":"ES的经纬度查询_准备测试数据","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/43_ES的经纬度查询_RESTful实现.html":{"url":"qf_es/43_ES的经纬度查询_RESTful实现.html","title":"ES的经纬度查询_RESTful实现","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"qf_es/44_ES的经纬度查询_Java实现.html":{"url":"qf_es/44_ES的经纬度查询_Java实现.html","title":"ES的经纬度查询_Java实现","keywords":"","body":"new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2020-08-26 18:51:37 "},"sgg/":{"url":"sgg/","title":"ES","keywords":"","body":"001-开篇002-技术选型003-教学大纲004-入门-环境准备005-入门-RESTful & JSON006-入门-Postman客户端工具007-入门-倒排索引008-入门-HTTP-索引-创建put方式而 POST 是不支持的009-入门-HTTP-索引-查询 & 删除只需要改变请求方式即可查看所有索引删除索引010-入门-HTTP-文档-创建（Put & Post）POST请求体必须要有这里能用PUT幂等性的操作 POST换PUT也可以了这回(幂等性)011-入门-HTTP-查询-主键查询 & 全查询主键查询(上来先GET)存在的如果不存在全部查询(search)012-入门-HTTP-全量修改 & 局部修改 & 删除& 全量修改& 局部修改& 删除013-入门-HTTP-条件查询 & 分页查询 & 查询排序条件查询分页查询排序014-入门-HTTP-多条件查询 & 范围查询& 多条件查询或者& 范围查询015-入门-HTTP-全文检索 & 完全匹配 & 高亮查询016-入门-HTTP-聚合查询017-入门-HTTP-映射关系018-入门-JavaAPI-环境准备019-入门-JavaAPI-索引-创建020-入门-JavaAPI-索引-查询 & 删除021-入门-JavaAPI-文档-新增 & 修改022-入门-JavaAPI-文档-查询 & 删除023-入门-JavaAPI-文档-批量新增 & 批量删除024-入门-JavaAPI-文档-高级查询-全量查询025-入门-JavaAPI-文档-高级查询-分页查询 & 条件查询 & 字段查询026-入门-JavaAPI-文档-高级查询-组合查询 & 范围查询027-入门-JavaAPI-文档-高级查询-模糊查询 & 高亮查询028-入门-JavaAPI-文档-高级查询-最大值查询 & 分组查询029 -环境-简介030-环境-Windows集群部署031-环境-Linux单节点部署032-环境-Linux集群部署033-进阶-核心概念034-进阶-系统架构-简介035-进阶-单节点集群036-进阶-故障转移037-进阶-水平扩容038-进阶-应对故障039-进阶-路由计算 & 分片控制040-进阶-数据写流程041-进阶-数据读流程042-进阶-更新流程 & 批量操作流程043-进阶-倒排索引044-进阶-文档搜索045-进阶-文档刷新 & 文档刷写 & 文档合并046-进阶-文档分析047-进阶-文档控制048-进阶-文档展示-Kibana049-框架集成-SpringData-整体介绍05-框架集成-SpringData-代码功能集成051-框架集成-SpringData-集成测试-索引操作052-框架集成-SpringData-集成测试-文档操作053-框架集成-SpringData-集成测试-文档搜索054-框架集成-SparkStreaming-集成055-框架集成-Flink-集成056-优化-硬件选择057-优化-分片策略058-优化-路由选择059-优化-写入速度优化060-优化-内存设置061-优化-重要配置062-面试题001-开篇 结构化数据和非结构化数据 课件: sgg_elasticsearch 002-技术选型 Elastic Stack的核心 Elasticsearch是一个分布式、RESTful风格的搜索和数据分析引擎，能够解决不断涌现出的各种用例。作为Elastic Stack的核心，它集中存储您的数据，帮助您发现意料之中以及意料之外的情况 The Elastic Stack，包括 Elasticsearch、Kibana、Beats和 Logstash(也称为ELK Stack)。能够安全可靠地获取任何来源、在何格式的数据，然后实时地对数据进行搜索、分析和可视化。Elaticsearch,简称为ES，ES是一个开源的高扩展的分布式全文搜索引擎,是整个ElasticStack 技术栈的核心。它可以近乎实时的存储、检索数据;本身扩展性很好，可以扩展到上百台服务器，处理PB级别的数据。 003-教学大纲 ES和其他技术栈 集成 004-入门-环境准备 git rebase mark here!!! 005-入门-RESTful & JSON URI http: /l localhost : 9200/test/test.txt GET,POST,PUT,DELETE,HEAD JSON Javascript object Notation var obj = { \"name\" : \"zhangsan\", \"age\": 30, \"info\" : { \"email\" : \"xxxxx\"} }var objs = [obj, obj] new object ()I JSON字符串:网络中传递的字符串的格式符合JSON格式， 006-入门-Postman客户端工具 idea 自带 .http 测试用例 007-入门-倒排索引 008-入门-HTTP-索引-创建 put方式 PUT http://10.221.154.185:9003/shopping2 HTTP/1.1 200 OK Warning: 299 Elasticsearch-6.8.0-65b6179 \"the default number of shards will change from [5] to [1] in 7.0.0; if you wish to continue using the default of [5] shards, you must manage this on the create index request or with an index template\" content-type: application/json; charset=UTF-8 { \"acknowledged\": true, \"shards_acknowledged\": true, \"index\": \"shopping2\" } Response code: 200 (OK); Time: 272ms; Content length: 68 bytes put操作 有 幂等性 PUT http://10.221.154.185:9003/shopping2 HTTP/1.1 400 Bad Request content-type: application/json; charset=UTF-8 { \"error\": { \"root_cause\": [ { \"type\": \"resource_already_exists_exception\", \"reason\": \"index [shopping2/ltqnduE0QtqWZErxMLo73g] already exists\", \"index_uuid\": \"ltqnduE0QtqWZErxMLo73g\", \"index\": \"shopping2\" } ], \"type\": \"resource_already_exists_exception\", \"reason\": \"index [shopping2/ltqnduE0QtqWZErxMLo73g] already exists\", \"index_uuid\": \"ltqnduE0QtqWZErxMLo73g\", \"index\": \"shopping2\" }, \"status\": 400 } Response code: 400 (Bad Request); Time: 152ms; Content length: 377 bytes 而 POST 是不支持的 POST http://10.221.154.185:9003/shopping2 HTTP/1.1 405 Method Not Allowed Allow: GET,HEAD,DELETE,PUT content-type: application/json; charset=UTF-8 { \"error\": \"Incorrect HTTP method for uri [/shopping2] and method [POST], allowed: [GET, HEAD, DELETE, PUT]\", \"status\": 405 } Response code: 405 (Method Not Allowed); Time: 131ms; Content length: 120 bytes 009-入门-HTTP-索引-查询 & 删除 只需要改变请求方式即可 GET http://10.221.154.185:9003/shopping2 HTTP/1.1 200 OK Warning: 299 Elasticsearch-6.8.0-65b6179 \"[types removal] The parameter include_type_name should be explicitly specified in get indices requests to prepare for 7.0. In 7.0 include_type_name will default to 'false', which means responses will omit the type name in mapping definitions.\" content-type: application/json; charset=UTF-8 { \"shopping2\": { \"aliases\": {}, \"mappings\": {}, \"settings\": { \"index\": { \"creation_date\": \"1629946010925\", \"number_of_shards\": \"5\", \"number_of_replicas\": \"1\", \"uuid\": \"ltqnduE0QtqWZErxMLo73g\", \"version\": { \"created\": \"6080099\" }, \"provided_name\": \"shopping2\" } } } } Response code: 200 (OK); Time: 207ms; Content length: 237 bytes 查看所有索引 GET http://10.221.154.185:9003/_cat/indices?v= HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 [ { \"health\": \"green\", \"status\": \"open\", \"index\": \".monitoring-es-6-2021.08.26\", \"uuid\": \"d6g3cn54S1-BHihWWWq8Xg\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"23479\", \"docs.deleted\": \"799\", \"store.size\": \"12.9mb\", \"pri.store.size\": \"12.9mb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".monitoring-kibana-6-2021.08.26\", \"uuid\": \"D2hUxM19RK2BXMsjYSHwqw\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"3284\", \"docs.deleted\": \"0\", \"store.size\": \"742.5kb\", \"pri.store.size\": \"742.5kb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".kibana_1\", \"uuid\": \"3kfy0k8wRH-TIK6uADsgeA\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"23\", \"docs.deleted\": \"2\", \"store.size\": \"939.3kb\", \"pri.store.size\": \"939.3kb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".monitoring-kibana-6-2021.08.23\", \"uuid\": \"EmCEEvOqT5yiTHM4AVbNOw\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"12622\", \"docs.deleted\": \"0\", \"store.size\": \"2.5mb\", \"pri.store.size\": \"2.5mb\" }, { \"health\": \"yellow\", \"status\": \"open\", \"index\": \"logstash-2021.08.25\", \"uuid\": \"5wAHDGeuTuyD2sQ1md1S7Q\", \"pri\": \"5\", \"rep\": \"1\", \"docs.count\": \"6\", \"docs.deleted\": \"0\", \"store.size\": \"29.5kb\", \"pri.store.size\": \"29.5kb\" }, { \"health\": \"yellow\", \"status\": \"open\", \"index\": \"index1\", \"uuid\": \"mY9diN_nTEeEW6Q2CqM7Lw\", \"pri\": \"5\", \"rep\": \"1\", \"docs.count\": \"0\", \"docs.deleted\": \"0\", \"store.size\": \"1.2kb\", \"pri.store.size\": \"1.2kb\" }, { \"health\": \"yellow\", \"status\": \"open\", \"index\": \"shopping\", \"uuid\": \"Nlwy9q6hRGOqa83HPanTPA\", \"pri\": \"5\", \"rep\": \"1\", \"docs.count\": \"0\", \"docs.deleted\": \"0\", \"store.size\": \"1.2kb\", \"pri.store.size\": \"1.2kb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".monitoring-es-6-2021.08.24\", \"uuid\": \"KZ_dF3JjSvG9b9pWOL9lnw\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"111107\", \"docs.deleted\": \"111\", \"store.size\": \"41.5mb\", \"pri.store.size\": \"41.5mb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".monitoring-kibana-6-2021.08.25\", \"uuid\": \"js2fp2rRRUWAINODm2yzvA\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"25203\", \"docs.deleted\": \"0\", \"store.size\": \"5.2mb\", \"pri.store.size\": \"5.2mb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".monitoring-es-6-2021.08.23\", \"uuid\": \"oeoN6InjQDqjDldd3lbbJw\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"63183\", \"docs.deleted\": \"120\", \"store.size\": \"24.3mb\", \"pri.store.size\": \"24.3mb\" }, { \"health\": \"yellow\", \"status\": \"open\", \"index\": \"victor\", \"uuid\": \"Mm8HtnTbRs6JYS1rJNZYZA\", \"pri\": \"5\", \"rep\": \"1\", \"docs.count\": \"0\", \"docs.deleted\": \"0\", \"store.size\": \"1.2kb\", \"pri.store.size\": \"1.2kb\" }, { \"health\": \"yellow\", \"status\": \"open\", \"index\": \"wcm\", \"uuid\": \"mY074hdvTbyfBIrbnOSMeQ\", \"pri\": \"5\", \"rep\": \"1\", \"docs.count\": \"0\", \"docs.deleted\": \"0\", \"store.size\": \"1.2kb\", \"pri.store.size\": \"1.2kb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".monitoring-es-6-2021.08.25\", \"uuid\": \"mx1jVv4XQZ-Zy9XCeG_dgg\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"162119\", \"docs.deleted\": \"276\", \"store.size\": \"76.7mb\", \"pri.store.size\": \"76.7mb\" }, { \"health\": \"yellow\", \"status\": \"open\", \"index\": \"filebeat-6.8.0-2021.08.25\", \"uuid\": \"Eup3hDEfSC6o1JyrIjoqjw\", \"pri\": \"5\", \"rep\": \"1\", \"docs.count\": \"12\", \"docs.deleted\": \"0\", \"store.size\": \"95.6kb\", \"pri.store.size\": \"95.6kb\" }, { \"health\": \"yellow\", \"status\": \"open\", \"index\": \"shopping2\", \"uuid\": \"ltqnduE0QtqWZErxMLo73g\", \"pri\": \"5\", \"rep\": \"1\", \"docs.count\": \"0\", \"docs.deleted\": \"0\", \"store.size\": \"1.2kb\", \"pri.store.size\": \"1.2kb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".monitoring-kibana-6-2021.08.24\", \"uuid\": \"9NyFK509Rji_S8SVBNwQ-Q\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"16611\", \"docs.deleted\": \"0\", \"store.size\": \"3.2mb\", \"pri.store.size\": \"3.2mb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \".kibana_task_manager\", \"uuid\": \"i_nepgs2QSOWDtUpyzQo7Q\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"2\", \"docs.deleted\": \"0\", \"store.size\": \"13.3kb\", \"pri.store.size\": \"13.3kb\" }, { \"health\": \"green\", \"status\": \"open\", \"index\": \"kibana_sample_data_ecommerce\", \"uuid\": \"bOVjHpisQrOqOGbk7j3ylA\", \"pri\": \"1\", \"rep\": \"0\", \"docs.count\": \"4675\", \"docs.deleted\": \"0\", \"store.size\": \"4.7mb\", \"pri.store.size\": \"4.7mb\" }, { \"health\": \"yellow\", \"status\": \"open\", \"index\": \"filebeat-6.8.0-2021.08.24\", \"uuid\": \"MKL1vgIAQ927I0G6wSIA1w\", \"pri\": \"5\", \"rep\": \"1\", \"docs.count\": \"2\", \"docs.deleted\": \"0\", \"store.size\": \"17.5kb\", \"pri.store.size\": \"17.5kb\" } ] Response code: 200 (OK); Time: 170ms; Content length: 3889 bytes 删除索引 DELETE http://10.221.154.185:9003/shopping2 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"acknowledged\": true } Response code: 200 (OK); Time: 161ms; Content length: 21 bytes 010-入门-HTTP-文档-创建（Put & Post） 索引已经创建好了，接下来我们来创建文档，并添加数据。这里的文档可以类比为关系型数据库中的表数据，添加的数据格式为JSON格式 在Postman中，向ES服务器发POST请求: http://127.0.0.1:9200/shopping/l_doc POST http://10.221.154.185:9003/shopping/_doc HTTP/1.1 400 Bad Request content-type: application/json; charset=UTF-8 { \"error\": { \"root_cause\": [ { \"type\": \"parse_exception\", \"reason\": \"request body is required\" } ], \"type\": \"parse_exception\", \"reason\": \"request body is required\" }, \"status\": 400 } Response code: 400 (Bad Request); Time: 119ms; Content length: 163 bytes POST请求体必须要有 POST http://10.221.154.185:9003/shopping/_doc Accept: application/json Content-Type: application/json { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } ### POST http://10.221.154.185:9003/shopping/_doc HTTP/1.1 201 Created Location: /shopping/_doc/xKRsgHsBT86PdrEa7xBP content-type: application/json; charset=UTF-8 { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"xKRsgHsBT86PdrEa7xBP\", \"_version\": 1, \"result\": \"created\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 0, \"_primary_term\": 1 } Response code: 201 (Created); Time: 130ms; Content length: 175 bytes 这里能用PUT PUT http://10.221.154.185:9003/shopping/_doc HTTP/1.1 405 Method Not Allowed Allow: POST content-type: application/json; charset=UTF-8 { \"error\": \"Incorrect HTTP method for uri [/shopping/_doc] and method [PUT], allowed: [POST]\", \"status\": 405 } Response code: 405 (Method Not Allowed); Time: 120ms; Content length: 105 bytes post中的返回体的 _id 是由ES软件生成的, post同样的请求,返回的id结果不一样,说明我们的post请求不是幂等的 但是这个id 他很随机,不好记,我门也可以自己定义ID 幂等性的操作 POST POST http://10.221.154.185:9003/shopping/_doc/1001 HTTP/1.1 201 Created Location: /shopping/_doc/1001 content-type: application/json; charset=UTF-8 { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1001\", \"_version\": 1, \"result\": \"created\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 1, \"_primary_term\": 1 } Response code: 201 (Created); Time: 123ms; Content length: 159 bytes 换PUT也可以了这回(幂等性) PUT http://10.221.154.185:9003/shopping/_doc/1002 HTTP/1.1 201 Created Location: /shopping/_doc/1002 content-type: application/json; charset=UTF-8 { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1002\", \"_version\": 1, \"result\": \"created\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 0, \"_primary_term\": 1 } Response code: 201 (Created); Time: 101ms; Content length: 159 bytes 011-入门-HTTP-查询-主键查询 & 全查询 主键查询(上来先GET) 存在的 GET http://10.221.154.185:9003/shopping/_doc/1001 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1001\", \"_version\": 1, \"_seq_no\": 1, \"_primary_term\": 1, \"found\": true, \"_source\": { \"name\": \"tom\", \"sex\": \"cat\", \"age\": \"13\", \"image\": \"beautiful\" } } Response code: 200 (OK); Time: 100ms; Content length: 190 bytes 如果不存在 GET http://10.221.154.185:9003/shopping/_doc/2001 HTTP/1.1 404 Not Found content-type: application/json; charset=UTF-8 { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"2001\", \"found\": false } Response code: 404 (Not Found); Time: 94ms; Content length: 63 bytes 全部查询(search) GET http://10.221.154.185:9003/shopping/_search HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"took\": 1, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 4, \"max_score\": 1.0, \"hits\": [ { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"CqRugHsBT86PdrEa5xLI\", \"_score\": 1.0, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1001\", \"_score\": 1.0, \"_source\": { \"name\": \"tom\", \"sex\": \"cat\", \"age\": \"13\", \"image\": \"beautiful\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"xKRsgHsBT86PdrEa7xBP\", \"_score\": 1.0, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1002\", \"_score\": 1.0, \"_source\": { \"name\": \"tom\", \"sex\": \"cat\", \"age\": \"13\", \"image\": \"beautiful\" } } ] } } Response code: 200 (OK); Time: 120ms; Content length: 763 bytes 012-入门-HTTP-全量修改 & 局部修改 & 删除 & 全量修改 ### PUT http://10.221.154.185:9003/shopping/_doc/1001 Accept: application/json Content-Type: application/json { \"name\": \"jerry\", \"sex\": \"mouse\", \"age\": \"09\", \"image\": \"funny\" } PUT http://10.221.154.185:9003/shopping/_doc/1001 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1001\", \"_version\": 2, \"result\": \"updated\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 2, \"_primary_term\": 1 } Response code: 200 (OK); Time: 116ms; Content length: 159 bytes 查询 & 局部修改 & 删除 DELETE http://10.221.154.185:9003/shopping/_doc/1001 HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1001\", \"_version\": 3, \"result\": \"deleted\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 3, \"_primary_term\": 1 } Response code: 200 (OK); Time: 133ms; Content length: 159 bytes 不可重复删 DELETE http://10.221.154.185:9003/shopping/_doc/1001 HTTP/1.1 404 Not Found content-type: application/json; charset=UTF-8 { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1001\", \"_version\": 5, \"result\": \"not_found\", \"_shards\": { \"total\": 2, \"successful\": 1, \"failed\": 0 }, \"_seq_no\": 5, \"_primary_term\": 1 } Response code: 404 (Not Found); Time: 137ms; Content length: 161 bytes 013-入门-HTTP-条件查询 & 分页查询 & 查询排序 条件查询 GET http://10.221.154.185:9003/shopping/_search?q=sex%3Acat HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"took\": 25, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 0.2876821, \"hits\": [ { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1002\", \"_score\": 0.2876821, \"_source\": { \"name\": \"tom\", \"sex\": \"cat\", \"age\": \"13\", \"image\": \"beautiful\" } } ] } } Response code: 200 (OK); Time: 134ms; Content length: 293 bytes 还可以在请求体中写 ### GET http://10.221.154.185:9003/shopping/_search Accept: application/json Content-Type: application/json { \"query\": { \"match\": { \"sex\": \"cat\" } } } GET http://10.221.154.185:9003/shopping/_search HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"took\": 1, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 1, \"max_score\": 0.2876821, \"hits\": [ { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1002\", \"_score\": 0.2876821, \"_source\": { \"name\": \"tom\", \"sex\": \"cat\", \"age\": \"13\", \"image\": \"beautiful\" } } ] } } Response code: 200 (OK); Time: 137ms; Content length: 292 bytes 全量查询 ### GET http://10.221.154.185:9003/shopping/_search Accept: application/json Content-Type: application/json { \"query\": { \"match_all\": { } } } GET http://10.221.154.185:9003/shopping/_search HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"took\": 2, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 3, \"max_score\": 1.0, \"hits\": [ { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"CqRugHsBT86PdrEa5xLI\", \"_score\": 1.0, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"xKRsgHsBT86PdrEa7xBP\", \"_score\": 1.0, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1002\", \"_score\": 1.0, \"_source\": { \"name\": \"tom\", \"sex\": \"cat\", \"age\": \"13\", \"image\": \"beautiful\" } } ] } } Response code: 200 (OK); Time: 117ms; Content length: 615 bytes 分页查询 ### 分页查询 GET http://10.221.154.185:9003/shopping/_search Accept: application/json Content-Type: application/json { \"query\": { \"match_all\": { } }, \"from\": 0, \"size\": 2 } (页码-1)*每页条数 GET http://10.221.154.185:9003/shopping/_search HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"took\": 1, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 3, \"max_score\": 1.0, \"hits\": [ { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"CqRugHsBT86PdrEa5xLI\", \"_score\": 1.0, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"xKRsgHsBT86PdrEa7xBP\", \"_score\": 1.0, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } } ] } } Response code: 200 (OK); Time: 213ms; Content length: 467 bytes 指定数据源 排序 ### 分页查询,指定数据源 GET http://10.221.154.185:9003/shopping/_search Accept: application/json Content-Type: application/json { \"query\": { \"match_all\": { } }, \"from\": 0, \"size\": 2, \"_source\": [ \"name\",\"age\" ] , \"sort\": { \"age\": { \"order\": \"desc\" } } } 014-入门-HTTP-多条件查询 & 范围查询 & 多条件查询 ### 条件查询 GET http://10.221.154.185:9003/shopping/_search Accept: application/json Content-Type: application/json { \"query\": { \"bool\": { \"must\": [ { \"match\": { \"age\": \"22\" } }, { \"match\": { \"name\": \"nancy\" } } ] } } } GET http://10.221.154.185:9003/shopping/_search HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"took\": 3, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 2, \"max_score\": 0.5753642, \"hits\": [ { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"CqRugHsBT86PdrEa5xLI\", \"_score\": 0.5753642, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"xKRsgHsBT86PdrEa7xBP\", \"_score\": 0.5753642, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } } ] } } Response code: 200 (OK); Time: 175ms; Content length: 485 bytes 或者 ### 条件查询2 或者 GET http://10.221.154.185:9003/shopping/_search Accept: application/json Content-Type: application/json { \"query\": { \"bool\": { \"should\": [ { \"match\": { \"name\": \"tom\" } }, { \"match\": { \"name\": \"nancy\" } } ] } } } GET http://10.221.154.185:9003/shopping/_search HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"took\": 1, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 3, \"max_score\": 0.2876821, \"hits\": [ { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"CqRugHsBT86PdrEa5xLI\", \"_score\": 0.2876821, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"xKRsgHsBT86PdrEa7xBP\", \"_score\": 0.2876821, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"1002\", \"_score\": 0.2876821, \"_source\": { \"name\": \"tom\", \"sex\": \"cat\", \"age\": \"13\", \"image\": \"beautiful\" } } ] } } Response code: 200 (OK); Time: 122ms; Content length: 639 bytes & 范围查询 ### 条件范围查询 GET http://10.221.154.185:9003/shopping/_search Accept: application/json Content-Type: application/json { \"query\": { \"bool\": { \"should\": [ { \"match\": { \"name\": \"tom\" } }, { \"match\": { \"name\": \"nancy\" } } ], \"filter\": { \"range\": { \"age\": { \"gt\": \"18\" } } } } } } GET http://10.221.154.185:9003/shopping/_search HTTP/1.1 200 OK content-type: application/json; charset=UTF-8 { \"took\": 13, \"timed_out\": false, \"_shards\": { \"total\": 5, \"successful\": 5, \"skipped\": 0, \"failed\": 0 }, \"hits\": { \"total\": 2, \"max_score\": 0.2876821, \"hits\": [ { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"CqRugHsBT86PdrEa5xLI\", \"_score\": 0.2876821, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } }, { \"_index\": \"shopping\", \"_type\": \"_doc\", \"_id\": \"xKRsgHsBT86PdrEa7xBP\", \"_score\": 0.2876821, \"_source\": { \"name\": \"nancy\", \"sex\": \"女\", \"age\": \"22\", \"image\": \"beauty\" } } ] } } Response code: 200 (OK); Time: 106ms; Content length: 486 bytes 015-入门-HTTP-全文检索 & 完全匹配 & 高亮查询 默认会给你分词,并存在倒排索引当中 016-入门-HTTP-聚合查询 https://www.bilibili.com/video/BV1hh411D7sb?p=16&spm_id_from=pageDriver 017-入门-HTTP-映射关系 018-入门-JavaAPI-环境准备 019-入门-JavaAPI-索引-创建 020-入门-JavaAPI-索引-查询 & 删除 021-入门-JavaAPI-文档-新增 & 修改 022-入门-JavaAPI-文档-查询 & 删除 023-入门-JavaAPI-文档-批量新增 & 批量删除 024-入门-JavaAPI-文档-高级查询-全量查询 025-入门-JavaAPI-文档-高级查询-分页查询 & 条件查询 & 字段查询 026-入门-JavaAPI-文档-高级查询-组合查询 & 范围查询 027-入门-JavaAPI-文档-高级查询-模糊查询 & 高亮查询 028-入门-JavaAPI-文档-高级查询-最大值查询 & 分组查询 029 -环境-简介 030-环境-Windows集群部署 031-环境-Linux单节点部署 032-环境-Linux集群部署 033-进阶-核心概念 034-进阶-系统架构-简介 035-进阶-单节点集群 036-进阶-故障转移 037-进阶-水平扩容 038-进阶-应对故障 039-进阶-路由计算 & 分片控制 040-进阶-数据写流程 041-进阶-数据读流程 042-进阶-更新流程 & 批量操作流程 043-进阶-倒排索引 044-进阶-文档搜索 045-进阶-文档刷新 & 文档刷写 & 文档合并 046-进阶-文档分析 047-进阶-文档控制 048-进阶-文档展示-Kibana 049-框架集成-SpringData-整体介绍 05-框架集成-SpringData-代码功能集成 051-框架集成-SpringData-集成测试-索引操作 052-框架集成-SpringData-集成测试-文档操作 053-框架集成-SpringData-集成测试-文档搜索 054-框架集成-SparkStreaming-集成 055-框架集成-Flink-集成 056-优化-硬件选择 057-优化-分片策略 058-优化-路由选择 059-优化-写入速度优化 060-优化-内存设置 061-优化-重要配置 062-面试题 21:45new Valine({el: \"#vcomments\",appId: 'CHjATxRcQrXst8eJrdwX0vjz-gzGzoHsz',appKey: 'nWerbwV2WMAxOEmAMkJKvXzs',placeholder: 'Just go go',avatar: '',meta: undefined,pageSize: 10,lang: 'zh-CN',recordIP: false}) victorfengming.gitee.io，使用署名4.0国际(CC BY 4.0)协议发布 all right reserved，powered by Gitbook最后更新： 2021-10-28 10:57:22 "}}